{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZd5yLnnHOK0"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Custom embedddings con Gensim\n",
        "#### Alumna: Ariadna Garmendia\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enunciado\n",
        "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "- Graficarlos.\n",
        "- Obtener conclusiones."
      ],
      "metadata": {
        "id": "9nR2W3C8op8n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7nqkumo9z9"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import re # Regular Expressions (regex)\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Para leer y parsear texto HTML\n",
        "import bs4 as bs\n",
        "\n",
        "# Para evitar respuesta \"forbidden\"\n",
        "import ssl\n",
        "\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "import requests"
      ],
      "metadata": {
        "id": "eS8t5VsmtPh6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lFToQs5FK5uZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec # Word2Vec es el generador de embeddings de Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizo un cuento en expañol llamado \"El caballero de la armadura oxidada\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context = ssl._create_unverified_context()\n",
        "\n",
        "user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "\n",
        "url = \"http://www.librosmaravillosos.com/elcaballerodelaarmaduraoxidada/index.html\"\n",
        "\n",
        "headers={'User-Agent':user_agent,} \n",
        "\n",
        "request=urllib.request.Request(url,None,headers) #The assembled request\n",
        "response = urllib.request.urlopen(request)\n",
        "raw_html = response.read() # The raw page\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all()\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text\n",
        "\n",
        "# Elimino lo que no me interesa\n",
        "separator_end = 'F I NF I N' # Separador a partir del cual remuevo todo lo que sigue\n",
        "corpus = article_text.split(separator_end, 1)[0] \n",
        "corpus = corpus[corpus.rfind('Hace ya mucho tiempo,'):] # Remuevo lo que está antes de esta frase\n",
        "corpus = re.sub('Capítulo 2En los bosques de Merlín', ' ', corpus)\n",
        "corpus = re.sub('Capítulo 3El sendero de la verdad', ' ', corpus)\n",
        "corpus = re.sub('Capítulo 4El castillo del silencio', ' ', corpus)\n",
        "corpus = re.sub('Capítulo 5El castillo del conocimiento', ' ', corpus)\n",
        "corpus = re.sub('Capítulo 6El castillo de la voluntad y la osadía', ' ', corpus)\n",
        "corpus = re.sub('Capítulo 7La cima de la verdad', ' ', corpus)\n",
        "corpus = re.sub(r'—', ' ', corpus) # \n",
        "corpus = re.sub(r'\\s+', ' ', corpus) # substituir más de un caracter de espacio, salto de línea o tabulación\n",
        "\n"
      ],
      "metadata": {
        "id": "uQsAGj6rszjc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "8OioGunQtUlI",
        "outputId": "64c13742-b4b8-4c3a-f58d-d75d54e33e4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hace ya mucho tiempo, en una tierra muy lejana, vivía un caballero que pensaba que era bueno, generoso y amoroso. Hacía todo lo que suelen hacer los caballeros buenos, generosos y amorosos. Luchaba contra sus enemigos, que era malos, mezquinos y odiosos. Mataba a dragones y rescataba a damiselas en apuros. Cuando en el asunto de la caballería había crisis, tenía la mala costumbre de rescatar damiselas incluso cuando ellas no deseaban ser rescatadas y, debido a esto, aunque muchas damas le estaban agradecidas, otras tantas se mostraban furiosas con el caballero. Él lo aceptaba con filosofía. Después de todo, no se puede contentar a todo el mundo.Nuestro caballero era famoso por su armadura. Reflejaba unos rayos de luz tan brillantes que la gente del pueblo juraba no haber visto el sol salir en el norte o ponerse en el este cuando el caballero partía a la batalla. Y partía a la batalla con bastante frecuencia. Ante la mera mención de una cruzada, el caballero se ponía la armadura entusiasmado, montaba su caballo y cabalgaba en cualquier dirección. Su entusiasmo era tal que a veces partía en varias direcciones a la vez, lo cual no es nada fácil.Durante años, el caballero es esforzó en ser el número uno del reino. Siempre había otra batalla que ganar, otro dragón que matar y otra damisela que rescatar.El caballero tenía una mujer fiel y bastante tolerante, Julieta, que escribía hermosos poemas, decía cosas inteligentes y tenía debilidad por el vino. También tenía un hijo de cabellos dorados, Cristóbal, al que esperaba ver algún día, convertido en un valiente caballero.Julieta y Cristóbal veían poco al caballero porque, cuando no estaba luchando en una batalla, matando dragones o rescatando damiselas, estaba ocupado probándose su armadura y admirando su brillo. Con el tiempo, el caballero se enamoró hasta tal punto de su armadura que se la empezó a poner para cenar y, a menudo, para dormir. Después de un tiempo, ya no se tomaba la molestia de quitársela para nada. Poco a poco, su familia fue olvidando qué aspecto tenía sin ella.Ocasionalmente, Cristóbal le preguntaba a su madre qué aspecto tenía su padre. Cuando esto sucedía, Julieta llevaba al chico hasta la chimenea y señalaba el retrato del caballero.He aquí a tu padre decía con un suspiro.Una tarde, mientras contemplaba el retrato, Cristóbal le dijo a su madre: Ojalá pudiera a ver a padre en persona. ¡No puedes tenerlo todo! respondió bruscamente Julieta.Estaba cada vez más harta de tener tan sólo una pintura como recuerdo del rostro de su marido y estaba cansada de dormir mal por culpa del ruido metálico de la armadura.Cuando paraba en casa y no estaba absolutamente pendiente de su armadura, el caballero solía recitar monólogos sobre sus hazañas. Julieta y Cristóbal casi nunca podían decir una palabra. Cuando lo hacían, el caballero las acallaba, ya sea cerrando su visera o quedándose repentinamente dormido.Un día, Julieta se enfrentó a su marido.Creo que amas más a tu armadura de lo que me amas a mí.Eso no es verdad respondió el caballero ¿Acaso no te amé lo suficiente como para rescatarte de aquel dragón e instalarte en este elegante castillo con paredes empedradas?Lo que tú amabas dijo Julieta, espiando a través de la visera para poder ver sus ojos era la idea de rescatarme. No me amabas realmente entonces y tampoco me amas realmente ahora.Sí que te amo insistió el caballero, abrazándola torpemente con su fría y rígida armadura, casi rompiéndole las costillas. ¡Entonces, quítate esa armadura para ver quién eres en realidad! le exigió.No puedo quitármela. Tengo que estar preparado para montar en mi caballo y partir en cualquier dirección explicó el caballero.Si no te quitas la armadura, cogeré a Cristóbal, subiré a mi caballo y me marcharé de tu vida.Bueno, esto sí que fue un golpe para el caballero. No quería que Julieta se fuera. Amaba a su esposa y a su hijo y a su elegante castillo, pero también amaba a su armadura porque les mostraba a todos quién era él: un caballero bueno, generoso y amoroso. ¿Por qué no se daba cuenta Julieta de ninguna de estas cualidades?El caballero estaba inquieto. Finalmente, tomó una decisión. Continuar llevando la armadura no valía la pena si por ello había de perder a Julieta y Cristóbal.De mala gana, el caballero intentó quitarse el yelmo pero, ¡no se movió! Tiró con más fuerza. Estaba muy enganchado. Desesperado, intentó levantar la visera pero, por desgracia, también estaba atascada. Aunque tiró de la visera una y otra vez, no consiguió nada.El caballero caminó de arriba abajo con gran agitación. ¿Cómo podía haber sucedido esto? Quizá no era tan sorprendente encontrar el yelmo atascado, ya que no se lo había quitado en años, pero la visera era otro asunto. Lo había abierto con regularidad para comer y beber. Pero bueno, ¡si la había abierto esa misma mañana para desayunar huevos revueltos y cerdo en su salsa!Repentinamente, el caballero tuvo una idea. Sin decir adónde iba, salió corriendo hacia la tienda del herrero, en el patio del castillo. Cuando llegó, el herrero estaba dándose forma a una herradura con sus manos.Herrero dijo el caballero tengo un problema.Sois un problema, señor dijo socarronamente el herrero, con su tacto habitual.El caballero, que normalmente gustaba de bromear, arrugó el entrecejo.No estoy de humor para tus bromas en estos momentos. Estoy atrapado en esta armadura vociferó, al tiempo que golpeaba el suelo con el pie revestido de acero, dejándolo caer accidentalmente sobre el dedo gordo del pie del herrero.El herrero dejó escapar un aullido y, olvidando por un momento que el caballero era su señor, le propinó un brutal golpe en el yelmo. El caballero sintió tan sólo una ligera molestia. El yelmo ni se movió. Inténtalo otra vez ordenó el caballero, sin darse cuenta de que el herrero le había golpeado porque estaba enfadado.Con gusto dijo el herrero, balanceando un martillo en venganza y dejándolo caer con fuerza sobre el yelmo del caballero. El yelmo ni siquiera se abolló.El caballero se sintió muy turbado. El herrero era, con mucho, el hombre más fuerte del reino. Si él no podía sacar al caballero de su armadura, ¿quién podría?Como era un buen hombre, excepto cuando le aplastaban el dedo gordo del pie, el herrero percibió el pánico del caballero y sintió lástima.Estáis en una situación difícil, caballero, pero no os deis por vencido. Regresad mañana cuando yo haya descansado. Me habéis cogido el final de un día muy duro. Aquella noche, la cena fue difícil. Julieta se enfadaba cada vez más a medida que iba introduciendo por los orificios de la visera del caballero la comida que había tenido que triturar previamente. A mitad de la cena, el caballero le contó a Julieta que el herrero había intentado abrir la armadura, pero que había fracasado. ¡No te creo, bestia ruidosa! Gritó al tiempo que estrellaba el plato de puré de estofado de paloma contra su yelmo.El caballero no sintió nada. Sólo cuando la salsa comenzó a chorrear por los orificios de la visera, se dio cuenta de que le habían dado en la cabeza. Tampoco había sentido el martillo del herrero aquella tarde. De hecho, ahora que lo pensaba, su armadura no le dejaba sentir apenas nada, y la había llevado durante tanto tiempo que había olvidado cómo se sentían las cosas sin ella.El caballero se entristeció mucho porque Julieta no creía que estaba intentando quitarse la armadura. El herrero y él lo habían intentado, y lo siguieron intentado durante días, sin éxito. Cada día el caballero se deprimía más y Julieta estaba cada vez más fría.Finalmente, el caballero admitió que los esfuerzos del herrero eran vanos. ¡Vaya con el hombre más fuerte del reino! ¡Ni siquiera puedes abrir este montón de lata! gritó con frustración.Cuando el caballero regresó a casa, Julieta le chilló: Tu hijo no tiene más que un retrato de su padre, y estoy harta de hablar con una visera cerrada. No pienso volver a pasar comida por los agujeros de esa horrible cosa nunca más. ¡Este es el último puré de cordero que te preparo!No es mi culpa si estoy atrapado en esta armadura. Tenía que llevarla para estar siempre listo para la batalla. ¿De qué otra manera, si no, hubiera podido comprar bonitos castillos y caballos para ti y para Cristóbal? No lo hacías por nosotros argumentó Julieta, ¡Lo hacías por ti!Al caballero le dolió en el alma que su mujer pareciera no amarlo más. También temía que, si no se quitaba la armadura pronto, Julieta y Cristóbal realmente se marcharían. Tenía que quitarse la armadura, pero no sabía cómo.El caballero descartó una idea tras otra por considerarlas poco viables. Algunos planes eran realmente peligrosos. Sabía que cualquier caballero que se plantease fundir su armadura con la antorcha de un castillo, o congelarla saltando a un foso helado, o hacerla explotar con un cañón, estaba seriamente necesitado de ayuda. Incapaz de encontrar ayuda en su propio reino, el caballero decidió buscar en otras tierras.\"En algún lugar debe de haber alguien que me pueda ayudar a quitarme esta armadura\", pensó.Desde luego, echaría de menos a Julieta, Cristóbal y el elegante castillo. También temía que, en su ausencia, Julieta encontrara el amor en brazos de otro caballero, uno que estuviera deseoso de quitarse la armadura y de ser un padre para Cristóbal. Sin embargo, el caballero tenía que irse, así que, una mañana, muy temprano, montó en su caballo y se alejó cabalgando. No osó mirar atrás por miedo a cambiar de idea.Al salir de la provincia, el caballero se detuvo para despedirse del rey, que había sido muy bueno con él. El rey vivía en un grandioso castillo en la cima de una colina del barrio elegante. Al cruzar el puente levadizo y entrar en el patio, el caballero vio al bufón sentado con las piernas cruzadas, tocando la flauta.El bufón se llamaba Bolsalegre porque llevaba sobre su hombro una bolsa con los colores del arco iris, llena de artilugios para hacer reír o sonreír a la gente. Había extrañas cartas que utilizaba para adivinar el futuro de las personas, cuentas de vivos colores que hacía aparecer y desaparecer y graciosas marionetas que usaba para divertir a su audiencia. Hola, Bolsalegre dijo el caballero He venido a decirle adiós al rey.El bufón miro hacia arriba. El rey se acaba de ir.No hay nada que él os pueda decir. ¿Adónde ha ido? preguntó el caballero. A una cruzada ha partido.Si lo esperáis, vuestro tiempo habréis perdido.El caballero quedó decepcionado por no haber podido ver al rey y perturbado por no poder unirse a él en la cruzada. Oh suspiró. Podría morir de inanición dentro de esta armadura antes de que el rey llegara. quizás no le vuelva a ver nunca más.El caballero sintió ganas de dejarse caer de su montura pero, por supuesto, la armadura se lo impedía. Sois una imagen triste de ver.No con todo vuestro poder, vuestra situación podéis resolver. No estoy de humor para tus insultantes rimas ladró el caballero, tenso dentro de su armadura ¿No puedes tomarte los problemas de alguien seriamente por una vez?Con una clara y lírica voz, Bolsalegre cantó: A mí los problemas no me han de afectar.Son oportunidades para criticar. Otra canción cantarías si fueras tú el que estuviera atrapado aquí gruñó el caballero.Bolsalegre continuó: A todos, alguna armadura nos tiene atrapados.Sólo que la vuestra ya la habéis encontrado. No tengo tiempo de quedarme y oír tus tonterías. Tengo que encontrar la manera de salir de esta armadura.Y dicho esto, el caballero se dispuso a partir, pero Bolsalegre le llamó: Hay alguien que puede ayudaros, caballero, a sacar a la luz vuestro yo verdadero.El caballero detuvo su caballo bruscamente y, emocionado, regresó hacia Bolsalegre. ¿Conoces a alguien que me pueda sacar de esta armadura? ¿Quién es? Tenéis que ver al mago Merlín, así lograréis ser libre al fin. ¿Merlín? El único Merlín del que he oído hablar es el gran sabio, el maestro del Rey Arturo. Si. Si, el mismo es.Merlín solo hay uno, ni dos ni tres. ¡Pero no puede ser! Exclamó el caballero Merlín y el rey Arturo vivieron hace muchos años.Bolsalegre replicó: Es verdad, pero aún vive ahora. En los bosques el sabio mora. Pero esos bosques son tan grandes... dijo el caballero ¿cómo lo encontraré ahí?Bolsalegre sonrió. Aunque muy difícil ahora os parece. Cuando el alumno está preparado, el maestro aparece. Ojalá Merlín apareciera pronto. Voy a buscarlo a él dijo el caballero.Estiró el brazo y le dio la mano a Bolsalegre en señal de gratitud, y por poco le tritura los dedos del bufón con el guantelete.Bolsalegre dio un grito. El caballero soltó rápidamente la mano del bufón. Lo siento.Bolsalegre se frotó los magullados dedos. Cuando la armadura desaparezca y estéis bien. Sentiréis el dolor de los otros también. ¡Me voy! dijo el caballero.Hizo girar su caballo y, abrigando nuevas esperanzas en su corazón, se alejó galopando. No fue tarea fácil encontrar el astuto mago. Había muchos bosques en los que buscar, pero sólo un Merlín. Así que el pobre caballero cabalgó día tras día, noche tras noche, debilitándose cada vez más.Mientras cabalgaba en solitario a través de los bosques, el caballero se dio cuenta de que había muchas cosas que no sabía. Siempre había pensado que era muy listo, pero no se sentía tan listo ahora, intentando sobrevivir en los bosques.De mala gana, se reconoció a sí mismo que no podía distinguir una baya venenosa de una comestible. Esto hacía del acto de comer una ruleta rusa. Beber no era menos complicado. El caballero intentó meter la cabeza en un arroyo, pero su yelmo se llenó de agua. Casi se ahoga dos veces. Por si eso fuera poco, estaba perdido desde que había entrado en el bosque. No sabía distinguir el norte del sur, ni el este del oeste. Por fortuna, su caballo sí lo sabía.Después de meses de buscar en vano, el caballero estaba bastante desanimado. Aún no había encontrado a Merlín, a pesar de haber viajado muchas leguas. Lo que le hacía sentirse peor aún era que ni siquiera sabía cuánto era una legua. Una mañana, se despertó sintiéndose más débil de lo normal y un tanto peculiar. Aquella misma mañana encontró a Merlín. El caballero reconoció al mago enseguida. Estaba sentado en un árbol, vestido con una larga túnica blanca. Los animales del bosque estaban reunidos a su alrededor, y los pájaros descansaban en sus hombros y brazos.El caballero movió la cabeza sombríamente de un lado a otro, haciendo que rechinase su armadura. ¿Cómo podían estos animales encontrar a Merlín con tanta facilidad cuando había sido tan difícil para él? Os he estado buscando le dijo al mago He estado perdido durante meses. Toda vuestra vida le corrigió Merlín, mordiendo una zanahoria y compartiéndola con el conejo más cercano.El caballero se enfureció. No he venido hasta aquí para ser insultado. Quizá siempre os habéis tomado la verdad como un insulto dijo Merlín, compartiendo la zanahoria con algunos de los animales.Al caballero tampoco le gustó mucho este comentario, pero estaba demasiado débil de hambre y sed como para subir a su caballo y marcharse. En lugar de eso, dejó caer su cuerpo envuelto en metal sobre la hierba. Merlín le miró con compasión. Sois muy afortunado comentó Estáis demasiado débil para correr. ¿Y eso qué quiere decir? preguntó con brusquedad el caballero.Merlín sonrió por respuesta. Una persona no puede correr y aprender a la vez. Debe permanecer en un lugar durante un tiempo. Sólo me quedaré aquí el tiempo necesario para aprender cómo salir de esta armadura dijo el caballero. Cuando hayáis aprendido eso afirmó Merlín nunca más tendréis que subir a vuestro caballo y partir en todas direcciones.El caballero estaba demasiado cansado como para cuestionar esto. De alguna manera, se sentía consolado y se quedó dormido enseguida.Cuando el caballero despertó, vio a Merlín y a los animales a su alrededor. Intentó sentarse, pero estaba demasiado débil. Merlín le tendió una copa de plata que contenía un extraño líquido. Bebed esto le ordenó. ¿Qué es? preguntó el caballero, mirando la copa receloso. ¡Estáis tan asustado! dijo Merlín Por supuesto, por eso os pusisteis la armadura desde el principio.El caballero no se molestó en negarlo, pues estaba demasiado sediento. Está bien, lo beberé. Vertedlo por mi visera. No lo haré. Es demasiado valioso para desperdiciarlo.Rompió una caña, puso un extremo en la copa y deslizó el otro por uno de los orificios de la visera del caballero. ¡Ésta es una gran idea! dijo el caballero. Yo lo llamo pajita replicó Merlín. ¿Por qué? ¿Y por qué no?El caballero se encogió de hombros y sorbió el líquido por la caña. Los primeros sorbos le parecieron amargos, los siguientes más agradables, y los últimos tragos fueros bastante deliciosos.Agradecido, el caballero le devolvió la copa a Merlín. Deberías lanzarlo al mercado. Os haríais rico.Merlín se limitó a sonreír.¿Qué es? preguntó el caballero. Vida. ¿Vida? Si dijo el sabio mago. ¿No os pareció amarga al principio y, luego, a medida que la degustabais, no la encontrabais cada vez más apetecible?El caballero asintió. Sí, los últimos sorbos resultaron deliciosos. Eso fue cuando empezasteis a aceptar lo que estabais bebiendo. ¿Estáis diciendo que la vida es buena cuando uno la acepta? preguntó el caballero. ¿Acaso no es así? replicó Merlín, levantando una ceja divertido. ¿Esperáis que acepte toda esta pesada armadura? Ah dijo Merlín no nacisteis con esa armadura. Os la pusisteis vos mismo. ¿Os habéis preguntado por qué? ¿Y por qué no? replicó el caballero, irritado. En ese momento, le estaba empezando a doler la cabeza. No estaba acostumbrado a pensar de esa manera. Seréis capaz de pensar con mayor claridad cuando recuperéis fuerzas dijo Merlín.Dicho esto, el mago hizo sonar sus palmas y las ardillas, llevando nueces entre los dientes, se alinearon delante del caballero. Una por una, cada ardilla trepó al hombro del caballero, rompió y masticó una nuez, y luego empujó los pequeños trozos a través de la visera del caballero. Las liebres hicieron lo mismo con las zanahorias, y los ciervos trituraron raíces y bayas para que el caballero comiera. Este método de alimentación nunca sería aprobado por el ministerio de Sanidad, pero ¿qué otra cosa podía hacer un caballero atrapado en su armadura en medio del bosque?Los animales alimentaban al caballero con regularidad, y Merlín le daba a beber enormes copas de Vida con la pajita. Lentamente, el caballero se fue fortaleciendo, y comenzó a sentirse esperanzado.Cada día le hacía la misma pregunta a Merlín: ¿Cuándo podré salir de esta armadura?Cada día Merlín replicaba: ¡Paciencia! Habéis llevado esa armadura durante mucho tiempo. No podéis salir de ella así como así.Una noche, los animales y el caballero estaban oyendo al mago tocar con su laúd los últimos éxitos de los trovadores. Mientras esperaba que Merlín acabara de tocar Añoro los viejos tiempos, en que los caballeros eran valientes y las damiselas eran frías, el caballero le hizo una pregunta que tenía en mente desde hacía tiempo. ¿Fuisteis en verdad el maestro del rey Arturo?El rostro del mago se encendió. Sí, yo le enseñé a Arturo dijo. Pero ¿cómo podéis seguir vivo? ¡Arturo vivió hace mucho tiempo! exclamó el caballero. Pasado, presente y futuro son uno cuando estás conectado a la Fuente replicó Merlín. ¿Qué es la Fuente? preguntó el caballero. Es el poder misterioso e invisible que es el origen de todo. No entiendo dijo el caballero. Eso se debe a que intentáis comprender con la mente, pero vuestra mente es limitada. Tengo una mente muy buena le discutió el caballero. E inteligente añadió Merlín Ella te atrapó en esa armadura.El caballero no pudo refutar eso. Luego recordó algo que Merlín le había dicho nada más llegar. Una vez me dijisteis que me había puesto esta armadura porque tenía miedo. ¿No es eso verdad? respondió Merlín. No, la llevaba para protegerme cuando iba a la batalla. Y temíais que os hirieran de gravedad o que os mataran añadió Merlín. ¿Acaso no lo teme todo el mundo?Merlín negó con la cabeza. ¿Y quién os dijo que teníais que ir a la batalla? Tenía que demostrar que era un caballero bueno, generoso y amoroso. Si realmente erais bueno, generoso y amoroso, ¿por qué teníais que demostrarlo? preguntó Merlín.El caballero eludió tener que pensar en eso de la misma manera que solía eludir todas las cosas: se puso a dormir.A la mañana siguiente, despertó con un pensamiento elevado en su mente: ¿Era posible que no fuese bueno, generoso y amoroso? Decidió preguntárselo a Merlín. ¿Qué pensáis vos? replicó Merlín. ¿Por qué siempre respondéis a una pregunta con otra pregunta? ¿Y por qué siempre buscáis que otros os respondan vuestras preguntas?El caballero se marchó enfadado, maldiciendo a Merlín entre dientes. ¡Ese Merlín! masculló ¡Hay veces que realmente me saca de mi armadura!Con un ruido seco, el caballero dejó caer su pesado cuerpo bajo un árbol para reflexionar sobre las preguntas del mago.¿Qué pensaba en realidad? ¿Podría ser dijo en voz alta a nadie en particular que yo no fuera bueno, generoso y amoroso? Podría ser dijo una vocecita Si no ¿por qué estáis sentado sobre mi cola? ¿Eh? el caballero miró hacia abajo y vio a una pequeña ardilla sentada a su lado. Es decir, a casi toda la ardilla. Su cola estaba escondida. ¡uh perdona! dijo el caballero, moviendo rápidamente la pierna para que la ardilla pudiera recuperar su cola Espero no haberte hecho daño. No veo muy bien con esta visera en mi camino. No lo dudo replicó la ardilla sin ningún resentimiento en la voz Por eso siempre estáis pidiendo disculpas a la gente por haberles hecho daño. La única cosa que me irrita más que un mago sabelotodo es una ardilla sabelotodo. gruñó el caballero No tengo por qué quedarme aquí y hablar contigo.Luchó contra el peso de la armadura en un intento de ponerse de pie. De repente, sorprendido, balbuceó: ¡Eh... tu y yo estamos hablando! Un tributo a mi buena fe replicó la ardilla teniendo en cuenta que os habéis sentado sobre mi cola. Pero si los animales no pueden hablar dijo el caballero. uh, claro que pueden dijo la ardilla Lo que sucede es que la gente no escucha.El caballero movió la cabeza, perplejo. ¿Me has hablado antes? Claro, cada vez que rompía una nuez y la empujaba por vuestra visera. ¿Cómo es que te puedo oír ahora si no te podía oír entonces? Admiro una mente inquisitiva comentó la ardilla pero ¿nunca aceptáis nada tal como es, simplemente porque es? Estás respondiendo a mis preguntas con preguntas dijo el caballero Has pasado demasiado tiempo con Merlín. Y vos no habéis pasado el tiempo suficiente con él.La ardilla le dio un ligero golpe al caballero con su cola y trepó a un árbol corriendo. El caballero la llamó. ¡Espera! ¿Cómo te llamas? Ardilla replicó ella simplemente, y desapareció en la copa del árbol.Aturdido, el caballero movió la cabeza. ¿Se había imaginado todo esto? En ese preciso instante, vio a Merlín acercarse. Merlín dijo Tengo ganas de salir de aquí. He empezado a hablar con las ardillas. Espléndido replicó el Mago.El caballero le miró preocupado. ¿Cómo puede ser espléndido? ¿Qué queréis decir? Simplemente eso. Os estáis volviendo lo suficientemente sensible como para sentir las vibraciones de otros.El caballero estaba obviamente confundido, así que Merlín continuó explicando: No hablasteis con la ardilla con palabras, sino que sentisteis sus vibraciones, y tradujisteis esas vibraciones en palabras. Estoy esperando el día en que empecéis a hablar con las flores. Eso será el día que las plantéis en mi tumba. ¡Tengo que salir de estos bosques! ¿Adonde irías? Regresaría con Julieta y Cristóbal. Han estado solos durante mucho tiempo. Tengo que volver y cuidar de ellos. ¿Cómo podéis cuidar de ellos si ni siquiera podéis cuidar de vos mismo? preguntó Merlín. Pero les echo de menos se quejó el caballero quiero regresar con ellos. Aún en el peor de los casos. Y es exactamente así como regresaréis si vais con vuestra armadura le previno Merlín.El caballero miró a Merlín con tristeza. No quiero esperar a quitarme la armadura. Quiero volver ahora y ser un marido bueno, generoso y amoroso para Julieta y un gran padre para Cristóbal.Merlín asintió comprensivo. Le dijo al caballero que regresar para dar de sí mismo era un maravilloso regalo. Sin embargo añadió un don para ser un don, debe ser aceptado. De no ser así es como una carga para las personas. ¿Queréis decir que quizá no quieran que regrese? preguntó el caballero sorprendido Seguramente me darían otra oportunidad. Después de todo, yo soy uno de los mejores caballeros del reino. Quizás esta armadura sea más gruesa de lo que parece dijo Merlín con suavidad.El caballero reflexionó sobre esto. Recordó las eternas quejas de Julieta porque él se iba a la batalla tan a menudo, por la atención que le prestaba a su armadura, y por su visor cerrado y su costumbre de quedarse dormido para no oír las palabras. Quizá Julieta no quisiera que él volviese, pero Cristóbal sí querría. ¿Por qué no mandarle una nota a Cristóbal y preguntárselo? sugirió Merlín.El caballero estuvo de acuerdo en que era una buena idea, pero ¿cómo podía hacerle llegar una nota a Cristóbal?Merlín señaló a la paloma que estaba posada sobre su hombro. Rebeca la llevará.El caballero estaba perplejo. Ella no sabe donde vivo. Es sólo un estúpido pájaro. Puedo distinguir el norte del sur y el este del oeste respondió secamente Rebeca lo cual es más de lo que se podría decir de vos.El caballero se disculpó rápidamente. Estaba completamente pasmado. No sólo había hablado con una paloma y una ardilla, sino que además las había hecho enfadar a las dos en el mismo día.Como era un pájaro de gran corazón, Rebeca aceptó las disculpas del caballero y partió con la nota para Cristóbal en el pico. No arrulles con palomas extrañas o dejarás caer mi nota le gritó el caballero.Rebeca ignoró este comentario desconsiderado. El caballero estaba cada vez más impaciente, temiendo que hubiera caído presa de alguno de los halcones de caza que él y otros caballeros habían entrenado. Se estremeció, preguntándose cómo había podido participar en un deporte tan sucio, y se arrepintió otra vez de su horrible equivocación.Cuando Merlín terminó de tocas su laúd y de cantar Tendrás un largo y frío invierno, si tienes un corto y frío corazón, el caballero le expresó sus preocupaciones con respecto a Rebeca.Merlín le dio confianza con un alegre verso: La paloma más lista que jamás haya volado, no puede ir a parar a ningún guisado. En ese momento, un gran parloteo se levantó entre los animales. Todos miraban al cielo, así que Merlín y el caballero miraron también. Muy alto, sobre sus cabezas, dando círculos para aterrizar, estaba Rebeca.El caballero se puso de pie con gran esfuerzo, el tiempo que Rebeca se posaba en el hombro de Merlín. Cogiendo la nota de su pico, el mago la miró y le dijo al caballero con gravedad que era de Cristóbal. ¡Déjamela ver! dijo el caballero, quitándole el papel... ¡Está en blanco! Exclamó ¿qué quiere decir esto? Quiere decir dijo Merlín suavemente que vuestro hijo no os conoce lo suficiente como para daros una respuesta.El caballero permaneció quieto un momento, pasmado, luego lanzó un gemido y lentamente cayó al suelo. Intentó retener las lágrimas, pues los caballeros de brillante armadura simplemente no lloran. Sin embargo, pronto su pena le venció. Luego, exhausto y medio ahogado en su yelmo por las lágrimas, el caballero se quedó dormido. Cuando el caballero despertó, Merlín estaba sentado silenciosamente a su lado. Siento no haber actuado como un caballero dijo Mi barba está hecha una sopa. añadió disgustado. No os excuséis dijo Merlín Acabáis de dar el primer paso para liberaros de vuestra armadura. ¿Qué queréis decir? Ya lo veréis replicó el Mago. Se puso de pie. Es hora de que os vayáis.Esto molestó al caballero. Estaba empezando a disfrutar de estar en el bosque con Merlín y los animales. De cualquier manera, le parecía que no tenía adónde ir. Aparentemente, Julieta y Cristóbal no lo querían en casa. Es verdad que podía volver al asunto de la caballería e ir a alguna cruzada. Tenía muy buena reputación en batalla, y había muchos reyes que se sentirían felices teniéndolo a su lado, pero ya no le parecía que luchar pudiese tener sentido.Merlín le recordó al caballero su nuevo propósito: liberarse de la armadura. ¿Por qué molestarse? preguntó el caballero ásperamente a Julieta y a Cristóbal les daba igual si me la quito o no. Hacedlo por vos mismo sugirió Merlín El estar atrapado entro todo ese acero os ha causado muchos problemas, y las cosas empeorarán con el paso del tiempo. Incluso podríais morir a causa de una neumonía por culpa de una barba empapada. Supongo que sí, mi barba se ha convertido en un fastidio replicó el caballero Estoy cansado de cargar con ella y estoy harto de comer papillas. Ahora que lo pienso, ni siquiera me puedo rascar la espalda cuando me pica. ¿Y cuándo fue la última vez que sentisteis el calor de un beso, olisteis la fragancia de una flor, o escuchasteis una hermosa melodía sin que vuestra armadura se interpusiera entre vosotros? Ya ni me acuerdo murmuró el caballero con tristeza Tenéis razón, Merlín. Tengo que liberarme de esta armadura por mí mismo. No podéis continuar viviendo y pensando como lo habéis hecho hasta ahora dijo Merlín Fue así como os quedasteis atrapado en ese montón de acero al principio. Pero, ¿cómo puedo cambiar todo eso? preguntó el caballero intranquilo. No es tan difícil como parece explicó Merlín, conduciendo al caballero hacia un sendero Éste es el sendero que seguisteis para llegar a estos bosques. Yo no seguí ningún sendero dijo el caballero ¡Estuve perdido durante meses! La gente no suele percibir el sendero por el que transita replicó Merlín. ¿Queréis decir que el sendero estaba ahí pero yo no lo podía ver? Sí, y podéis regresar por el mismo, si asó lo deseáis; pero conduce a la deshonestidad, la avaricia, el odio, los celos, el miedo y la ignorancia. ¿Estáis diciendo que yo soy todo eso? preguntó el caballero indignado. En algunos momentos, sois alguna de esas cosas admitió Merlín en voz baja.El mago señaló hacia otro sendero. Era más estrecho que el primero y muy empinado. Parece una escalada difícil observó el caballero. Ése dijo Merlín asintiendo es el Sendero de la Verdad. Se vuelve más empinado a medida que se acerca a la cima de una lejana montaña.El caballero contempló el empinado camino sin entusiasmo. No estoy seguro de que valga la pena. ¿Qué conseguiré cuando llegue a la cima? Se trata de lo que no tendréis. explicó Merlín ¡Vuestra armadura!El caballero reflexionó sobre esto. Si regresaba por el camino por el que había venido, no tendría esperanzas de liberarse de su armadura y, probablemente moriría de soledad y fatiga. La única manera de quitarse la armadura era, por lo visto, seguir el Sendero de la Verdad, aunque pudiese, en tal caso, morir intentando trepar hacia la empinada montaña.El caballero observó el difícil sendero que tenía delante. Luego miró hacia abajo, y contempló el acero que cubría su cuerpo. Está bien dijo con resignación Probaré el Sendero de la Verdad.Merlín asintió: Vuestra decisión de transitar un sendero desconocido, teniendo que cargar con una pesada armadura, requiere mucho coraje.El caballero sabía que tenía que comenzar de inmediato, porque, si no, podría cambiar de opinión. Iré a buscar mi fiel caballo dijo 0h, no rebatió Merlín, moviendo la cabeza de lado a lado El camino tiene partes demasiado estrechas para que un caballo pueda pasar. Tendréis que ir a pie. Horrorizado, el caballero se dejó caer sobre una roca. Creo que prefiero morir por culpa de una barba empapada dijo, perdiendo todo el coraje con una rapidez impresionante. No tendrás que viajar solo le dijo Merlín Ardilla os acompañará. ¿Qué pretendéis, que cabalgue sobre una ardilla? preguntó el caballero, asustado ante la idea de tener por compañera en tan arduo viaje a un animal sabelotodo. Puede que no me puedas montar dijo la ardilla pero me necesitaréis para que os ayuda a comer. ¿Quién si no, masticará las nueces para vos y las pasará por vuestra visera?Cuando Rebeca oyó la conversación, voló desde un árbol cercano y se posó en el hombro del caballero. Yo también os acompañaré. He estado en la cima de la montaña y conozco el camino dijo.La buena disposición que mostraban los dos animales para ayudarle, proporcionó al caballero el coraje que necesitaba. \"Bueno, bueno se dijo ¡uno de los principales caballeros del reino necesitando que una ardilla y un pájaro le den coraje!\"Se puso de pie con gran esfuerzo, indicándole a Merlín que estaba listo para comenzar el viaje.Mientras caminaban por el sendero, el mago sacó una exquisita llave dorada de su cuello y se la dio al caballero. Esta llave abrirá las puertas de los tres castillos que bloquearán vuestro camino. ¡Lo sé! Gritó el caballero Habrá una princesa en cada castillo, y mataré al dragón que la retiene y la rescataré... ¡Basta! lo interrumpió Merlín No habrá princesas en ninguno de estos castillos. E, incluso si las hubiese, en estos momentos no estáis capacitado para rescatar a ninguna. Tenéis que aprender a salvaros vos primero.Tras la reprimenda, el caballero permaneció en silencio, mientras Merlín continuaba: El primer castillo se llama Silencio; el segundo Conocimiento y el tercero Voluntad y Osadía. Una vez hayáis entrado en ellos, encontraréis la salida sólo cuando hayáis aprendido lo que habéis ido a aprender.Desde el punto de vista del caballero, esto no parecía tan divertido como rescatar princesas. Además, en aquel momento, visitar castillos no era lo que más le apetecía. ¿Por qué no puedo simplemente rodear los castillos? Preguntó malhumorado. Si lo hacéis, os extraviaréis del sendero y seguramente os perderéis. La única manera de llegar a la cima de la montaña es atravesando los castillos dijo Merlín firmemente.El caballero suspiró profundamente mientras contemplaba la empinada y estrecha senda. Desaparecía entre los altos árboles que sobresalían hacia unas nubes bajas. Presintió que este viaje sería mucho más difícil que una cruzada.Merlín sabía lo que el caballero estaba pensando. Sí afirmó es una batalla diferente la que tendréis que librar en el Sendero de la Verdad. La lucha será aprender a amaros. ¿Cómo haré eso? preguntó el caballero. Empezaréis por aprender a conoceros respondió Merlín Esta batalla no se puede ganar con la espada, así que la tendréis que dejar aquí la tierna mirada de Merlín descansó en el caballero por un momento. Luego añadió : Si os encontráis con algo con lo que no podáis lidiar, llamadme, y yo acudiré. ¿Queréis decir que podéis aparecer dondequiera que yo me encuentre? Cualquier mago que se precie lo puede hacer replicó Merlín. Dicho esto desapareció.El caballero quedó asombrado. ¡Pero bueno... si ha desaparecido!Ardilla asintió. A veces realmente la hace buena. Gastaréis toda vuestra energía hablando les riño Rebeca Pongámonos en marcha.El yelmo del caballero emitió un chirrido cuando éste asintió. Partieron con Ardilla al frente y, detrás, el caballero con Rebeca sobre su hombro. De tanto en tanto, Rebeca volaba en misión exploratoria y volvía para informarles de lo que les esperaba más adelante.Después de unas horas, el caballero se derrumbó, exhausto y dolorido. No estaba acostumbrado a viajar sin caballo y con la armadura puesta. Como de todas maneras era casi de noche, Rebeca y Ardilla decidieron parar para dormir.Rebeca voló entre los arbustos y regresó con algunas bayas, que empujó a través de los orificios de la visera del caballero. Ardilla fue a un arroyo cercano y llenó algunas cáscaras de nuez con agua, que el caballero bebió con la pajita que Merlín le había proporcionado. Demasiado agotado como ara esperar a que Ardilla le preparara más nueces, se quedó dormido.A la mañana siguiente le despertó el sol cayendo sobre sus ojos. La luminosidad le molestaba. Su visera nunca había dejado pasar tanta luz. Mientras intentaba entender este fenómeno, se dio cuenta de que Ardilla y Rebeca le estaban observando, al tiempo que parloteaban y arrullaban con excitación. Hizo un esfuerzo por sentarse y, de repente, se dio cuenta de que podía ver mucho más que el día anterior, y que podía sentir la fresca brisa en sus mejillas.¡Una parte de su visera se había roto y se había caído!\"¿Cómo habrá sucedido?\", se preguntó.Ardilla contestó a la pregunta que él no había formulado en voz alta. Se ha oxidado y se ha caído. Pero ¿Cómo? preguntó el caballero. Por las lágrimas que derramasteis después de ver la carta en blanco de vuestro hijo dijo Rebeca.El caballero meditó sobre esto. La pena que había sentido era tan profunda que su armadura no había podido protegerle. Al contrario, sus lágrimas habían comenzado a deshacer el acero que le rodeaba. ¡Esto es! Gritó ¡Las lágrimas de auténticos sentimientos me liberarán de la armadura!Se puso de pie más rápido de lo que había hecho en años. ¡Ardilla! ¡Rebeca! gritó ¡Espabilad! ¡Vamos al Sendero de la Verdad!Rebeca y Ardilla estaban tan llenas de alegría con lo que estaba sucediéndole al caballero que no le dijeron que su rima era malísima. Los tres continuaron la ascensión de la montaña. Era un día muy especial para el caballero. Notó las diminutas partículas iluminadas por el sol que flotaban en el aire, filtrándose a través de las ramas de los árboles. Miró con detenimiento las caras de algunos petirrojos y vio que no eran todas iguales. Le comentó eso a Rebeca, que dio pequeños saltitos, arrullando alegremente. Estáis empezando a ver las diferencias en otras formas de vida porque estáis empezando a ver las diferencias en vuestro interior.El caballero intentó comprender qué quería decir Rebeca exactamente. Era demasiado orgulloso para preguntar, pues todavía pensaba que un caballero tenía que ser más listo que una paloma.En ese preciso momento, Ardilla, que había ido a explorar, regresaba alborotada. El Castillo del Silencio está justo detrás de la próxima subida.Emocionado ante la idea de ver el Castillo, el caballero apuró el paso. Llegó a la cima del monte sin aliento. Era verdad, el castillo se veía a lo lejos, bloqueando el sendero por completo. El caballero les confesó a Ardilla y Rebeca que estaba decepcionado. Había esperado una estructura más elegante. En lugar de eso, el Castillo del Silencio parecía uno más.Rebeca rió y dijo: Cuando aprendáis a aceptar en lugar de esperar, tendréis menos decepciones.El caballero asintió ante la sabiduría de estas palabras. He pasado casi toda mi vida decepcionándome. Recuerdo que, estando en la cuna, pensaba que era el bebé más bonito del mundo. Entonces mi niñera me miró y dijo: \"Tenéis una cara que sólo una madre puede amar\". Me sentí decepcionado por ser feo en lugar de hermoso, y me decepcionó que la niñera fuera tan poco amable. Si realmente os hubierais sentido hermoso, no os hubiera importado lo que ella dijo. No os hubierais sentido decepcionado explicó Ardilla.Esto tenía sentido para el caballero. Estoy empezando a pensar que los animales son más listos que las personas. El hecho de que podáis decir eso os hace tan listo como nosotros replicó Ardilla. No creo que todo esto tenga nada que ver con ser listo dijo Rebeca Los animales aceptan los humanos esperan. Nunca oiréis a un conejo decir: \"Espero que el sol salga esta mañana para poder ir al lago a jugar\". Si el sol no sale, no le estropeará el día al conejo. Es feliz siendo un conejo.El caballero pensó en esto. No recordaba a ninguna persona que fuera feliz simplemente por ser una persona.Al poco rato llegaron a la puerta del enorme castillo. El caballero cogió la llave dorada de su cuello y la introdujo en la cerradura. Y mientras abría la puerta, Rebeca le dijo: Nosotras no iremos contigo.El caballero, que estaba empezando a amar y a confiar en los animales, se sintió decepcionado porque no le acompañaran. Estaba a punto de decirlo, cuando se dio cuenta. Estaba esperando otra vez.Los animales sabían que el caballero dudaba entre entrar o no en el castillo. Os podemos mostrar la puerta dijo Ardilla, pero tendréis que entrar solo.Al alejarse volando, Rebeca le llamó alegremente. Nos encontraremos al otro lado. Abandonado a su suerte, el caballero asomó la cabeza con precaución por la puerta del castillo. Las rodillas te temblaban ligeramente, por lo que producía un ruido metálico a causa de su armadura. Como no quería parecer una gallina frente a una paloma, en caso de que Rebeca pudiera verle, reunió fuerzas y entró valientemente, cerrando la puerta a sus espaldas.Por un momento deseó no haber dejado atrás su espada, pero Merlín le había prometido que no tendría que matar dragones, y el caballero confiaba en el mago.Entró en la enorme antesala del castillo y miró a su alrededor. Sólo vio el fuego que ardía en una enorme chimenea de piedra en uno de los muros y tres alfombras en el suelo. Se sentó en la alfombra más cercana al fuego.El caballero pronto se dio cuenta de dos cosas: primero, parecía no haber ninguna puerta que lo condujera fuera de la habitación, hacia otras áreas del castillo. Segundo, había un extraordinario y aterrador silencio. Se sobresaltó al notar que el fuego ni siquiera chasqueaba. El caballero pensaba que su castillo era silencioso, especialmente en las épocas en que Julieta no le hablaba durante días, pero aquello no era nada comparado con esto. El Castillo del Silencio hacia honor a su nombre, pensó. Jamás en su vida se había sentido tan solo.De repente, el caballero se sobresaltó por el sonido de una voz familiar a sus espaldas. Hola caballero.El caballero se giró y se sorprendió al ver al rey aproximarse desde una esquina lejana de la habitación. ¡Rey! dijo con la voz entrecortada Ni siquiera os había visto. ¿Qué estáis haciendo aquí? Lo mismo que vos, caballero: buscando la puerta.El caballero miró a su alrededor otra vez. No veo ninguna puerta. Uno no puede ver realmente hasta que comprende dijo el Rey Cuando comprendáis lo que hay en esta habitación, podréis ver la puerta que conduce a la siguiente. Definitivamente, eso espero, rey dijo el caballero Me sorprende veros aquí. Había oído que estabais en una cruzada. Eso es lo que dicen siempre que viajo por el Sendero de la Verdad explicó el rey Mis súbditos lo entienden mejor así.El caballero parecía perplejo. Todo el mundo entiende las cruzadas dijo el rey pero muy pocos comprenden la Verdad. Sí asintió el caballero Yo mismo no estaría en este Sendero si no estuviera atrapado en esta armadura. La mayoría de la gente está atrapada en su armadura declaró el rey. ¿Qué queréis decir? preguntó el caballero. Ponemos barreras para protegernos de quienes creemos que somos. Luego un día quedamos atrapados tras las barreras y ya no podemos salir. Nunca pensé que vos estuvierais atrapado, rey. Sois tan sabio... dijo el caballero.El rey soltó una carcajada. Soy lo suficientemente sabio como para saber cuándo estoy atrapado, y también para regresar aquí para aprender más de mí mismo.El caballero estaba entusiasmado, pensando que quizás el rey podría mostrarle el camino. Decidme dijo el caballero, su rostro iluminado ¿podríamos atravesar el castillo juntos? Así no sería tan solitario.El rey negó con la cabeza. Una vez lo intenté. Es verdad que mis compañeros y yo no nos sentíamos solos porque hablábamos constantemente, pero cuando uno habla es imposible ver la puerta de salida de esta habitación. Quizá podríamos limitarnos a caminar juntos, sin hablar sugirió el caballero. No le apetecía mucho tener que caminar solo por el Castillo del Silencio.El rey volvió a negar con la cabeza, esta vez con más fuerza. No, también lo intenté. Hizo que el vacío fuera menos doloroso, pero tampoco pude ver la puerta de salida.El caballero protestó. Pero si no estabais hablando... Permanecer en silencio es algo más que no hablar dijo el rey Descubrí que, cuando estaba con alguien, mostraba sólo mi mejor imagen. No dejaba caer mis barreras, de manera que ni yo ni la otra persona podíamos ver lo que yo intentaba esconder. No lo capto dijo el caballero. Lo comprenderéis replicó el rey cuando hayáis permanecido aquí el tiempo suficiente. Uno debe estar solo para poder dejar caer su armadura.El caballero estaba desesperado. ¡No quiero quedarme aquí solo! exclamó, golpeando el suelo con el pie, y dejándolo caer involuntariamente sobre el pie del rey.El rey gritó de dolor y comenzó a dar saltos.¡El caballero estaba horrorizado! Primero al herrero; ahora al rey. Perdonad, señor dijo, disculpándose.El rey se acarició el pie con suavidad. Oh, bueno. Esa armadura os hace más daño a vos que a mí luego, miró al caballero con expresión sabia . Comprendo que no queráis quedaros solo en el castillo. Yo tampoco deseaba las primeras veces que estuve aquí, pero ahora me doy cuenta de que lo que uno ha de hacer aquí, lo ha de hacer solo Dicho esto, se alejó cojeando al tiempo que decía : Ahora debo irme.Perplejo, el caballero preguntó: ¿A dónde vais? La puerta está por aquí. Esa puerta es sólo de entrada. La puerta que lleva a la siguiente habitación está en la pared más lejana. La vi, por fin, cuando vos entrabais dijo el rey. ¿Qué queréis decir con que por fin la visteis? ¿No recordabais dónde estaba, de las otras veces que estuvisteis aquí? preguntó el caballero, sin comprender por qué el rey continuaba viniendo. Uno nunca acaba de viajar por el Sendero de la Verdad. Cada vez que vengo, a medida que voy comprendiendo cada vez más, encuentro nuevas puertas el rey se despidió con la mano Trataos bien, buen amigo. ¡Aguardad, por favor! le suplicó el caballero.El rey se volvió y le miró con compasión. ¿Sí?El caballero, que no podía hacer que tambalease la resolución del rey, pidió: ¿Hay algún consejo que me podáis dar antes de iros?El rey lo pensó por un momento, luego respondió: Esto es un nuevo tipo de cruzada para vos, querido caballero: una que requiere más coraje que todas las otras batallas que habéis conocido antes. Si lográis reunir las fuerzas necesarias y quedaros para hacer lo que tenéis que hacer aquí será vuestra mayor victoria.Dicho esto, el rey se giró y, estirando el brazo como para abrir una puerta, desapareció en la pared, dejando al caballero mirando con incredulidad.El caballero corrió al sitio donde había estado el rey, esperando que, de cerca, también podría ver la puerta. Al encontrar tan sólo lo que parecía ser una pared sólida, comenzó a caminar por toda la habitación. Lo único que el caballero podía oír era el sonido de su armadura resonando por todo el castillo.Después de un rato, se sentía más deprimido que nunca. Para animarse, cantó un par de canciones de batalla:Estaré contigo para llevarte a una Cruzada, cariño yDondequiera que deje mi yelmo, es mi casa.Las cantó una y otra vez.A medida que su voz se fue cansando, la quietud comenzó a ahogar su canto, envolviéndolo en el silencio más absoluto. Sólo entonces pudo el caballero admitir francamente algo que ya sabía: tenía miedo a estar solo.En ese momento, vio una puerta en la pared más lejana de la habitación. Fue hasta ella, la abrió lentamente y entró en otra habitación. Esta otra sala se parecía mucho a la anterior, sólo que era más pequeña. También ésta estaba vacía de todo sonido.Para pasar el tiempo, el caballero, comenzó a hablar consigo mismo. Decía cualquier cosa que le venía a la mente. Habló de cómo era de pequeño y de qué manera era diferente de los otros niños que conocía. Mientras cazaban codornices y jugaban a \"Ponle la cola al burro\", él se quedaba en casa y leía. Como en aquel entonces los libros eran manuscritos de los monjes, había pocos y, muy pronto, los hubo leído todos. Fue entonces cuando comenzó a hablar con todo aquel que pasaba delante de él. Cuando no había con quién hablar, hablaba consigo mismo, igual que ahora.Se encontró diciendo que había hablado tanto durante toda su vida para evitar sentirse solo.El caballero pensó profundamente sobre esto hasta que el sonido de su propia voz rompió el aterrador silencio. Supongo que siempre he tenido miedo de estar solo.Mientras pronunciaba estas palabras, otra puerta se hizo visible. El caballero la abrió y entró en la siguiente habitación. Era más pequeña aún que la anterior.Se sentó en el suelo y continuó pensando. Al poco rato, le vino el pensamiento de que toda su vida había perdido el tiempo hablando de lo que había hecho y de lo que iba a hacer. Nunca había disfrutado de lo que pasaba en el momento. Y entonces apareció otra puerta. Llevaba a una habitación aún más pequeña que las anteriores.Animado por su progreso, el caballero hizo algo que nunca antes había hecho. Se quedó quieto y escuchó el silencio. Se di cuenta de que, durante la mayor parte de su vida, no había escuchado realmente a nadie ni a nada. El sonido del viento, de la lluvia, el sonido del agua que corre por los arroyos, habían estado siempre ahí, pero en realidad nunca los había oído. Tampoco había oído a Julieta, cuando ella intentaba decirlo cómo se sentía; especialmente cuando estaba triste. Le hacía recordar que él también estaba triste. De hecho, una de las razones por las que había decidido dejarse la armadura puesta todo el tiempo era porque así ahogaba la triste voz de Julieta. Todo lo que tenía que hacer era bajar la visera y ya no la oía. Julieta debía de haberse sentido muy sola hablando con un hombre envuelto en acero; tan sola como él se había sentido en esta lúgubre habitación. Su propio dolor y su soledad afloraron. Comenzó a sentir el dolor y la soledad de Julieta también. Durante años, la había obligado a vivir en un castillo de silencio. Se puso a llorar. El caballero lloró tanto que las lágrimas se derramaron por los agujeros de la visera y empaparon la alfombra que había debajo de él. Las lágrimas fluyeron hacia la chimenea y apagaron el fuego. En realidad, toda la habitación había empezado a inundarse, y el caballero se hubiera ahogado si no fuera porque en ese preciso instante apareció otra puerta.Aunque estaba exhausto por el diluvio, se arrastró hasta la puerta, la abrió y entró en una habitación que no era mucho más grande que el establo de su caballo. Me pregunto por qué las habitaciones son cada vez más pequeñas dijo en voz alta.Una voz replicó: Porque os estáis acercando a vos mismo.Sobresaltado, el caballero miró a su alrededor. Estaba solo, o eso había creído. ¿Quién había hablado? Tú has hablado dijo la voz como respuesta a su pensamiento.La voz parecía venir de dentro de sí mismo. ¿Eso era posible? Sí, es posible respondió la voz Soy tu verdadero yo. Pero si yo soy mi yo verdadero. Protestó el caballero. Mírate pronunció la voz con ligera aversión. Ahí sentado medio muerto, dentro de ese montón de lata, con la visera oxidada y la barba hecha una sopa. Si tú eres tu verdadero yo, ¡los dos estamos con problemas! Ahora óyeme tú a mí dijo el caballero He vivido todos estos años sin oír una palabra sobre ti. Ahora que oigo, lo primero que me dices es que tú eres mi verdadero yo. ¿Por qué no me habías hablado antes? He estado aquí durante años replicó la voz pero ésta es la primera vez que estás lo suficientemente silencioso como para oírme.El caballero dudó. Si tú eres mi verdadero yo, entonces, por favor, dime ¿quién soy yo?La voz replicó amablemente. No puedes pretender aprender todo de golpe. ¿Por qué no te vas a dormir? Está bien dijo el caballero pero antes, quiero saber cómo debo llamarte. ¿Llamarme? preguntó la voz, perpleja Pero si yo soy tú. No puedo llamarte yo. Me confunde. Está bien. Llámame Sam. ¿Por qué Sam? ¿Y por qué no? fue la respuesta.Tienes que conocer a Merlín dijo el caballero, empezando a cabecear de cansancio. Luego se le cerraron los ojos mientras se sumergía en un profundo y dulce sueño.Cuando despertó, no sabía dónde estaba. Tan sólo era consciente de sí mismo. El resto del mundo parecía haberse desvanecido. A medida que se fue despertando, el caballero se fue dando cuenta de que Ardilla y Rebeca estaban sentadas sobre su pecho. ¿Cómo habéis entrado aquí? preguntó.Ardilla rió. No estamos ahí. Vos estáis aquí arrulló Rebeca.El caballero abrió más los ojos y se sentó. Miró a su alrededor sorprendido. Sin lugar a dudas, se encontraba sentado sobre el Sendero de la Verdad, al otro lado del Castillo del Silencio. ¿Cómo salí de allí? preguntó.Rebeca le respondió: De la única manera posible, pensando. Lo último que recuerdo dijo el caballero es que estaba sentado hablando con... Aquí se detuvo. Quería contarles a Rebeca y Ardilla acerca de Sam, pero no era fácil de explicar. Además, podía habérselo imaginado todo. Tenía mucho que pensar. El caballero se rascó la cabeza, pero tardó un momento en darse cuenta de que en realidad estaba rascando su propia piel. Se llevó las dos manos envueltas en acero a la cabeza. ¡Su yelmo había desaparecido! Se tocó la cara y la larga barba ¡Ardilla! ¡Rebeca! gritó. Ya lo sabemos dijeron en un alegre unísono Habéis debido llorar otra vez en el Castillo del Silencio. Lo hice replicó el caballero Pero, ¿cómo puede haberse oxidado todo un yelmo en una noche?Los animales rieron con estrépito. Rebeca yacía sin aliento, dando aletazos contra el suelo. Al caballero le pareció que estaba fuera de sus pajarillos. Exigió que le hicieran saber qué era tan gracioso.Ardilla fue la primera en recuperar el aliento. No estuvisteis sólo una noche en el castillo. Entonces, ¿durante cuánto tiempo? ¿Y si os dijera que mientras estabais ahí dentro pude haber recogido fácilmente más de cinco mil nueces? ¡Diría que estáis loca! exclamó el caballero.Pues permanecisteis en el castillo durante mucho, muchísimo tiempo afirmó Rebeca.El caballero dejó caer la mandíbula incrédulo. Miró hacia el cielo y, con una resonante voz, dijo: Merlín, debo hablar con vos.Como había prometido, el mago apareció inmediatamente. Iba desnudo, a excepción de su larga barba y estaba completamente mojado. Parecía que el caballero le había cogido mientras tomaba un baño. Lamento la intrusión dijo el caballero pero era una urgencia. YO... No hay problema dijo Merlín, interrumpiéndolo Los magos somos molestados a menudo. Se sacudió el agua de la barba Respondiendo a vuestra pregunta, he de deciros que es verdad. Permanecisteis en el Castillo del Silencio por un largo tiempo.Merlín no dejaba de sorprender al caballero. ¿Cómo sabíais lo que quería preguntaros? Como me conozco, puedo conoceros. Somos todos parte el uno del otro.El caballero pensó un momento. Estoy empezando a entender. ¿He podido comprender el dolor de Julieta porque soy parte de ella? Sí respondió Merlín Por eso pudisteis llorar por ella y por vos mismo. Fue la primera vez que derramasteis lágrimas por otra persona.El caballero le dijo a Merlín que se sentía orgulloso. El mago sonrió indulgente. Uno no debe sentirse orgulloso por ser humano. Tiene tan poco sentido como que Rebeca se sintiera orgullosa por poder volar. Rebeca nació con alas. Vos nacisteis con un corazón, y ahora lo estáis utilizando, como es natural. Realmente sabéis cómo desanimar a un amigo, Merlín. No era mi intención ser duro con vos. Lo estáis haciendo bien, de no ser así, no hubierais conocido a Sam. Entonces, ¿lo oí realmente? ¿No fue sólo mi imaginación?Merlín soltó una risita ahogada. No, Sam es real. De hecho, es un yo más real que el que habéis estado llamando yo durante estos años. No os estáis volviendo loco. Simplemente, estáis empezando a oír a vuestro yo verdadero. Por esta razón el tiempo transcurrió sin que os dierais cuenta. No lo comprendo dijo el caballero. Comprenderéis cuando hayáis pasado por el Castillo del Conocimiento.Antes de que el caballero pudiera hacer más preguntas, Merlín desapareció. El caballero, Ardilla y Rebeca continuaron el viaje por el Sendero de la Verdad, en dirección al Castillo del Conocimiento. Se detuvieron tan sólo dos veces ese día, una para comer y otra para que el caballero afeitara su escuálida barba y cortara su largo cabello con el borde afilado del guantelete. Una vez hecho esto, el caballero tuvo mejor aspecto y se sintió mucho mejor, más libre que antes. Sin el yelmo podía comer nueces sin la ayuda de Ardilla. Aunque había apreciado la técnica salvavidas, no consideraba que aquello fuera un modo de vida realmente elegante. Se podía alimentar también de frutas y raíces a las que se había acostumbrado. Nunca más comería paloma ni ninguna otra ave o carne, pues se daba cuenta que hacerlo sería, literalmente, como comerse a sus amigos.Justo antes de caer la noche, el trío continuó caminando penosamente por un monte y contempló el Castillo del Conocimiento en la distancia. Era más grande que el Castillo del Silencio, y la puerta era de oro sólido. Era el castillo más grande que el caballero hubiera visto jamás, incluso más grande que el que el caballero se había construido. El caballero contempló la impresionante estructura y se preguntó quién lo habría diseñado.En ese preciso momento, sus pensamientos fueron interrumpidos por la voz de Sam. El Castillo del Conocimiento fue diseñado por el propio universo: la fuente de todo conocimiento.El caballero se sintió sorprendido y a la vez complacido de volver a oír la voz de Sam. Me alegro que hayas vuelto dijo En realidad, nunca me fui replicó Sam recuerda que yo soy tú. Por favor, no quiero volver a oír eso. ¿Qué te parezco ahora que me he afeitado y me he cortado el pelo? Es la primera vez que sacas provecho de ser esquilado replicó Sam.El caballero rió con la broma de Sam. Le gustaba su sentido del humor. Si el Castillo del Conocimiento se asemejaba al Castillo del Silencio, estaría feliz de tener a Sam por compañía.El caballero, Rebeca y Ardilla cruzaron el puente levadizo por encima del foso y se detuvieron ante la dorada puerta. El caballero cogió la llave que colgaba de su cuello e hizo girar la cerradura. Al abrir la puerta, le preguntó a Rebeca y a Ardilla si se irían como lo habían hecho en el Castillo del Silencio. No replicó Ardilla El silencio es para uno; el conocimiento es para todos.El caballero se preguntó cómo era posible que se considerara a una paloma un blanco fácil.Los tres atravesaron la puerta y penetraron en una oscuridad tan densa que el caballero no podía ver ni su propia mano. El caballero buscó a tientas las acostumbradas antorchas que suelen estar en la entrada de los castillos, pero no había ninguna. ¿Un castillo con puerta de oro y sin antorchas? Incluso los castillos de la zona barata tienen antorchas refunfuñó el caballero al tiempo que Ardilla lo llamaba.El caballero tanteó el camino hasta donde se encontraba ella y vio que estaba señalando una inscripción que brillaba en la pared. Ponía: El conocimiento es la luz que iluminará vuestro camino.\"Prefería una antorcha\", pensó el caballero, ¡quien quiera que sea el que gestiona este castillo, está decidido a reducir las facturas de la luz!Sam habló: Significa que cuantas más cosas sepas, más luz habrá en el interior del castillo. ¡Apuesto a que tienes razón, Sam! exclamó el caballero. Y un rayo de luz se filtró en la habitación.En ese preciso momento, Ardilla volvió a llamar al caballero para que se reuniera con ella. Había encontrado otra brillante inscripción grabada en la pared:¿Habéis confundido la necesidad con el amor?Todavía perturbado, el caballero masculló: Supongo que tengo que encontrar la respuesta para conseguir un poco más de luz. Lo estas cogiendo rápidamente replicó Sam, a lo que el caballero respondió bufando: No tengo tiempo para jugar a Preguntas y Respuestas. ¡Quiero encontrar mi camino por el castillo para poder llegar pronto a la cima de la montaña! Tal vez lo que tengáis que aprender aquí sea que tenéis todo el tiempo del mundo sugirió Rebeca.El caballero no estaba de un ánimo muy receptivo y no tenía ganas de oír su filosofía. Por un momento consideró la posibilidad de internarse en la oscuridad del castillo e intentar atravesarlo. La negrura, sin embargo, era bastante intimidatoria y, sin su espada, se sentía temeroso. Le pareció que la única alternativa que le quedaba era intentar descifrar el significado de la inscripción. Suspiró y se sentó ante ella. La leyó otra vez;\"¿Habéis confundido la necesidad con el amor?\"El caballero sabía que amaba a Julieta y a Cristóbal, aunque tenía que admitir que había amado más a Julieta antes de que le diera por ponerse bajo los toneles de vino y vaciar su contenido en su boca.Sam dijo: Sí, amabais a Julieta y a Cristóbal, pero, ¿no los necesitabais también? Supongo que sí admitió el caballero.Había necesitado toda la belleza que Julieta le añadía a su vida con su inteligencia y su encantadora poesía. También había necesitado las cosas agradables que ella solía hacer, como invitar amigos para que lo animaran, después de que se quedara atrapado en su armadura.Se acordó de las épocas en las que el asunto de la caballería había estado bajo mínimos y no se podían permitir comprar ropa nueva o contratar sirvientes. Julieta había confeccionado hermosos vestidos para la familia y había preparado deliciosos platos para el caballero y sus amigos. El caballero reconoció que Julieta había mantenido siempre el castillo muy limpio. Y él le había dado muchos castillos para limpiar. A menudo habían tenido que mudarse a un castillo más barato cuando él había regresado de las cruzadas sin un chavo. Había dejado que Julieta hiciera casi todas las mudanzas ella sola, pues él solía estar siempre en algún torneo. Recordó su aspecto agotado mientras llevaba sus pertenencias de un castillo a otro, y cómo se había puesto cuando se vio imposibilitada de tocarlo a causa de la armadura. ¿No fue entonces cuando Julieta comenzó a ponerse bajo los toneles de vino? preguntó Sam suavemente.El caballero asintió, y las lágrimas brotaron de sus ojos. Después, se le ocurrió algo espantoso: no había querido culparse de las cosas que hacía. Había preferido culpar a Julieta por todo el vino que bebía. De hecho, le venía bien que ella bebiera, así podía decir que todo era por su culpa, incluyendo el hecho de que él estuviera atrapado en la armadura.A medida que el caballero se iba dando cuenta de lo injusto que había sido con Julieta, las lágrimas iban cayendo por sus mejillas. Si, la había necesitado más de lo que la había amado. Deseó haberla necesitado menos y amado más, pero no había sabido cómo hacerlo.Mientras continuaba llorando, le vino a la cabeza que también había necesitado a Cristóbal más de lo que le había amado. Un caballero necesitaba un hijo para que partiera a las batallas y luchara en nombre de su padre cuando éste se hiciera mayor. Esto no quería decir que el caballero no amara a Cristóbal, pues amaba la belleza de su hijo. También disfrutaba oyéndole decir: \"¡Te quiero papá!”, pero, así como había amado estas cosas de Cristóbal, también respondían a una necesidad suya.Un pensamiento le vino a la mente como un relámpago: ¡Había necesitado el amor de Julieta y Cristóbal porque no se amaba a sí mismo! De hecho, había necesitado el amor de todas las damiselas que había rescatado y de toda la gente por la que había luchado en las cruzadas porque no se amaba a sí mismo.El caballero lloró aún más al darse cuenta de que si no se amaba, no podía amar realmente a otros. Su necesidad de ellos se interpondría.Al admitir esto, una hermosa y resplandeciente luz brilló a su alrededor, ahí donde antes había habido oscuridad. Una mano se posó suavemente sobre su hombro. Miró a través de sus lágrimas y vio a Merlín que le sonreía. Habéis descubierto una gran verdad le dijo el mago al caballero Sólo podéis amar a otros en la medida en que os amáis a vos mismo. ¿Y cómo hago para empezar a amarme? preguntó el caballero. Ya habéis empezado, al saber lo que ahora sabéis dijo Merlín. Sé que soy un tonto sollozó el caballero. No, conocéis la verdad, y la verdad es amor.Esto consoló al caballero, que dejó de llorar. A medida que sus lágrimas se fueron secando, fue notando la luz que había a su alrededor. Era distinta de cualquier luz que hubiera visto antes.Parecía no venir de ningún lugar, y de todos los lugares a la vez.Merlín hizo eco del pensamiento del caballero: No ha nada más hermoso que la luz del conocimiento.El caballero miró la luz que le rodeaba y luego hacia la lejana oscuridad. Para vos no hay oscuridad en este castillo, ¿no es verdad? No replicó Merlín Ya no.Animado, el caballero se puso de pie, listo para continuar. Le agradeció a Merlín por haber aparecido incluso sin haber sido llamado. Está bien dijo el mago Uno no siempre sabe cuándo pedir ayuda.Y, dicho esto, desapareció.Cuando el caballero se dispuso a continuar, Rebeca apareció volando desde la oscuridad. ¡Escuchad! dijo toda emocionada ¡Esperad a ver lo que voy a mostraros!El caballero nunca había visto a Rebeca tan excitada. Normalmente, era más bien tranquila, pero ahora no dejaba de dar saltos sobre su hombro, sin poder contenerse mientras guiaba al caballero y a Ardilla hacia un gran espejo. ¡Es eso! ¡Es eso! gorjeó en voz alta, los ojos brillando de entusiasmo.El caballero tuvo una decepción. Es sólo un viejo espejo dijo impaciente Vamos, pongámonos en marcha. No es un espejo corriente insistió rebeca No refleja tu aspecto. Refleja cómo eres de verdad.El caballero estaba intrigado, pero no entusiasmado. Nunca le habían importado mucho los espejos porque nunca se había considerado muy guapo. Pero Rebeca insistió, así que, de mala gana, se colocó ante el espejo y contempló su reflejo. Para su gran sorpresa, en lugar de un hombre alto con ojos tristes y nariz grande, con una armadura hasta el cuello, vio a una persona encantadora y vital, cuyos ojos brillaban con amor y compasión. ¿Quién es? preguntóArdilla respondió: Sois vos. Este espejo es un fantasma dijo el caballero Yo no soy así. Estáis viendo a vuestro yo verdadero explicó Sam el yo que vive bajo esa armadura. Pero protestó el caballero, contemplándose con atención en el espejo ese hombre es un espécimen perfecto. Y su rostro está lleno de inocencia y de belleza. Ése es su potencial le respondió Sam ser hermoso, inocente y perfecto. Si ése es mi potencial dijo el caballero algo terrible sucedió en el camino. Sí replicó Sam pusiste una armadura invisible entre tú y tus verdaderos sentimientos. Ha estado ahí durante tanto tiempo que se ha hecho visible y permanente. Quizá sí escondí mis sentimientos dijo el caballero Pero no podía decir simplemente todo lo que se me pasaba por la cabeza y hacer todo lo que me apetecía. Nadie me hubiera querido. El caballero se detuvo al pronunciar estas palabras, pues se dio cuenta que se había pasado la vida intentando agradar a la gente. Pensó en todas las cruzadas en las que había luchado, los dragones que había matado, y en las damiselas en apuros que había rescatado: todo para demostrar que era bueno, generoso y amoroso. En realidad, no tenía que demostrar nada. Era bueno, generoso y amoroso. ¡Jabalinas saltarinas! exclamó ¡He desperdiciado toda mi vida! NO dijo Sam, rápidamente No la has desperdiciado. Necesitabas tiempo para aprender todo lo que has aprendido. Todavía tengo ganas de llorar dijo el caballero. Pues, eso sí sería un desperdicio dijo Sam. Acto seguido, entonó esta canción.\"Las lágrimas de autocompasión no te pueden ayudar. No son del tipo que a tu armadura puedan eliminar\"El caballero no estaba de humor para apreciar ni la canción ni el humor de Sam. Deja ya esas pesadas rimas, o te echaré fuera chilló. No me puedes echar rió Sam Yo soy tú. ¿No lo recuerdas?En ese momento, el caballero se hubiera pegado un tiro gustoso con tal de librarse de Sam, más, por fortuna, aún no habían inventado las armas de fuego. Aparentemente, no había manera de librarse de Sam.El caballero se miró al espejo otra vez. La amabilidad, la compasión, el amor, la inteligencia y la generosidad le devolvieron la mirada. Se dio cuenta de que todo lo que tenía que hacer para tener todas esas cualidades era reclamarlas, pues siempre habían estado ahí.Ante este pensamiento, la hermosa luz brilló una vez más, con más fuerza que antes. Iluminó toda la habitación revelando, para sorpresa del caballero, que el castillo tenía tan sólo una gigantesca habitación. Es la construcción estándar para un Castillo del Conocimiento dijo Sam. El verdadero Conocimiento no se divide en compartimientos porque todo procede de una única verdad.El caballero asintió. Estaba listo para partir justo cuando Ardilla se acercó corriendo. Este castillo tiene un patio con un gran manzano en el centro. Oh, llévame a él pidió el caballero ansioso, pues empezaba a tener hambre.El caballero y Rebeca siguieron a Ardilla hasta el patio. Las robustas ramas del árbol se torcían por el peso de las manzanas más brillantes y rojas que el caballero hubiera visto jamás. ¿Te gustan las manzanas? preguntó Sam.El caballero se encontró riendo. Luego notó una inscripción grabada en una losa junto al árbol:Por esta fruta impongo condición,pero ahora aprenderéis acerca de la ambición.El caballero reflexionó sobre esto pero, con franqueza, no tenía ni idea de lo que significaba. Finalmente, decidió olvidarlo. Si lo haces, no saldremos de aquí dijo Sam.El caballero gruñó. Estas inscripciones son cada vez más difíciles de entender. Nadie dijo que el Castillo del Conocimiento fuera fácil dijo Sam con firmeza.El caballero suspiró, cogió una manzana y se sentó bajo el árbol con Rebeca y Ardilla. ¿Vosotras lo entendéis? les preguntó.Ardilla negó con la cabeza.El caballero miró a Rebeca, que también negó con la cabeza. Pero lo que sí se dijo pensativa es que no tengo ninguna ambición. Ni yo intervino Ardilla y apuesto a que este árbol tampoco tiene ninguna. Tiene razón dijo Rebeca Este árbol es como nosotras. No tiene ambiciones. Quizá vos no necesitéis ninguna. Esto está bien para los animales y los árboles dijo el caballero Pero ¿qué sería una persona si no tiene ambición? Feliz dijo Sam No, no lo creo. Todos estáis en lo cierto dijo una voz familiar.El caballero se volvió y vio a Merlín de pie, detrás de él y los animales. El mago vestía su larga túnica blanca y llevaba un laúd. Estaba a punto de llamaros, Merlín dijo el caballero. Lo sé replicó el mago Todo el mundo necesita ayuda para entender a un árbol. Los árboles son felices simplemente siendo árboles, al igual que Rebeca y Ardilla son felices siendo simplemente lo que son. Pero los humanos somos distintos protestó el caballero tenemos mentes. Nosotros también tenemos mentes declaró Ardilla, un tanto ofendida. Lo siento. Es sólo que los seres humanos tenemos mentes más complicadas que hacen que deseemos ser mejores explicó el caballero. ¿Mejores que qué? preguntó Merlín, tañendo ociosamente unas notas en su laúd. Mejores de lo que somos respondió el caballero. Nacéis hermosos, inocentes y perfectos. ¿Qué podría ser mejor que eso? demandó Merlín. No, quiero decir que queremos ser mejores de lo que pensamos que somos, y mejores que los demás... ya sabéis, como yo, que siempre he querido ser el mejor caballero del reino. Ah, sí admitió Merlín la ambición de vuestra complicada mente os llevó a intentar demostrar que erais mejor que otros caballeros. ¿Y qué hay de malo en ello? preguntó el caballero a la defensiva. ¿Cómo podríais ser mejor que otros caballeros si todos nacisteis tan inocentes y perfectos como erais? Al menos era feliz intentándolo replicó el caballero. ¿Lo erais? ¿0 es que estabais tan ocupado intentando serlo que no podíais disfrutar del simple hecho de ser? Me estáis confundiendo musitó el caballero Sé que las personas necesitan tener ambición. Desean ser listas y tener bonitos castillos y poder cambiar el caballo del año pasado por uno nuevo. Quieren progresar. Ahora estáis hablando del deseo del hombre de enriquecerse; pero si una persona es generosa, amorosa, compasiva, inteligente y altruista, ¿cómo podría ser más rica? Esas riquezas no sirven para comprar castillos y caballos dijo el caballero.Es verdad Merlín esbozó una sonrisa hay más de un tipo de riquezas, así como hay más de un tipo de ambición. A mí me parece que la ambición es la ambición. 0 deseas progresar o no lo deseas. Es más complicado todo eso respondió el mago La ambición que proviene de la mente te puede servir para conseguir bonitos castillos y buenos caballos. Sin embargo, sólo la ambición que proviene del corazón puede darte, además, la felicidad. ¿Qué es la ambición del corazón? le cuestionó el caballero. La ambición del corazón es pura. No compite con nadie y no hace daño a nadie. De hecho, le sirve a uno de tal manera que sirve a otros al mismo tiempo. ¿Cómo? preguntó el caballero, esforzándose por comprender. Es aquí donde podemos aprender del manzano. Se ha convertido en un árbol hermoso y maduro, que da generosamente sus frutos a todos. Cuantas más manzanas coge más gente dijo Merlín más crece el árbol y más hermoso deviene. Este árbol hace exactamente lo que un manzano debe hacer: desarrollar su potencial para beneficio de todos. Lo mismo sucede con las personas que tienen ambiciones del corazón. Pero objetó el caballero si me pasara el día regalando manzanas, no podría tener un elegante castillo y no podría cambiar el caballo del año pasado por uno nuevo. Vos, como la mayoría de la gente, queréis poseer muchas cosas bonitas, pero es necesario separar la necesidad de la codicia. Decidle eso a una esposa que quiere un castillo en un mejor barrio replicó mordaz el caballero.Una expresión divertida se dibujó en el rostro de Merlín. Podríais vender algunas de vuestras manzanas para pagar el castillo y el caballo. Después podríais dar las manzanas que no necesitarais para que los demás se alimentasen. Este mundo es más fácil para los árboles que para las personas dijo el caballero filosóficamente. Es una cuestión de percepción dijo Merlín Recibís la misma energía vital que el árbol. Utilizáis la misma agua, el mismo aire y la misma nutrición de la tierra. Os aseguro que si aprendéis del árbol podréis dar frutos y no tardaréis en tener todos los caballos y castillos que deseáis. ¿Queréis decir que podría conseguir todo lo que necesito simplemente quedándome quieto en mi propio jardín? preguntó el caballero.Merlín rió. A los seres humanos se les dio dos pies para que no tuvieran que permanecer en un mismo lugar, pero si se quedaran quietos más a menudo para poder aceptar y apreciar, en lugar de ir de aquí para allá intentando apoderarse de todo lo que pueden, entenderían verdaderamente lo que es la ambición del corazón.El caballero permaneció en silencio, reflexionando sobre las palabras de Merlín. Estudió el manzano que florecía ante sus ojos. Observó a Ardilla, a Rebeca y a Merlín. Ni el árbol ni los animales tenían ambición, y la ambición de Merlín provenía sin duda de su corazón. Todos permanecían sanos y felices; eran hermosos especímenes de la vida.Después pensó en sí mismo: escuálido y con una barba que empezaba a tener mal aspecto. Estaba malnutrido, nervioso, y exhausto por tener que arrastrar su pesada armadura. Había adquirido todo esto por su ambición mental, y ahora comprendía que todo eso debía cambiar. La idea le inspiraba temor, pero luego pensó que ya lo había perdido todo, así que ¿qué más podía perder? A partir de este momento, mis ambiciones vendrán del corazón prometió el caballero.Mientras pronunciaba estas palabras, el castillo y Merlín desaparecieron, y el caballero se encontró otra vez en el Sendero de la Verdad, con Rebeca y Ardilla. Junto al sendero se extendía un cabrilleante arroyo. Sediento, se arrodilló para beber de su agua y notó con sorpresa que la armadura que cubría sus brazos y piernas se había oxidado y caído. Su barba había crecido. Era evidente que el Castillo del Conocimiento, al igual que el Castillo del Silencio, había jugado con el tiempo.El caballero reflexionó sobre este extraño fenómeno y no tardó en darse cuenta de que Merlín estaba en lo cierto. Decidió que era verdad que el tiempo transcurría con rapidez cuando uno se escuchaba a sí mismo. Recordó cuántas veces el tiempo se había hecho eterno mientras él esperaba que otras personas lo llenaran.Ahora que todo lo que quedaba de su armadura era el peto, el caballero se sintió más ligero y más joven de lo que se había sentido en años. También descubrió que no se había sentido tan bien consigo mismo desde hacía mucho tiempo. Con el paso firme de un muchacho, partió hacia el Castillo de la Voluntad y la Osadía con Rebeca volando sobre su cabeza y Ardilla corriendo a sus pies. Hacia el amanecer del día siguiente, el inverosímil trío llegó al último castillo. Era más alto que los otros y sus muros parecían más gruesos. Confiado de que atravesaría velozmente este castillo, el caballero cruzó el puente levadizo con los animales.Cuando estaban a medio camino se abrió de golpe la puerta del castillo y un enorme y amenazador dragón, cubierto de relucientes escamas verdes, surgió de su interior, echando fuego por la boca. Espantado, el caballero se paró en seco.Había visto muchos dragones, pero éste no se parecía a ninguno. Era enorme, y las llamas salían no sólo de su boca, como sucedía con cualquier dragón común y corriente, sino también de sus ojos y oídos. Y, por si eso fuera poco, las llamas eran azules, lo cual quería decir que este dragón tenía un alto contenido de butano.El caballero buscó su espada, pero su mano no encontró nada. Comenzó a temblar. Con una voz débil e irreconocible, el caballero pidió ayuda a Merlín, más, para su desesperación, el mago no apareció. ¿Por qué no viene? preguntó ansiosamente, al tiempo que esquivaba una llamarada azul del monstruo. No lo sé replicó Ardilla Normalmente se puede contar con él.Rebeca, sentada sobre el hombre del caballero, ladeó la cabeza y escuchó con atención. Por lo que he podido captar, Merlín está en París, asistiendo a una conferencia sobre magos.\"No me puede abandonar ahora\", se dijo el caballero. \"Me prometió que no habría dragones en el Sendero de la Verdad\" Se refería a dragones comunes y corrientes rugió el monstruo con una voz que hizo temblar los árboles y que por poco hizo caer a Rebeca del hombro del caballero.La situación parecía seria. Un dragón que podía leer las mentes era definitivamente lo peor que se podía esperar pero, de alguna manera, el caballero logró dejar de temblar. Con la voz más fuerte y potente que pudo, gritó: ¡Fuera de mi camino, bombona de butano gigante!La bestia bufó, lanzando fuego en todas direcciones. Caramba, ¡qué atrevido el gatito asustado!El caballero, que no sabía que más hacer, intentó ganar tiempo. ¿Qué haces en el Castillo de la voluntad y la Osadía? preguntó. ¿Hay algún sitio mejor donde yo pueda vivir? Soy el Dragón del Miedo y la Duda.El caballero reconoció que el nombre era muy acertado. Miedo y duda era exactamente lo que sentía.El dragón volvió a vociferar: Estoy aquí para acabar con todos los listillos que piensan que pueden derrotar a cualquiera simplemente porque han pasado por el Castillo del Conocimiento.Rebeca susurró al oído del caballero: Merlín dijo una vez que el conocimiento de uno mismo podía matar al Dragón del Miedo y la Duda. ¿Y tú lo crees? susurró al caballero. Sí afirmó Rebeca con firmeza. ¡Pues, entonces, encárgate tú de ese lanzallamas verde! El caballero dio media vuelta y cruzó el puente levadizo corriendo, en retirada. ¡Jo,jo,jo! rió el dragón, y con su último \"jo\" por poco quema los pantalones del caballero. ¿Os retiráis después de haber llegado tan lejos? preguntó Ardilla, mientras el caballero se sacudía las chispas de la espalda. No lo sé replicó él He llegado a habituarme a ciertos lujos, como vivir. San intervino. ¿Cómo te soportas si no tienes la voluntad y la osadía de poner a prueba el conocimiento que tienes de ti mismo? ¿Tú también crees que el conocimiento de uno mismo puede matar al Dragón del Miedo y la Duda? preguntó el caballero. Por supuesto. El conocimiento de uno mismo es la verdad y ya sabes lo que dicen: \"la verdad es más poderosa que la espada\". Ya sé que eso es lo que se dice, pero ¿hay alguien que lo haya probado y haya sobrevivido? preguntó sutilmente el caballero.Tan pronto como acabó de pronunciar estas palabras, el caballero recordó que no necesitaba probar nada. Era bueno, generoso y amoroso. Por lo tanto, no debía sentir ni miedo ni dudas. El dragón no era más que una ilusión.El caballero dirigió la mirada a través del puente hacia donde se encontraba el monstruo lanzando fuego hacia unos arbustos, por lo visto para no perder la práctica. Con el pensamiento en la mente de que el dragón sólo existía si él creía que existía, el caballero inspiró profundamente y, con lentitud, volvió a atravesar el puente levadizo.El dragón, por supuesto, fue a su encuentro, bufando y echando fuego. Esta vez, sin embargo, el caballero siguió adelante. Pero el coraje del caballero no tardó en comenzar a derretirse, al igual que su barba, con el calor de las llamaradas del dragón. Con un grito de temor y angustia, dio media vuelta y salió corriendo.El dragón dejó escapar una poderosa carcajada y disparó un chorro de fuego contra el caballero en retirada. Con un aullido de dolor, el caballero atravesó el puente como una bala, con Rebeca y Ardilla tras él. Al divisar un pequeño arroyo, sumergió rápidamente su chamuscado trasero en el agua fresca, sofocando las llamas en el acto.Ardilla y Rebeca intentaban consolarlo desde la orilla. Habéis sido muy valiente dijo Ardilla. No está mal por tratarse del primer intento añadió Rebeca.Sorprendido, el caballero la miró desde donde estaba. ¿Cómo que el primer intento?Ardilla le respondió con toda naturalidad: Tendréis más suerte la segunda vezEl caballero respondió enfadado: Tú irás la segunda vez. Recordad que el dragón es sólo una ilusión dijo Rebeca. ¿Y el fuego que sale de su boca? ¿Eso también es una ilusión? En efecto respondió Rebeca el fuego también era una ilusión. Entonces, ¿cómo es que estoy sentado en este arroyo con el trasero quemado? exigió el caballero. Porque vos mismo hicisteis que el fuego fuera real, le dais el poder de quemar vuestro trasero o cualquier otra cosa dijo Ardilla. Tienes razón corroboró Sam Debes regresar y enfrentarte al dragón de una vez por todas.El caballero se sintió acorralado. Eran tres contra uno. 0, mejor dicho, dos y medio contra uno; la mitad Sam del caballero estaba de acuerdo con Ardilla y Rebeca, mientras que la otra mitad quería permanecer en el arroyo.Mientras el caballero luchaba contra un coraje que flaqueaba, oyó a Sam decir: Dios le dio coraje al hombre. El hombre da coraje a Dios. Estoy harto de intentar comprender el significado de las cosas. Prefiero quedarme sentado en el arroyo y descansar. Mira lo animó Sam si te enfrentas al dragón, hay una posibilidad de que lo elimines, pero si no te enfrentas a él, es seguro que él te destruir). Las decisiones son fáciles cuando sólo hay una alternativa dijo el caballero. Se puso en pie de mala gana, inspiró profundamente y cruzó el puente levadizo una vez más.El dragón le miró incrédulo. Era un tipo verdaderamente terco ¿Otra vez? bufó Bueno, esta vez sí que te pienso quemar.Pero esta vez el caballero que marchaba hacia el dragón era otro; uno que cantaba una y otra vez: \"el miedo y la duda son ilusiones\".El dragón lanzó gigantescas llamaradas contra el caballero una y otra vez pero, por más que lo intentaba, no lograba hacerlo arder.A medida que el caballero se iba acercando, el dragón se iba haciendo cada vez más pequeño, hasta que alcanzó el tamaño de una rana. Una vez extinguida su llama, el dragón comenzó a lanzar semillas. Estas semillas las Semillas de la Duda tampoco lograron detener al caballero. El dragón se iba haciendo aún más pequeño a medida que continuaba avanzando con determinación. ¡He vencido! exclamó el caballero victorioso.El dragón apenas podía hablar. Quizás esta vez, pero regresaré una y otra vez para bloquear tu camino.Dicho esto, desapareció con una explosión de humo azul. Regresa siempre que quieras le gritó el caballero Cada vez que lo hagas, yo seré más fuerte y tú más débil.Rebeca voló y aterrizó en el hombro del caballero. Lo veis, yo tenía razón. El conocimiento de uno mismo puede matar al Dragón del Miedo y la Duda. Si realmente creías que era sí, ¿por qué no me acompañaste cuando me acerqué al dragón? preguntó el caballero, que ya no se sentía inferior a su amiga emplumada.Rebeca mulló sus plumas. No quería interferir. Era vuestro viaje.Divertido, el caballero estiró el brazo para abrir la puerta del castillo, pero ¡el Castillo de la Voluntad y la Osadía había desaparecido!Sam le explicó: No tienes que aprender sobre la voluntad y la osadía porque acabas de demostrar que ya la posees.El caballero echó la cabeza hacia atrás, riendo de pura alegría. Podía ver la cima de la montaña. El sendero parecía aún más empinado que antes, pero no importaba.Sabía que ya nada le podía detener. Centímetro a centímetro, palmo a palmo, el caballero escaló, con los dedos ensangrentados por tener que aferrarse a las afiladas rocas. Cuando ya casi había llegado a la cima, se encontró con un canto rodado que bloqueaba su camino. Como siempre, había una inscripción sobre él: aunque este Universo poseo, nada poseo, pues no puedo conocer lo desconocido si me aferro a lo conocido.El caballero se sentía demasiado exhausto para superar el último obstáculo. Parecía imposible descifrar la inscripción y estar colgado de la pared de la montaña al mismo tiempo, pero sabía que debía intentarlo.Ardilla y Rebeca se sintieron tentadas de ayudarle, pero se contuvieron, pues sabían que a veces la ayuda puede debilitar a un ser humano.El caballero inspiró profundamente, lo que le aclaró un poco la mente. Leyó la última parte de la inscripción en voz alta: \"Pues no puedo conocer lo desconocido si me aferro a lo conocido\".El caballero reflexionó sobre algunas de las cosas \"conocidas\" a las que se había aferrado durante toda su vida. Estaba su identidad quién creía que era y que no era Estaban sus creencias aquello que él pensaba que era verdad y lo que consideraba falso Y estaban sus juicios las cosas que tenía por buenas y aquellas que consideraba malas.El caballero observó la roca y un pensamiento terrible cruzó por su mente: también conocía la roca a la cual se aferraba para seguir con vida. ¿Quería decir la inscripción que debía soltarse y dejarse caer al abismo de lo desconocido? Lo has cogido caballero, dijo Sam Tienes que soltarte. ¿Qué intentas hacer, matarnos a los dos? Gritó el caballero. De hecho, ya estamos muriendo ahora mismo dijo Sam Mírate. Estás tan delgado que podrías deslizarte por debajo de una puerta, y estás lleno de estrés y miedo. No estoy tan asustado como antes dijo el caballero. En ese caso, déjate ir y confía . Dijo Sam ¿Qué confíe en quién? replicó el caballero enfadado. Estaba harto de la filosofía de Sam. No es un quién respondió Sam ¡No es un quién sino un qué! ¿Un qué? preguntó el caballero. Sí dijo Sam La vida, la fuerza, el universo, Dios, como quieras llamarlo.El caballero miró por encima de su hombro y vio el abismo aparentemente infinito que había debajo de él. Déjate ir le susurró Sam con urgencia.El caballero no parecía tener alternativa. Perdía fuerza en cada segundo que pasaba y la sangre brotaba de sus dedos allí donde se aferraban a la roca. Pensando que moriría, se dejó ir y se precipitó al abismo, a la profundidad infinita de sus recuerdos.Recordó todas las cosas de su vida de las que había culpado a su madre, a su padre, a sus profesores, a su mujer, a su hijo, a sus amigos y a todos los demás. A medida que caía en el vacío, fue desprendiéndose de todos los juicios que había hecho contra ellos.Fue cayendo cada vez más rápidamente, vertiginosamente, mientras su mente descendía hacia su corazón. Luego, por primera vez en su vida, contempló su vida con claridad, sin juzgar y sin excusarse. En ese instante, aceptó toda la responsabilidad por su vida, por la influencia que la gente tenía sobre ella, y por los acontecimientos que le habían dado forma.A partir de ese momento, fuera de sí mismo, nunca más culparía a nada ni a nadie de todos los errores y desgracias. El reconocimiento de que él era la causa, no el efecto, le dio una nueva sensación de poder. Ya no tenía miedo.Le sobrevino una desconocida sensación de calma y algo muy extraño le sucedió: ¡empezó a caer hacia arriba! ¡Sí, parecía imposible, pero caía hacia arriba, surgiendo del abismo! Al mismo tiempo, se seguía sintiendo conectado con lo más profundo de él, con el centro de la Tierra. Continuó cayendo hacia arriba, sabiendo que estaba unido al cielo y la Tierra.Repentinamente, dejó de caer y se encontró de pie en la cima de la montaña y comprendió el significado de la inscripción de la roca. Había soltado todo aquello que había temido y todo aquello que había sabido y poseído. Su voluntad de abarcar lo desconocido le había liberado. Ahora el universo era suyo, para ser experimentado y disfrutado.El caballero permaneció en la cima, respirando profundamente y le sobrevino una sobrecogedora sensación de bienestar. Se sintió mareado por el encantamiento de ver, oír y sentir el universo que le rodeaba. Antes, el temor a lo desconocido había entumecido sus sentidos, pero ahora podía experimentar todo con una claridad sorprendente. La calidez del sol del atardecer, la melodía de la suave brisa de la montaña y la belleza de las formas y los colores de la naturaleza que pintaban el paisaje, causaron un placer indescriptible al caballero. Su corazón rebosaba de amor: por sí mismo, por Julieta y Cristóbal, por Merlín, por Ardilla y por Rebeca, por la vida y por todo el maravilloso mundo.Rebeca y Ardilla observaron al caballero ponerse de rodillas, con lágrimas de gratitud surgiendo de sus ojos.\"Casi muero por todas las lágrimas que no derramé\", pensó. Las lágrimas resbalaban por sus mejillas, por su barba y por su peto. Como provenían de su corazón, estaban extraordinariamente calientes, de manera que no tardaron en derretir lo que quedaba de su armadura.El caballero lloraba de alegría. No volvería a ponerse la armadura y cabalgar en todas direcciones nunca más. Nunca más vería la gente el brillante reflejo del acero, pensando que el sol estaba saliendo por el norte o poniéndose por el oeste.Sonrió a través de sus lágrimas, ajeno a que una nueva y radiante luz irradiaba de él; una luz mucho más brillante y hermosa que la de su pulida armadura, una luz destellante como un arroyo, resplandeciente como la luna, deslumbrante como el sol.Porque ahora el caballero era el arroyo.Era la luna. Era el sol.Podía ser todas las cosas a la vez, Y más, porque era uno con el universo.Era amor.F I N El caballero de la armadura oxidadaRobert FisherCapítulo 1El dilema del caballeroCapítulo 1El dilema del caballero Añoro los viejos tiempos, en que los caballeros eran valientes y las damiselas eran frías, Tendrás un largo y frío invierno, si tienes un corto y frío corazón, Estaré contigo para llevarte a una Cruzada, cariño yDondequiera que deje mi yelmo, es mi casa.Estaré contigo para llevarte a una Cruzada, cariño yDondequiera que deje mi yelmo, es mi casa. El conocimiento es la luz que iluminará vuestro camino.El conocimiento es la luz que iluminará vuestro camino.¿Habéis confundido la necesidad con el amor?¿Habéis confundido la necesidad con el amor?Por esta fruta impongo condición,pero ahora aprenderéis acerca de la ambición.Por esta fruta impongo condición,pero ahora aprenderéis acerca de la ambición. aunque este Universo poseo, nada poseo, pues no puedo conocer lo desconocido si me aferro a lo conocido.Porque ahora el caballero era el arroyo.Era la luna. Era el sol.Podía ser todas las cosas a la vez, Y más, porque era uno con el universo.Era amor.Porque ahora el caballero era el arroyo.Era la luna. Era el sol.Podía ser todas las cosas a la vez, Y más, porque era uno con el universo.Era amor.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separo las frases usando el delimitador que usé (.)\n",
        "corpus = corpus.split('.') "
      ],
      "metadata": {
        "id": "115oXD7G07gq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjNRpHW21EyC",
        "outputId": "2f8dba22-17cb-4b96-8d6d-cb83e53be7c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hace ya mucho tiempo, en una tierra muy lejana, vivía un caballero que pensaba que era bueno, generoso y amoroso',\n",
              " ' Hacía todo lo que suelen hacer los caballeros buenos, generosos y amorosos',\n",
              " ' Luchaba contra sus enemigos, que era malos, mezquinos y odiosos',\n",
              " ' Mataba a dragones y rescataba a damiselas en apuros',\n",
              " ' Cuando en el asunto de la caballería había crisis, tenía la mala costumbre de rescatar damiselas incluso cuando ellas no deseaban ser rescatadas y, debido a esto, aunque muchas damas le estaban agradecidas, otras tantas se mostraban furiosas con el caballero',\n",
              " ' Él lo aceptaba con filosofía',\n",
              " ' Después de todo, no se puede contentar a todo el mundo',\n",
              " 'Nuestro caballero era famoso por su armadura',\n",
              " ' Reflejaba unos rayos de luz tan brillantes que la gente del pueblo juraba no haber visto el sol salir en el norte o ponerse en el este cuando el caballero partía a la batalla',\n",
              " ' Y partía a la batalla con bastante frecuencia',\n",
              " ' Ante la mera mención de una cruzada, el caballero se ponía la armadura entusiasmado, montaba su caballo y cabalgaba en cualquier dirección',\n",
              " ' Su entusiasmo era tal que a veces partía en varias direcciones a la vez, lo cual no es nada fácil',\n",
              " 'Durante años, el caballero es esforzó en ser el número uno del reino',\n",
              " ' Siempre había otra batalla que ganar, otro dragón que matar y otra damisela que rescatar',\n",
              " 'El caballero tenía una mujer fiel y bastante tolerante, Julieta, que escribía hermosos poemas, decía cosas inteligentes y tenía debilidad por el vino',\n",
              " ' También tenía un hijo de cabellos dorados, Cristóbal, al que esperaba ver algún día, convertido en un valiente caballero',\n",
              " 'Julieta y Cristóbal veían poco al caballero porque, cuando no estaba luchando en una batalla, matando dragones o rescatando damiselas, estaba ocupado probándose su armadura y admirando su brillo',\n",
              " ' Con el tiempo, el caballero se enamoró hasta tal punto de su armadura que se la empezó a poner para cenar y, a menudo, para dormir',\n",
              " ' Después de un tiempo, ya no se tomaba la molestia de quitársela para nada',\n",
              " ' Poco a poco, su familia fue olvidando qué aspecto tenía sin ella',\n",
              " 'Ocasionalmente, Cristóbal le preguntaba a su madre qué aspecto tenía su padre',\n",
              " ' Cuando esto sucedía, Julieta llevaba al chico hasta la chimenea y señalaba el retrato del caballero',\n",
              " 'He aquí a tu padre decía con un suspiro',\n",
              " 'Una tarde, mientras contemplaba el retrato, Cristóbal le dijo a su madre: Ojalá pudiera a ver a padre en persona',\n",
              " ' ¡No puedes tenerlo todo! respondió bruscamente Julieta']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtUlW_nJ1Lr8",
        "outputId": "cba61d79-70f1-4279-cd71-c01193f4703f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1121"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(corpus)"
      ],
      "metadata": {
        "id": "f4TARF9MeKSg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ticoqYD1Z3I7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "4512c047-e995-4cd9-b5f4-06c9126fc697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0  Hace ya mucho tiempo, en una tierra muy lejana...\n",
              "1   Hacía todo lo que suelen hacer los caballeros...\n",
              "2   Luchaba contra sus enemigos, que era malos, m...\n",
              "3   Mataba a dragones y rescataba a damiselas en ...\n",
              "4   Cuando en el asunto de la caballería había cr...\n",
              "5                       Él lo aceptaba con filosofía\n",
              "6   Después de todo, no se puede contentar a todo...\n",
              "7       Nuestro caballero era famoso por su armadura\n",
              "8   Reflejaba unos rayos de luz tan brillantes qu...\n",
              "9      Y partía a la batalla con bastante frecuencia"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a56b5cef-de0a-4be2-8fec-3a630610e849\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hace ya mucho tiempo, en una tierra muy lejana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hacía todo lo que suelen hacer los caballeros...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luchaba contra sus enemigos, que era malos, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mataba a dragones y rescataba a damiselas en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cuando en el asunto de la caballería había cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Él lo aceptaba con filosofía</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Después de todo, no se puede contentar a todo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nuestro caballero era famoso por su armadura</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Reflejaba unos rayos de luz tan brillantes qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Y partía a la batalla con bastante frecuencia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a56b5cef-de0a-4be2-8fec-3a630610e849')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a56b5cef-de0a-4be2-8fec-3a630610e849 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a56b5cef-de0a-4be2-8fec-3a630610e849');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Armar el dataset \n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc9da46-ab8b-4ef9-e3e6-1bb2448fcca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 1121\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdO0C0-uwOnQ",
        "outputId": "7f1274dc-fd49-4093-8fae-e9bd73e391a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  1.1 Dividir los documentos en palabras (tokenizar) - Uso tokenizador de Keras"
      ],
      "metadata": {
        "id": "6TSj4SENqcrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rIsmMWmjrDHd"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0])) # Acá guardo todos los tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CHepi_DGrbhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c70f06-8c5a-44b4-dd1c-04236a2a6a02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hace',\n",
              "  'ya',\n",
              "  'mucho',\n",
              "  'tiempo',\n",
              "  'en',\n",
              "  'una',\n",
              "  'tierra',\n",
              "  'muy',\n",
              "  'lejana',\n",
              "  'vivía',\n",
              "  'un',\n",
              "  'caballero',\n",
              "  'que',\n",
              "  'pensaba',\n",
              "  'que',\n",
              "  'era',\n",
              "  'bueno',\n",
              "  'generoso',\n",
              "  'y',\n",
              "  'amoroso'],\n",
              " ['hacía',\n",
              "  'todo',\n",
              "  'lo',\n",
              "  'que',\n",
              "  'suelen',\n",
              "  'hacer',\n",
              "  'los',\n",
              "  'caballeros',\n",
              "  'buenos',\n",
              "  'generosos',\n",
              "  'y',\n",
              "  'amorosos'],\n",
              " ['luchaba',\n",
              "  'contra',\n",
              "  'sus',\n",
              "  'enemigos',\n",
              "  'que',\n",
              "  'era',\n",
              "  'malos',\n",
              "  'mezquinos',\n",
              "  'y',\n",
              "  'odiosos'],\n",
              " ['mataba',\n",
              "  'a',\n",
              "  'dragones',\n",
              "  'y',\n",
              "  'rescataba',\n",
              "  'a',\n",
              "  'damiselas',\n",
              "  'en',\n",
              "  'apuros'],\n",
              " ['cuando',\n",
              "  'en',\n",
              "  'el',\n",
              "  'asunto',\n",
              "  'de',\n",
              "  'la',\n",
              "  'caballería',\n",
              "  'había',\n",
              "  'crisis',\n",
              "  'tenía',\n",
              "  'la',\n",
              "  'mala',\n",
              "  'costumbre',\n",
              "  'de',\n",
              "  'rescatar',\n",
              "  'damiselas',\n",
              "  'incluso',\n",
              "  'cuando',\n",
              "  'ellas',\n",
              "  'no',\n",
              "  'deseaban',\n",
              "  'ser',\n",
              "  'rescatadas',\n",
              "  'y',\n",
              "  'debido',\n",
              "  'a',\n",
              "  'esto',\n",
              "  'aunque',\n",
              "  'muchas',\n",
              "  'damas',\n",
              "  'le',\n",
              "  'estaban',\n",
              "  'agradecidas',\n",
              "  'otras',\n",
              "  'tantas',\n",
              "  'se',\n",
              "  'mostraban',\n",
              "  'furiosas',\n",
              "  'con',\n",
              "  'el',\n",
              "  'caballero']]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Miro como quedaron las primeras 5 oraciones\n",
        "sentence_tokens[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Callback para graficar loss a medida que se entrena Gensim"
      ],
      "metadata": {
        "id": "IhAfI80Pruqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobracargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Defino los parámetros del modelo"
      ],
      "metadata": {
        "id": "Ne2De_wTs5dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO NRO 1 A PROBAR (SKIPGRAM):"
      ],
      "metadata": {
        "id": "rzWVLpgyDAk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i0wnDdv9sJ47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938ece39-d757-44a4-d2f0-dfd05b17ecd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ],
      "source": [
        "# Crearmos el modelo generador de vectoeres\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario (si aparece menos de 5 veces, Gensim la descarta)\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     size=50,       # dimensionalidad de los vectores (de salida)\n",
        "                     negative=20,    # cantidad de negative samples (las más representativas)... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Armo el vocabulario"
      ],
      "metadata": {
        "id": "gakZL6K5txk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO NRO 1"
      ],
      "metadata": {
        "id": "lD9yWvhHEADD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5lTt8wErsf17"
      },
      "outputs": [],
      "source": [
        "# Buildear el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TNc9qt4os5AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a68399-5280-4bf8-b2f8-f2e3c28faa9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 1121\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "idw9cHF3tSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4bac35-bf82-458d-a44c-00dfe73c7a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 455\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9rgVeARCWqj",
        "outputId": "011273cb-61c6-4db4-fc7d-361281c0f663"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hace': <gensim.models.keyedvectors.Vocab at 0x7f734e80fc10>,\n",
              " 'ya': <gensim.models.keyedvectors.Vocab at 0x7f734e80fc50>,\n",
              " 'mucho': <gensim.models.keyedvectors.Vocab at 0x7f734e80fc90>,\n",
              " 'tiempo': <gensim.models.keyedvectors.Vocab at 0x7f734e80fcd0>,\n",
              " 'en': <gensim.models.keyedvectors.Vocab at 0x7f734e80fd50>,\n",
              " 'una': <gensim.models.keyedvectors.Vocab at 0x7f734e80fdd0>,\n",
              " 'muy': <gensim.models.keyedvectors.Vocab at 0x7f734e80fe10>,\n",
              " 'lejana': <gensim.models.keyedvectors.Vocab at 0x7f734e80fe50>,\n",
              " 'un': <gensim.models.keyedvectors.Vocab at 0x7f734e80fd10>,\n",
              " 'caballero': <gensim.models.keyedvectors.Vocab at 0x7f734e80fd90>,\n",
              " 'que': <gensim.models.keyedvectors.Vocab at 0x7f734e80fe90>,\n",
              " 'pensaba': <gensim.models.keyedvectors.Vocab at 0x7f734e80fed0>,\n",
              " 'era': <gensim.models.keyedvectors.Vocab at 0x7f734e80ff10>,\n",
              " 'bueno': <gensim.models.keyedvectors.Vocab at 0x7f734e80ff50>,\n",
              " 'generoso': <gensim.models.keyedvectors.Vocab at 0x7f734e80ff90>,\n",
              " 'y': <gensim.models.keyedvectors.Vocab at 0x7f734e80ffd0>,\n",
              " 'amoroso': <gensim.models.keyedvectors.Vocab at 0x7f734e815050>,\n",
              " 'hacía': <gensim.models.keyedvectors.Vocab at 0x7f734e815090>,\n",
              " 'todo': <gensim.models.keyedvectors.Vocab at 0x7f734e8150d0>,\n",
              " 'lo': <gensim.models.keyedvectors.Vocab at 0x7f734e815110>,\n",
              " 'hacer': <gensim.models.keyedvectors.Vocab at 0x7f734e815150>,\n",
              " 'los': <gensim.models.keyedvectors.Vocab at 0x7f734e815190>,\n",
              " 'caballeros': <gensim.models.keyedvectors.Vocab at 0x7f734e8151d0>,\n",
              " 'contra': <gensim.models.keyedvectors.Vocab at 0x7f734e815210>,\n",
              " 'sus': <gensim.models.keyedvectors.Vocab at 0x7f734e815250>,\n",
              " 'a': <gensim.models.keyedvectors.Vocab at 0x7f734e815290>,\n",
              " 'dragones': <gensim.models.keyedvectors.Vocab at 0x7f734e8152d0>,\n",
              " 'damiselas': <gensim.models.keyedvectors.Vocab at 0x7f734e815310>,\n",
              " 'cuando': <gensim.models.keyedvectors.Vocab at 0x7f734e815350>,\n",
              " 'el': <gensim.models.keyedvectors.Vocab at 0x7f734e815390>,\n",
              " 'de': <gensim.models.keyedvectors.Vocab at 0x7f734e8153d0>,\n",
              " 'la': <gensim.models.keyedvectors.Vocab at 0x7f734e815410>,\n",
              " 'había': <gensim.models.keyedvectors.Vocab at 0x7f734e815450>,\n",
              " 'tenía': <gensim.models.keyedvectors.Vocab at 0x7f734e815490>,\n",
              " 'mala': <gensim.models.keyedvectors.Vocab at 0x7f734e8154d0>,\n",
              " 'incluso': <gensim.models.keyedvectors.Vocab at 0x7f734e815510>,\n",
              " 'no': <gensim.models.keyedvectors.Vocab at 0x7f734e815550>,\n",
              " 'ser': <gensim.models.keyedvectors.Vocab at 0x7f734e815590>,\n",
              " 'esto': <gensim.models.keyedvectors.Vocab at 0x7f734e8155d0>,\n",
              " 'aunque': <gensim.models.keyedvectors.Vocab at 0x7f734e815610>,\n",
              " 'le': <gensim.models.keyedvectors.Vocab at 0x7f734e815650>,\n",
              " 'estaban': <gensim.models.keyedvectors.Vocab at 0x7f734e815690>,\n",
              " 'otras': <gensim.models.keyedvectors.Vocab at 0x7f734e8156d0>,\n",
              " 'se': <gensim.models.keyedvectors.Vocab at 0x7f734e815710>,\n",
              " 'con': <gensim.models.keyedvectors.Vocab at 0x7f734e815750>,\n",
              " 'él': <gensim.models.keyedvectors.Vocab at 0x7f734e815790>,\n",
              " 'después': <gensim.models.keyedvectors.Vocab at 0x7f734e8157d0>,\n",
              " 'puede': <gensim.models.keyedvectors.Vocab at 0x7f734e815810>,\n",
              " 'mundo': <gensim.models.keyedvectors.Vocab at 0x7f734e815850>,\n",
              " 'por': <gensim.models.keyedvectors.Vocab at 0x7f734e815890>,\n",
              " 'su': <gensim.models.keyedvectors.Vocab at 0x7f734e8158d0>,\n",
              " 'armadura': <gensim.models.keyedvectors.Vocab at 0x7f734e815910>,\n",
              " 'luz': <gensim.models.keyedvectors.Vocab at 0x7f734e815950>,\n",
              " 'tan': <gensim.models.keyedvectors.Vocab at 0x7f734e815990>,\n",
              " 'gente': <gensim.models.keyedvectors.Vocab at 0x7f734e8159d0>,\n",
              " 'del': <gensim.models.keyedvectors.Vocab at 0x7f734e815a10>,\n",
              " 'haber': <gensim.models.keyedvectors.Vocab at 0x7f734e815a50>,\n",
              " 'visto': <gensim.models.keyedvectors.Vocab at 0x7f734e815a90>,\n",
              " 'sol': <gensim.models.keyedvectors.Vocab at 0x7f734e815ad0>,\n",
              " 'salir': <gensim.models.keyedvectors.Vocab at 0x7f734e815b10>,\n",
              " 'o': <gensim.models.keyedvectors.Vocab at 0x7f734e815b50>,\n",
              " 'ponerse': <gensim.models.keyedvectors.Vocab at 0x7f734e815b90>,\n",
              " 'este': <gensim.models.keyedvectors.Vocab at 0x7f734e815bd0>,\n",
              " 'batalla': <gensim.models.keyedvectors.Vocab at 0x7f734e815c10>,\n",
              " 'bastante': <gensim.models.keyedvectors.Vocab at 0x7f734e815c50>,\n",
              " 'ante': <gensim.models.keyedvectors.Vocab at 0x7f734e815c90>,\n",
              " 'cruzada': <gensim.models.keyedvectors.Vocab at 0x7f734e815cd0>,\n",
              " 'caballo': <gensim.models.keyedvectors.Vocab at 0x7f734e815d10>,\n",
              " 'cualquier': <gensim.models.keyedvectors.Vocab at 0x7f734e815d50>,\n",
              " 'tal': <gensim.models.keyedvectors.Vocab at 0x7f734e815d90>,\n",
              " 'veces': <gensim.models.keyedvectors.Vocab at 0x7f734e815dd0>,\n",
              " 'vez': <gensim.models.keyedvectors.Vocab at 0x7f734e815e10>,\n",
              " 'es': <gensim.models.keyedvectors.Vocab at 0x7f734e815e50>,\n",
              " 'nada': <gensim.models.keyedvectors.Vocab at 0x7f734e815e90>,\n",
              " 'fácil': <gensim.models.keyedvectors.Vocab at 0x7f734e815ed0>,\n",
              " 'durante': <gensim.models.keyedvectors.Vocab at 0x7f734e815f10>,\n",
              " 'años': <gensim.models.keyedvectors.Vocab at 0x7f734e815f50>,\n",
              " 'uno': <gensim.models.keyedvectors.Vocab at 0x7f734e815f90>,\n",
              " 'reino': <gensim.models.keyedvectors.Vocab at 0x7f734e815fd0>,\n",
              " 'siempre': <gensim.models.keyedvectors.Vocab at 0x7f734e817050>,\n",
              " 'otra': <gensim.models.keyedvectors.Vocab at 0x7f734e817090>,\n",
              " 'otro': <gensim.models.keyedvectors.Vocab at 0x7f734e8170d0>,\n",
              " 'dragón': <gensim.models.keyedvectors.Vocab at 0x7f734e817110>,\n",
              " 'matar': <gensim.models.keyedvectors.Vocab at 0x7f734e817150>,\n",
              " 'julieta': <gensim.models.keyedvectors.Vocab at 0x7f734e817190>,\n",
              " 'cosas': <gensim.models.keyedvectors.Vocab at 0x7f734e8171d0>,\n",
              " 'vino': <gensim.models.keyedvectors.Vocab at 0x7f734e817210>,\n",
              " 'también': <gensim.models.keyedvectors.Vocab at 0x7f734e817250>,\n",
              " 'hijo': <gensim.models.keyedvectors.Vocab at 0x7f734e817290>,\n",
              " 'cristóbal': <gensim.models.keyedvectors.Vocab at 0x7f734e8172d0>,\n",
              " 'al': <gensim.models.keyedvectors.Vocab at 0x7f734e817310>,\n",
              " 'ver': <gensim.models.keyedvectors.Vocab at 0x7f734e817350>,\n",
              " 'algún': <gensim.models.keyedvectors.Vocab at 0x7f734e817390>,\n",
              " 'día': <gensim.models.keyedvectors.Vocab at 0x7f734e8173d0>,\n",
              " 'poco': <gensim.models.keyedvectors.Vocab at 0x7f734e817410>,\n",
              " 'porque': <gensim.models.keyedvectors.Vocab at 0x7f734e817450>,\n",
              " 'estaba': <gensim.models.keyedvectors.Vocab at 0x7f734e817490>,\n",
              " 'hasta': <gensim.models.keyedvectors.Vocab at 0x7f734e8174d0>,\n",
              " 'para': <gensim.models.keyedvectors.Vocab at 0x7f734e817510>,\n",
              " 'menudo': <gensim.models.keyedvectors.Vocab at 0x7f734e817550>,\n",
              " 'dormir': <gensim.models.keyedvectors.Vocab at 0x7f734e817590>,\n",
              " 'fue': <gensim.models.keyedvectors.Vocab at 0x7f734e8175d0>,\n",
              " 'qué': <gensim.models.keyedvectors.Vocab at 0x7f734e817610>,\n",
              " 'aspecto': <gensim.models.keyedvectors.Vocab at 0x7f734e817650>,\n",
              " 'sin': <gensim.models.keyedvectors.Vocab at 0x7f734e817690>,\n",
              " 'ella': <gensim.models.keyedvectors.Vocab at 0x7f734e8176d0>,\n",
              " 'padre': <gensim.models.keyedvectors.Vocab at 0x7f734e817710>,\n",
              " 'llevaba': <gensim.models.keyedvectors.Vocab at 0x7f734e817750>,\n",
              " 'he': <gensim.models.keyedvectors.Vocab at 0x7f734e817790>,\n",
              " 'aquí': <gensim.models.keyedvectors.Vocab at 0x7f734e8177d0>,\n",
              " 'tu': <gensim.models.keyedvectors.Vocab at 0x7f734e817810>,\n",
              " 'mientras': <gensim.models.keyedvectors.Vocab at 0x7f734e817850>,\n",
              " 'dijo': <gensim.models.keyedvectors.Vocab at 0x7f734e817890>,\n",
              " 'persona': <gensim.models.keyedvectors.Vocab at 0x7f734e8178d0>,\n",
              " '¡no': <gensim.models.keyedvectors.Vocab at 0x7f734e817910>,\n",
              " 'puedes': <gensim.models.keyedvectors.Vocab at 0x7f734e817950>,\n",
              " 'respondió': <gensim.models.keyedvectors.Vocab at 0x7f734e817990>,\n",
              " 'cada': <gensim.models.keyedvectors.Vocab at 0x7f734e8179d0>,\n",
              " 'más': <gensim.models.keyedvectors.Vocab at 0x7f734e817a10>,\n",
              " 'tener': <gensim.models.keyedvectors.Vocab at 0x7f734e817a50>,\n",
              " 'sólo': <gensim.models.keyedvectors.Vocab at 0x7f734e817a90>,\n",
              " 'como': <gensim.models.keyedvectors.Vocab at 0x7f734e817ad0>,\n",
              " 'rostro': <gensim.models.keyedvectors.Vocab at 0x7f734e817b10>,\n",
              " 'culpa': <gensim.models.keyedvectors.Vocab at 0x7f734e817b50>,\n",
              " 'casa': <gensim.models.keyedvectors.Vocab at 0x7f734e817b90>,\n",
              " 'sobre': <gensim.models.keyedvectors.Vocab at 0x7f734e817bd0>,\n",
              " 'casi': <gensim.models.keyedvectors.Vocab at 0x7f734e817c10>,\n",
              " 'nunca': <gensim.models.keyedvectors.Vocab at 0x7f734e817c50>,\n",
              " 'decir': <gensim.models.keyedvectors.Vocab at 0x7f734e817c90>,\n",
              " 'las': <gensim.models.keyedvectors.Vocab at 0x7f734e817cd0>,\n",
              " 'visera': <gensim.models.keyedvectors.Vocab at 0x7f734e817d10>,\n",
              " 'dormido': <gensim.models.keyedvectors.Vocab at 0x7f734e817d50>,\n",
              " 'creo': <gensim.models.keyedvectors.Vocab at 0x7f734e817d90>,\n",
              " 'me': <gensim.models.keyedvectors.Vocab at 0x7f734e817dd0>,\n",
              " 'mí': <gensim.models.keyedvectors.Vocab at 0x7f734e817e10>,\n",
              " 'eso': <gensim.models.keyedvectors.Vocab at 0x7f734e817e50>,\n",
              " 'verdad': <gensim.models.keyedvectors.Vocab at 0x7f734e817e90>,\n",
              " 'te': <gensim.models.keyedvectors.Vocab at 0x7f734e817ed0>,\n",
              " 'e': <gensim.models.keyedvectors.Vocab at 0x7f734e817f10>,\n",
              " 'elegante': <gensim.models.keyedvectors.Vocab at 0x7f734e817f50>,\n",
              " 'castillo': <gensim.models.keyedvectors.Vocab at 0x7f734e817f90>,\n",
              " 'tú': <gensim.models.keyedvectors.Vocab at 0x7f734e817fd0>,\n",
              " 'través': <gensim.models.keyedvectors.Vocab at 0x7f734e81a050>,\n",
              " 'poder': <gensim.models.keyedvectors.Vocab at 0x7f734e81a090>,\n",
              " 'ojos': <gensim.models.keyedvectors.Vocab at 0x7f734e81a0d0>,\n",
              " 'idea': <gensim.models.keyedvectors.Vocab at 0x7f734e81a110>,\n",
              " 'realmente': <gensim.models.keyedvectors.Vocab at 0x7f734e81a150>,\n",
              " 'entonces': <gensim.models.keyedvectors.Vocab at 0x7f734e81a190>,\n",
              " 'tampoco': <gensim.models.keyedvectors.Vocab at 0x7f734e81a1d0>,\n",
              " 'ahora': <gensim.models.keyedvectors.Vocab at 0x7f734e81a210>,\n",
              " 'sí': <gensim.models.keyedvectors.Vocab at 0x7f734e81a250>,\n",
              " 'esa': <gensim.models.keyedvectors.Vocab at 0x7f734e81a290>,\n",
              " 'quién': <gensim.models.keyedvectors.Vocab at 0x7f734e81a2d0>,\n",
              " 'eres': <gensim.models.keyedvectors.Vocab at 0x7f734e81a310>,\n",
              " 'realidad': <gensim.models.keyedvectors.Vocab at 0x7f734e81a350>,\n",
              " 'puedo': <gensim.models.keyedvectors.Vocab at 0x7f734e81a390>,\n",
              " 'tengo': <gensim.models.keyedvectors.Vocab at 0x7f734e81a3d0>,\n",
              " 'estar': <gensim.models.keyedvectors.Vocab at 0x7f734e81a410>,\n",
              " 'mi': <gensim.models.keyedvectors.Vocab at 0x7f734e81a450>,\n",
              " 'partir': <gensim.models.keyedvectors.Vocab at 0x7f734e81a490>,\n",
              " 'explicó': <gensim.models.keyedvectors.Vocab at 0x7f734e81a4d0>,\n",
              " 'si': <gensim.models.keyedvectors.Vocab at 0x7f734e81a510>,\n",
              " 'vida': <gensim.models.keyedvectors.Vocab at 0x7f734e81a550>,\n",
              " 'golpe': <gensim.models.keyedvectors.Vocab at 0x7f734e81a590>,\n",
              " 'quería': <gensim.models.keyedvectors.Vocab at 0x7f734e81a5d0>,\n",
              " 'fuera': <gensim.models.keyedvectors.Vocab at 0x7f734e81a610>,\n",
              " 'amaba': <gensim.models.keyedvectors.Vocab at 0x7f734e81a650>,\n",
              " 'pero': <gensim.models.keyedvectors.Vocab at 0x7f734e81a690>,\n",
              " 'les': <gensim.models.keyedvectors.Vocab at 0x7f734e81a6d0>,\n",
              " 'todos': <gensim.models.keyedvectors.Vocab at 0x7f734e81a710>,\n",
              " '¿por': <gensim.models.keyedvectors.Vocab at 0x7f734e81a750>,\n",
              " 'cuenta': <gensim.models.keyedvectors.Vocab at 0x7f734e81a790>,\n",
              " 'ninguna': <gensim.models.keyedvectors.Vocab at 0x7f734e81a7d0>,\n",
              " 'estas': <gensim.models.keyedvectors.Vocab at 0x7f734e81a810>,\n",
              " 'intentó': <gensim.models.keyedvectors.Vocab at 0x7f734e81a850>,\n",
              " 'quitarse': <gensim.models.keyedvectors.Vocab at 0x7f734e81a890>,\n",
              " 'yelmo': <gensim.models.keyedvectors.Vocab at 0x7f734e81a8d0>,\n",
              " 'movió': <gensim.models.keyedvectors.Vocab at 0x7f734e81a910>,\n",
              " 'fuerza': <gensim.models.keyedvectors.Vocab at 0x7f734e81a950>,\n",
              " 'arriba': <gensim.models.keyedvectors.Vocab at 0x7f734e81a990>,\n",
              " 'gran': <gensim.models.keyedvectors.Vocab at 0x7f734e81a9d0>,\n",
              " '¿cómo': <gensim.models.keyedvectors.Vocab at 0x7f734e81aa10>,\n",
              " 'podía': <gensim.models.keyedvectors.Vocab at 0x7f734e81aa50>,\n",
              " 'quizá': <gensim.models.keyedvectors.Vocab at 0x7f734e81aa90>,\n",
              " 'encontrar': <gensim.models.keyedvectors.Vocab at 0x7f734e81aad0>,\n",
              " 'comer': <gensim.models.keyedvectors.Vocab at 0x7f734e81ab10>,\n",
              " 'misma': <gensim.models.keyedvectors.Vocab at 0x7f734e81ab50>,\n",
              " 'mañana': <gensim.models.keyedvectors.Vocab at 0x7f734e81ab90>,\n",
              " 'iba': <gensim.models.keyedvectors.Vocab at 0x7f734e81abd0>,\n",
              " 'corriendo': <gensim.models.keyedvectors.Vocab at 0x7f734e81ac10>,\n",
              " 'hacia': <gensim.models.keyedvectors.Vocab at 0x7f734e81ac50>,\n",
              " 'herrero': <gensim.models.keyedvectors.Vocab at 0x7f734e81ac90>,\n",
              " 'sois': <gensim.models.keyedvectors.Vocab at 0x7f734e81acd0>,\n",
              " 'estoy': <gensim.models.keyedvectors.Vocab at 0x7f734e81ad10>,\n",
              " 'humor': <gensim.models.keyedvectors.Vocab at 0x7f734e81ad50>,\n",
              " 'estos': <gensim.models.keyedvectors.Vocab at 0x7f734e81ad90>,\n",
              " 'atrapado': <gensim.models.keyedvectors.Vocab at 0x7f734e81add0>,\n",
              " 'esta': <gensim.models.keyedvectors.Vocab at 0x7f734e81ae10>,\n",
              " 'suelo': <gensim.models.keyedvectors.Vocab at 0x7f734e81ae50>,\n",
              " 'pie': <gensim.models.keyedvectors.Vocab at 0x7f734e81ae90>,\n",
              " 'acero': <gensim.models.keyedvectors.Vocab at 0x7f734e81aed0>,\n",
              " 'caer': <gensim.models.keyedvectors.Vocab at 0x7f734e81af10>,\n",
              " 'dejó': <gensim.models.keyedvectors.Vocab at 0x7f734e81af50>,\n",
              " 'momento': <gensim.models.keyedvectors.Vocab at 0x7f734e81af90>,\n",
              " 'sintió': <gensim.models.keyedvectors.Vocab at 0x7f734e81afd0>,\n",
              " 'ni': <gensim.models.keyedvectors.Vocab at 0x7f734e81d050>,\n",
              " 'siquiera': <gensim.models.keyedvectors.Vocab at 0x7f734e81d090>,\n",
              " 'hombre': <gensim.models.keyedvectors.Vocab at 0x7f734e81d0d0>,\n",
              " '¿quién': <gensim.models.keyedvectors.Vocab at 0x7f734e81d110>,\n",
              " 'podría': <gensim.models.keyedvectors.Vocab at 0x7f734e81d150>,\n",
              " 'estáis': <gensim.models.keyedvectors.Vocab at 0x7f734e81d190>,\n",
              " 'difícil': <gensim.models.keyedvectors.Vocab at 0x7f734e81d1d0>,\n",
              " 'os': <gensim.models.keyedvectors.Vocab at 0x7f734e81d210>,\n",
              " 'yo': <gensim.models.keyedvectors.Vocab at 0x7f734e81d250>,\n",
              " 'habéis': <gensim.models.keyedvectors.Vocab at 0x7f734e81d290>,\n",
              " 'noche': <gensim.models.keyedvectors.Vocab at 0x7f734e81d2d0>,\n",
              " 'medida': <gensim.models.keyedvectors.Vocab at 0x7f734e81d310>,\n",
              " 'abrir': <gensim.models.keyedvectors.Vocab at 0x7f734e81d350>,\n",
              " 'gritó': <gensim.models.keyedvectors.Vocab at 0x7f734e81d390>,\n",
              " 'paloma': <gensim.models.keyedvectors.Vocab at 0x7f734e81d3d0>,\n",
              " 'comenzó': <gensim.models.keyedvectors.Vocab at 0x7f734e81d410>,\n",
              " 'dio': <gensim.models.keyedvectors.Vocab at 0x7f734e81d450>,\n",
              " 'habían': <gensim.models.keyedvectors.Vocab at 0x7f734e81d490>,\n",
              " 'cabeza': <gensim.models.keyedvectors.Vocab at 0x7f734e81d4d0>,\n",
              " 'sentido': <gensim.models.keyedvectors.Vocab at 0x7f734e81d510>,\n",
              " 'hecho': <gensim.models.keyedvectors.Vocab at 0x7f734e81d550>,\n",
              " 'sentir': <gensim.models.keyedvectors.Vocab at 0x7f734e81d590>,\n",
              " 'tanto': <gensim.models.keyedvectors.Vocab at 0x7f734e81d5d0>,\n",
              " 'cómo': <gensim.models.keyedvectors.Vocab at 0x7f734e81d610>,\n",
              " 'intentando': <gensim.models.keyedvectors.Vocab at 0x7f734e81d650>,\n",
              " 'eran': <gensim.models.keyedvectors.Vocab at 0x7f734e81d690>,\n",
              " 'tiene': <gensim.models.keyedvectors.Vocab at 0x7f734e81d6d0>,\n",
              " 'hablar': <gensim.models.keyedvectors.Vocab at 0x7f734e81d710>,\n",
              " 'volver': <gensim.models.keyedvectors.Vocab at 0x7f734e81d750>,\n",
              " 'cosa': <gensim.models.keyedvectors.Vocab at 0x7f734e81d790>,\n",
              " 'último': <gensim.models.keyedvectors.Vocab at 0x7f734e81d7d0>,\n",
              " 'listo': <gensim.models.keyedvectors.Vocab at 0x7f734e81d810>,\n",
              " 'manera': <gensim.models.keyedvectors.Vocab at 0x7f73a7393790>,\n",
              " 'hubiera': <gensim.models.keyedvectors.Vocab at 0x7f73a7393750>,\n",
              " 'podido': <gensim.models.keyedvectors.Vocab at 0x7f73a7393a90>,\n",
              " 'castillos': <gensim.models.keyedvectors.Vocab at 0x7f73a73939d0>,\n",
              " 'pronto': <gensim.models.keyedvectors.Vocab at 0x7f73a7393910>,\n",
              " 'sabía': <gensim.models.keyedvectors.Vocab at 0x7f73a7393710>,\n",
              " 'tras': <gensim.models.keyedvectors.Vocab at 0x7f73a7393c90>,\n",
              " 'necesitado': <gensim.models.keyedvectors.Vocab at 0x7f73a7393d90>,\n",
              " 'ayuda': <gensim.models.keyedvectors.Vocab at 0x7f73a7393c10>,\n",
              " 'lugar': <gensim.models.keyedvectors.Vocab at 0x7f73a73978d0>,\n",
              " 'debe': <gensim.models.keyedvectors.Vocab at 0x7f73a73973d0>,\n",
              " 'alguien': <gensim.models.keyedvectors.Vocab at 0x7f73a73976d0>,\n",
              " 'pueda': <gensim.models.keyedvectors.Vocab at 0x7f73a7397490>,\n",
              " 'pensó': <gensim.models.keyedvectors.Vocab at 0x7f73a73974d0>,\n",
              " 'desde': <gensim.models.keyedvectors.Vocab at 0x7f73a7397390>,\n",
              " 'luego': <gensim.models.keyedvectors.Vocab at 0x7f73a7397950>,\n",
              " 'menos': <gensim.models.keyedvectors.Vocab at 0x7f734e800b90>,\n",
              " 'amor': <gensim.models.keyedvectors.Vocab at 0x7f734e800f50>,\n",
              " 'embargo': <gensim.models.keyedvectors.Vocab at 0x7f734e800f10>,\n",
              " 'así': <gensim.models.keyedvectors.Vocab at 0x7f734e800e90>,\n",
              " 'miedo': <gensim.models.keyedvectors.Vocab at 0x7f734e800e50>,\n",
              " 'cambiar': <gensim.models.keyedvectors.Vocab at 0x7f734e800dd0>,\n",
              " 'rey': <gensim.models.keyedvectors.Vocab at 0x7f734e800cd0>,\n",
              " 'sido': <gensim.models.keyedvectors.Vocab at 0x7f734e8007d0>,\n",
              " 'cima': <gensim.models.keyedvectors.Vocab at 0x7f734e800d10>,\n",
              " 'puente': <gensim.models.keyedvectors.Vocab at 0x7f734e8002d0>,\n",
              " 'levadizo': <gensim.models.keyedvectors.Vocab at 0x7f734e800c50>,\n",
              " 'vio': <gensim.models.keyedvectors.Vocab at 0x7f734e800c10>,\n",
              " 'bufón': <gensim.models.keyedvectors.Vocab at 0x7f734e800510>,\n",
              " 'sentado': <gensim.models.keyedvectors.Vocab at 0x7f734e800550>,\n",
              " 'cruzadas': <gensim.models.keyedvectors.Vocab at 0x7f734e800610>,\n",
              " 'bolsalegre': <gensim.models.keyedvectors.Vocab at 0x7f734e800110>,\n",
              " 'hombro': <gensim.models.keyedvectors.Vocab at 0x7f734e81d850>,\n",
              " 'personas': <gensim.models.keyedvectors.Vocab at 0x7f734e81d890>,\n",
              " 'ir': <gensim.models.keyedvectors.Vocab at 0x7f734e81d8d0>,\n",
              " 'hay': <gensim.models.keyedvectors.Vocab at 0x7f734e81d910>,\n",
              " 'ha': <gensim.models.keyedvectors.Vocab at 0x7f734e81d950>,\n",
              " 'preguntó': <gensim.models.keyedvectors.Vocab at 0x7f734e81d990>,\n",
              " 'vuestro': <gensim.models.keyedvectors.Vocab at 0x7f734e81d9d0>,\n",
              " 'perdido': <gensim.models.keyedvectors.Vocab at 0x7f734e81da10>,\n",
              " 'quedó': <gensim.models.keyedvectors.Vocab at 0x7f734e81da50>,\n",
              " 'decepcionado': <gensim.models.keyedvectors.Vocab at 0x7f734e81da90>,\n",
              " 'dentro': <gensim.models.keyedvectors.Vocab at 0x7f734e81dad0>,\n",
              " 'antes': <gensim.models.keyedvectors.Vocab at 0x7f734e81db10>,\n",
              " 'vuestra': <gensim.models.keyedvectors.Vocab at 0x7f734e81db50>,\n",
              " 'podéis': <gensim.models.keyedvectors.Vocab at 0x7f734e81db90>,\n",
              " '¿no': <gensim.models.keyedvectors.Vocab at 0x7f734e81dbd0>,\n",
              " 'voz': <gensim.models.keyedvectors.Vocab at 0x7f734e81dc10>,\n",
              " 'son': <gensim.models.keyedvectors.Vocab at 0x7f734e81dc50>,\n",
              " 'continuó': <gensim.models.keyedvectors.Vocab at 0x7f734e81dc90>,\n",
              " 'alguna': <gensim.models.keyedvectors.Vocab at 0x7f734e81dcd0>,\n",
              " 'oír': <gensim.models.keyedvectors.Vocab at 0x7f734e81dd10>,\n",
              " 'dicho': <gensim.models.keyedvectors.Vocab at 0x7f734e81dd50>,\n",
              " 'verdadero': <gensim.models.keyedvectors.Vocab at 0x7f734e81dd90>,\n",
              " 'tenéis': <gensim.models.keyedvectors.Vocab at 0x7f734e81ddd0>,\n",
              " 'mago': <gensim.models.keyedvectors.Vocab at 0x7f734e81de10>,\n",
              " 'merlín': <gensim.models.keyedvectors.Vocab at 0x7f734e81de50>,\n",
              " 'oído': <gensim.models.keyedvectors.Vocab at 0x7f734e81de90>,\n",
              " 'sabio': <gensim.models.keyedvectors.Vocab at 0x7f734e81ded0>,\n",
              " 'mismo': <gensim.models.keyedvectors.Vocab at 0x7f734e81df10>,\n",
              " 'solo': <gensim.models.keyedvectors.Vocab at 0x7f734e81df50>,\n",
              " 'dos': <gensim.models.keyedvectors.Vocab at 0x7f734e81df90>,\n",
              " 'tres': <gensim.models.keyedvectors.Vocab at 0x7f734e81dfd0>,\n",
              " 'exclamó': <gensim.models.keyedvectors.Vocab at 0x7f734e821050>,\n",
              " 'muchos': <gensim.models.keyedvectors.Vocab at 0x7f734e821090>,\n",
              " 'replicó': <gensim.models.keyedvectors.Vocab at 0x7f734e8210d0>,\n",
              " 'aún': <gensim.models.keyedvectors.Vocab at 0x7f734e821110>,\n",
              " 'bosques': <gensim.models.keyedvectors.Vocab at 0x7f734e821150>,\n",
              " 'ahí': <gensim.models.keyedvectors.Vocab at 0x7f734e821190>,\n",
              " 'parece': <gensim.models.keyedvectors.Vocab at 0x7f734e8211d0>,\n",
              " 'está': <gensim.models.keyedvectors.Vocab at 0x7f734e821210>,\n",
              " 'mano': <gensim.models.keyedvectors.Vocab at 0x7f734e821250>,\n",
              " 'rápidamente': <gensim.models.keyedvectors.Vocab at 0x7f734e821290>,\n",
              " 'bien': <gensim.models.keyedvectors.Vocab at 0x7f734e8212d0>,\n",
              " 'dolor': <gensim.models.keyedvectors.Vocab at 0x7f734e821310>,\n",
              " 'otros': <gensim.models.keyedvectors.Vocab at 0x7f734e821350>,\n",
              " 'hizo': <gensim.models.keyedvectors.Vocab at 0x7f734e821390>,\n",
              " 'corazón': <gensim.models.keyedvectors.Vocab at 0x7f734e8213d0>,\n",
              " 'sentía': <gensim.models.keyedvectors.Vocab at 0x7f734e821410>,\n",
              " 'arroyo': <gensim.models.keyedvectors.Vocab at 0x7f734e821450>,\n",
              " 'agua': <gensim.models.keyedvectors.Vocab at 0x7f734e821490>,\n",
              " 'despertó': <gensim.models.keyedvectors.Vocab at 0x7f734e8214d0>,\n",
              " 'débil': <gensim.models.keyedvectors.Vocab at 0x7f734e821510>,\n",
              " 'encontró': <gensim.models.keyedvectors.Vocab at 0x7f734e821550>,\n",
              " 'árbol': <gensim.models.keyedvectors.Vocab at 0x7f734e821590>,\n",
              " 'animales': <gensim.models.keyedvectors.Vocab at 0x7f734e8215d0>,\n",
              " 'alrededor': <gensim.models.keyedvectors.Vocab at 0x7f734e821610>,\n",
              " 'lado': <gensim.models.keyedvectors.Vocab at 0x7f734e821650>,\n",
              " 'haciendo': <gensim.models.keyedvectors.Vocab at 0x7f734e821690>,\n",
              " 'estado': <gensim.models.keyedvectors.Vocab at 0x7f734e8216d0>,\n",
              " 'toda': <gensim.models.keyedvectors.Vocab at 0x7f734e821710>,\n",
              " 'demasiado': <gensim.models.keyedvectors.Vocab at 0x7f734e821750>,\n",
              " 'miró': <gensim.models.keyedvectors.Vocab at 0x7f734e821790>,\n",
              " '¿y': <gensim.models.keyedvectors.Vocab at 0x7f734e8217d0>,\n",
              " 'respuesta': <gensim.models.keyedvectors.Vocab at 0x7f734e821810>,\n",
              " 'aprender': <gensim.models.keyedvectors.Vocab at 0x7f734e821850>,\n",
              " 'hayáis': <gensim.models.keyedvectors.Vocab at 0x7f734e821890>,\n",
              " 'tendréis': <gensim.models.keyedvectors.Vocab at 0x7f734e8218d0>,\n",
              " 'todas': <gensim.models.keyedvectors.Vocab at 0x7f734e821910>,\n",
              " 'copa': <gensim.models.keyedvectors.Vocab at 0x7f734e821950>,\n",
              " '¿qué': <gensim.models.keyedvectors.Vocab at 0x7f734e821990>,\n",
              " 'pues': <gensim.models.keyedvectors.Vocab at 0x7f734e8219d0>,\n",
              " 'puso': <gensim.models.keyedvectors.Vocab at 0x7f734e821a10>,\n",
              " 'asintió': <gensim.models.keyedvectors.Vocab at 0x7f734e821a50>,\n",
              " 'estabais': <gensim.models.keyedvectors.Vocab at 0x7f734e821a90>,\n",
              " 'buena': <gensim.models.keyedvectors.Vocab at 0x7f734e821ad0>,\n",
              " 'vos': <gensim.models.keyedvectors.Vocab at 0x7f734e821b10>,\n",
              " 'ese': <gensim.models.keyedvectors.Vocab at 0x7f734e821b50>,\n",
              " 'empezando': <gensim.models.keyedvectors.Vocab at 0x7f734e821b90>,\n",
              " 'pensar': <gensim.models.keyedvectors.Vocab at 0x7f734e821bd0>,\n",
              " 'nueces': <gensim.models.keyedvectors.Vocab at 0x7f734e821c10>,\n",
              " 'entre': <gensim.models.keyedvectors.Vocab at 0x7f734e821c50>,\n",
              " 'ardilla': <gensim.models.keyedvectors.Vocab at 0x7f734e821c90>,\n",
              " 'sería': <gensim.models.keyedvectors.Vocab at 0x7f734e821cd0>,\n",
              " 'medio': <gensim.models.keyedvectors.Vocab at 0x7f734e821d10>,\n",
              " 'pregunta': <gensim.models.keyedvectors.Vocab at 0x7f734e821d50>,\n",
              " 'mente': <gensim.models.keyedvectors.Vocab at 0x7f734e821d90>,\n",
              " 'pasado': <gensim.models.keyedvectors.Vocab at 0x7f734e821dd0>,\n",
              " 'estás': <gensim.models.keyedvectors.Vocab at 0x7f734e821e10>,\n",
              " 'comprender': <gensim.models.keyedvectors.Vocab at 0x7f734e821e50>,\n",
              " 'añadió': <gensim.models.keyedvectors.Vocab at 0x7f734e821e90>,\n",
              " 'recordó': <gensim.models.keyedvectors.Vocab at 0x7f734e821ed0>,\n",
              " 'algo': <gensim.models.keyedvectors.Vocab at 0x7f734e821f10>,\n",
              " 'llegar': <gensim.models.keyedvectors.Vocab at 0x7f734e821f50>,\n",
              " 'demostrar': <gensim.models.keyedvectors.Vocab at 0x7f734e821f90>,\n",
              " 'siguiente': <gensim.models.keyedvectors.Vocab at 0x7f734e821fd0>,\n",
              " 'pensamiento': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5050>,\n",
              " 'posible': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5090>,\n",
              " 'preguntas': <gensim.models.keyedvectors.Vocab at 0x7f734e7a50d0>,\n",
              " 'bajo': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5110>,\n",
              " 'alta': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5150>,\n",
              " 'nadie': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5190>,\n",
              " 'cola': <gensim.models.keyedvectors.Vocab at 0x7f734e7a51d0>,\n",
              " 'camino': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5210>,\n",
              " 'única': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5250>,\n",
              " 'contigo': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5290>,\n",
              " 'sorprendido': <gensim.models.keyedvectors.Vocab at 0x7f734e7a52d0>,\n",
              " 'hablando': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5310>,\n",
              " 'pueden': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5350>,\n",
              " 'has': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5390>,\n",
              " 'hablado': <gensim.models.keyedvectors.Vocab at 0x7f734e7a53d0>,\n",
              " 'simplemente': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5410>,\n",
              " 'mis': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5450>,\n",
              " 'desapareció': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5490>,\n",
              " 'preciso': <gensim.models.keyedvectors.Vocab at 0x7f734e7a54d0>,\n",
              " 'queréis': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5510>,\n",
              " 'confundido': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5550>,\n",
              " 'palabras': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5590>,\n",
              " 'esas': <gensim.models.keyedvectors.Vocab at 0x7f734e7a55d0>,\n",
              " 'ellos': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5610>,\n",
              " 'quiero': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5650>,\n",
              " 'regresar': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5690>,\n",
              " 'dar': <gensim.models.keyedvectors.Vocab at 0x7f734e7a56d0>,\n",
              " 'soy': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5710>,\n",
              " 'mejores': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5750>,\n",
              " 'reflexionó': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5790>,\n",
              " 'nota': <gensim.models.keyedvectors.Vocab at 0x7f734e7a57d0>,\n",
              " 'rebeca': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5810>,\n",
              " 'donde': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5850>,\n",
              " 'tienes': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5890>,\n",
              " 'lágrimas': <gensim.models.keyedvectors.Vocab at 0x7f734e7a58d0>,\n",
              " 'exhausto': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5910>,\n",
              " 'barba': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5950>,\n",
              " 'parecía': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5990>,\n",
              " 'igual': <gensim.models.keyedvectors.Vocab at 0x7f734e7a59d0>,\n",
              " 'razón': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5a10>,\n",
              " 'pensando': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5a50>,\n",
              " 'sendero': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5a90>,\n",
              " 'primero': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5ad0>,\n",
              " 'acerca': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5b10>,\n",
              " 'montaña': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5b50>,\n",
              " 'contempló': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5b90>,\n",
              " 'desconocido': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5bd0>,\n",
              " 'coraje': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5c10>,\n",
              " 'roca': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5c50>,\n",
              " 'viaje': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5c90>,\n",
              " 'sé': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5cd0>,\n",
              " 'silencio': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5d10>,\n",
              " 'conocimiento': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5d50>,\n",
              " 'voluntad': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5d90>,\n",
              " 'osadía': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5dd0>,\n",
              " 'profundamente': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5e10>,\n",
              " 'árboles': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5e50>,\n",
              " 'espada': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5e90>,\n",
              " 'parte': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5ed0>,\n",
              " 'rió': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5f10>,\n",
              " 'hermoso': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5f50>,\n",
              " 'feliz': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5f90>,\n",
              " 'puerta': <gensim.models.keyedvectors.Vocab at 0x7f734e7a5fd0>,\n",
              " 'enorme': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9050>,\n",
              " 'entró': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9090>,\n",
              " 'fuego': <gensim.models.keyedvectors.Vocab at 0x7f734e7a90d0>,\n",
              " 'sentó': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9110>,\n",
              " 'habitación': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9150>,\n",
              " 'aquello': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9190>,\n",
              " 'sonido': <gensim.models.keyedvectors.Vocab at 0x7f734e7a91d0>,\n",
              " 'mejor': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9210>,\n",
              " 'somos': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9250>,\n",
              " 'volvió': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9290>,\n",
              " 'pared': <gensim.models.keyedvectors.Vocab at 0x7f734e7a92d0>,\n",
              " 'tipo': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9310>,\n",
              " 'conocido': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9350>,\n",
              " 'abrió': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9390>,\n",
              " 'apareció': <gensim.models.keyedvectors.Vocab at 0x7f734e7a93d0>,\n",
              " 'debía': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9410>,\n",
              " 'llorar': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9450>,\n",
              " 'grande': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9490>,\n",
              " 'primera': <gensim.models.keyedvectors.Vocab at 0x7f734e7a94d0>,\n",
              " 'sam': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9510>,\n",
              " 'universo': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9550>,\n",
              " 'oscuridad': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9590>,\n",
              " 'inscripción': <gensim.models.keyedvectors.Vocab at 0x7f734e7a95d0>,\n",
              " 'necesidad': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9610>,\n",
              " 'amado': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9650>,\n",
              " 'espejo': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9690>,\n",
              " 'manzanas': <gensim.models.keyedvectors.Vocab at 0x7f734e7a96d0>,\n",
              " 'ambición': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9710>,\n",
              " 'duda': <gensim.models.keyedvectors.Vocab at 0x7f734e7a9750>}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nota: Es importante verificar la relación entre la cantidad de palabras distintas y la cantidad de documentos (si no tengo suficientes documentos, tendría que considerar conseguir más datos). En este caso la relación no es demasiado grande."
      ],
      "metadata": {
        "id": "bV_XwerCub7S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar el modelo generador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1c5b9c-ee7e-4305-a8c0-b4fada43d788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 131642.609375\n",
            "Loss after epoch 1: 69173.484375\n",
            "Loss after epoch 2: 68818.5\n",
            "Loss after epoch 3: 68297.25\n",
            "Loss after epoch 4: 69722.875\n",
            "Loss after epoch 5: 68597.53125\n",
            "Loss after epoch 6: 67334.6875\n",
            "Loss after epoch 7: 69152.5\n",
            "Loss after epoch 8: 70996.5\n",
            "Loss after epoch 9: 68548.625\n",
            "Loss after epoch 10: 68871.75\n",
            "Loss after epoch 11: 67932.8125\n",
            "Loss after epoch 12: 67133.0625\n",
            "Loss after epoch 13: 66634.4375\n",
            "Loss after epoch 14: 61493.625\n",
            "Loss after epoch 15: 58107.25\n",
            "Loss after epoch 16: 57744.875\n",
            "Loss after epoch 17: 56499.125\n",
            "Loss after epoch 18: 56224.5\n",
            "Loss after epoch 19: 54786.25\n",
            "Loss after epoch 20: 55461.0\n",
            "Loss after epoch 21: 54022.625\n",
            "Loss after epoch 22: 54549.75\n",
            "Loss after epoch 23: 53794.75\n",
            "Loss after epoch 24: 52945.5\n",
            "Loss after epoch 25: 52298.75\n",
            "Loss after epoch 26: 52276.375\n",
            "Loss after epoch 27: 51107.75\n",
            "Loss after epoch 28: 50929.5\n",
            "Loss after epoch 29: 50799.5\n",
            "Loss after epoch 30: 50701.375\n",
            "Loss after epoch 31: 50447.25\n",
            "Loss after epoch 32: 49395.625\n",
            "Loss after epoch 33: 49459.5\n",
            "Loss after epoch 34: 45558.5\n",
            "Loss after epoch 35: 45943.75\n",
            "Loss after epoch 36: 45394.25\n",
            "Loss after epoch 37: 44647.75\n",
            "Loss after epoch 38: 45062.5\n",
            "Loss after epoch 39: 44245.25\n",
            "Loss after epoch 40: 45178.0\n",
            "Loss after epoch 41: 44981.0\n",
            "Loss after epoch 42: 44916.75\n",
            "Loss after epoch 43: 45135.5\n",
            "Loss after epoch 44: 43951.5\n",
            "Loss after epoch 45: 44794.25\n",
            "Loss after epoch 46: 44467.0\n",
            "Loss after epoch 47: 43779.0\n",
            "Loss after epoch 48: 44024.25\n",
            "Loss after epoch 49: 43711.25\n",
            "Loss after epoch 50: 43103.5\n",
            "Loss after epoch 51: 44348.0\n",
            "Loss after epoch 52: 43890.5\n",
            "Loss after epoch 53: 44009.25\n",
            "Loss after epoch 54: 43875.5\n",
            "Loss after epoch 55: 43914.0\n",
            "Loss after epoch 56: 44036.25\n",
            "Loss after epoch 57: 44435.25\n",
            "Loss after epoch 58: 43775.5\n",
            "Loss after epoch 59: 43608.25\n",
            "Loss after epoch 60: 42952.75\n",
            "Loss after epoch 61: 43300.5\n",
            "Loss after epoch 62: 44488.25\n",
            "Loss after epoch 63: 43795.75\n",
            "Loss after epoch 64: 43621.5\n",
            "Loss after epoch 65: 43623.5\n",
            "Loss after epoch 66: 43303.75\n",
            "Loss after epoch 67: 42863.75\n",
            "Loss after epoch 68: 43296.0\n",
            "Loss after epoch 69: 43003.5\n",
            "Loss after epoch 70: 43134.25\n",
            "Loss after epoch 71: 43188.75\n",
            "Loss after epoch 72: 43969.5\n",
            "Loss after epoch 73: 42872.25\n",
            "Loss after epoch 74: 43897.0\n",
            "Loss after epoch 75: 43239.5\n",
            "Loss after epoch 76: 43682.5\n",
            "Loss after epoch 77: 42954.0\n",
            "Loss after epoch 78: 43539.0\n",
            "Loss after epoch 79: 43385.25\n",
            "Loss after epoch 80: 43025.0\n",
            "Loss after epoch 81: 43049.25\n",
            "Loss after epoch 82: 40305.0\n",
            "Loss after epoch 83: 40945.5\n",
            "Loss after epoch 84: 40953.5\n",
            "Loss after epoch 85: 40384.0\n",
            "Loss after epoch 86: 40374.0\n",
            "Loss after epoch 87: 41110.0\n",
            "Loss after epoch 88: 40679.0\n",
            "Loss after epoch 89: 40904.0\n",
            "Loss after epoch 90: 40477.0\n",
            "Loss after epoch 91: 40620.5\n",
            "Loss after epoch 92: 40176.0\n",
            "Loss after epoch 93: 40185.0\n",
            "Loss after epoch 94: 40554.5\n",
            "Loss after epoch 95: 40223.5\n",
            "Loss after epoch 96: 41135.0\n",
            "Loss after epoch 97: 40975.0\n",
            "Loss after epoch 98: 40845.0\n",
            "Loss after epoch 99: 40423.5\n",
            "Loss after epoch 100: 40318.0\n",
            "Loss after epoch 101: 40201.0\n",
            "Loss after epoch 102: 40720.0\n",
            "Loss after epoch 103: 40068.5\n",
            "Loss after epoch 104: 40311.5\n",
            "Loss after epoch 105: 40766.5\n",
            "Loss after epoch 106: 40328.5\n",
            "Loss after epoch 107: 40542.0\n",
            "Loss after epoch 108: 39916.0\n",
            "Loss after epoch 109: 40268.0\n",
            "Loss after epoch 110: 39999.0\n",
            "Loss after epoch 111: 39675.5\n",
            "Loss after epoch 112: 40207.5\n",
            "Loss after epoch 113: 40595.0\n",
            "Loss after epoch 114: 40841.5\n",
            "Loss after epoch 115: 40435.0\n",
            "Loss after epoch 116: 40332.5\n",
            "Loss after epoch 117: 40082.5\n",
            "Loss after epoch 118: 40633.5\n",
            "Loss after epoch 119: 39799.0\n",
            "Loss after epoch 120: 40425.0\n",
            "Loss after epoch 121: 40283.5\n",
            "Loss after epoch 122: 40290.5\n",
            "Loss after epoch 123: 39997.0\n",
            "Loss after epoch 124: 39950.0\n",
            "Loss after epoch 125: 40212.0\n",
            "Loss after epoch 126: 39843.5\n",
            "Loss after epoch 127: 39993.5\n",
            "Loss after epoch 128: 40535.5\n",
            "Loss after epoch 129: 39951.0\n",
            "Loss after epoch 130: 39608.5\n",
            "Loss after epoch 131: 40604.0\n",
            "Loss after epoch 132: 40098.0\n",
            "Loss after epoch 133: 41325.0\n",
            "Loss after epoch 134: 39862.5\n",
            "Loss after epoch 135: 40329.5\n",
            "Loss after epoch 136: 40057.5\n",
            "Loss after epoch 137: 39745.5\n",
            "Loss after epoch 138: 40280.0\n",
            "Loss after epoch 139: 39887.0\n",
            "Loss after epoch 140: 38935.5\n",
            "Loss after epoch 141: 40340.0\n",
            "Loss after epoch 142: 40569.5\n",
            "Loss after epoch 143: 40191.0\n",
            "Loss after epoch 144: 40288.5\n",
            "Loss after epoch 145: 40012.0\n",
            "Loss after epoch 146: 40885.0\n",
            "Loss after epoch 147: 40026.5\n",
            "Loss after epoch 148: 39453.5\n",
            "Loss after epoch 149: 39736.5\n",
            "Loss after epoch 150: 40158.0\n",
            "Loss after epoch 151: 39909.0\n",
            "Loss after epoch 152: 40791.0\n",
            "Loss after epoch 153: 39665.5\n",
            "Loss after epoch 154: 40450.0\n",
            "Loss after epoch 155: 39674.0\n",
            "Loss after epoch 156: 39956.0\n",
            "Loss after epoch 157: 39651.5\n",
            "Loss after epoch 158: 39732.0\n",
            "Loss after epoch 159: 40510.5\n",
            "Loss after epoch 160: 40269.5\n",
            "Loss after epoch 161: 40070.0\n",
            "Loss after epoch 162: 39097.5\n",
            "Loss after epoch 163: 40146.5\n",
            "Loss after epoch 164: 39712.0\n",
            "Loss after epoch 165: 39417.5\n",
            "Loss after epoch 166: 39283.5\n",
            "Loss after epoch 167: 40488.5\n",
            "Loss after epoch 168: 39357.5\n",
            "Loss after epoch 169: 39963.0\n",
            "Loss after epoch 170: 40408.5\n",
            "Loss after epoch 171: 40093.0\n",
            "Loss after epoch 172: 39653.0\n",
            "Loss after epoch 173: 39898.0\n",
            "Loss after epoch 174: 40552.5\n",
            "Loss after epoch 175: 40549.5\n",
            "Loss after epoch 176: 39806.5\n",
            "Loss after epoch 177: 40712.0\n",
            "Loss after epoch 178: 40474.0\n",
            "Loss after epoch 179: 40216.5\n",
            "Loss after epoch 180: 39802.0\n",
            "Loss after epoch 181: 40462.0\n",
            "Loss after epoch 182: 40459.0\n",
            "Loss after epoch 183: 40535.0\n",
            "Loss after epoch 184: 40787.5\n",
            "Loss after epoch 185: 40325.5\n",
            "Loss after epoch 186: 37985.0\n",
            "Loss after epoch 187: 37387.0\n",
            "Loss after epoch 188: 37312.0\n",
            "Loss after epoch 189: 37376.0\n",
            "Loss after epoch 190: 38129.0\n",
            "Loss after epoch 191: 37574.0\n",
            "Loss after epoch 192: 37363.0\n",
            "Loss after epoch 193: 36971.0\n",
            "Loss after epoch 194: 37887.0\n",
            "Loss after epoch 195: 37799.0\n",
            "Loss after epoch 196: 36575.0\n",
            "Loss after epoch 197: 37633.0\n",
            "Loss after epoch 198: 37410.0\n",
            "Loss after epoch 199: 38891.0\n",
            "Loss after epoch 200: 36756.0\n",
            "Loss after epoch 201: 37689.0\n",
            "Loss after epoch 202: 37957.0\n",
            "Loss after epoch 203: 38511.0\n",
            "Loss after epoch 204: 36712.0\n",
            "Loss after epoch 205: 38196.0\n",
            "Loss after epoch 206: 37958.0\n",
            "Loss after epoch 207: 38046.0\n",
            "Loss after epoch 208: 37219.0\n",
            "Loss after epoch 209: 38245.0\n",
            "Loss after epoch 210: 37129.0\n",
            "Loss after epoch 211: 37766.0\n",
            "Loss after epoch 212: 37172.0\n",
            "Loss after epoch 213: 37646.0\n",
            "Loss after epoch 214: 37081.0\n",
            "Loss after epoch 215: 36950.0\n",
            "Loss after epoch 216: 37235.0\n",
            "Loss after epoch 217: 36871.0\n",
            "Loss after epoch 218: 37546.0\n",
            "Loss after epoch 219: 37959.0\n",
            "Loss after epoch 220: 37998.0\n",
            "Loss after epoch 221: 37362.0\n",
            "Loss after epoch 222: 37695.0\n",
            "Loss after epoch 223: 37785.0\n",
            "Loss after epoch 224: 37113.0\n",
            "Loss after epoch 225: 37757.0\n",
            "Loss after epoch 226: 38074.0\n",
            "Loss after epoch 227: 37655.0\n",
            "Loss after epoch 228: 36962.0\n",
            "Loss after epoch 229: 37374.0\n",
            "Loss after epoch 230: 37380.0\n",
            "Loss after epoch 231: 37462.0\n",
            "Loss after epoch 232: 37650.0\n",
            "Loss after epoch 233: 38402.0\n",
            "Loss after epoch 234: 37647.0\n",
            "Loss after epoch 235: 37676.0\n",
            "Loss after epoch 236: 36742.0\n",
            "Loss after epoch 237: 37119.0\n",
            "Loss after epoch 238: 38279.0\n",
            "Loss after epoch 239: 37979.0\n",
            "Loss after epoch 240: 38037.0\n",
            "Loss after epoch 241: 37819.0\n",
            "Loss after epoch 242: 37132.0\n",
            "Loss after epoch 243: 37351.0\n",
            "Loss after epoch 244: 37566.0\n",
            "Loss after epoch 245: 37721.0\n",
            "Loss after epoch 246: 37963.0\n",
            "Loss after epoch 247: 37682.0\n",
            "Loss after epoch 248: 37805.0\n",
            "Loss after epoch 249: 37238.0\n",
            "Loss after epoch 250: 37675.0\n",
            "Loss after epoch 251: 38183.0\n",
            "Loss after epoch 252: 38555.0\n",
            "Loss after epoch 253: 37259.0\n",
            "Loss after epoch 254: 37808.0\n",
            "Loss after epoch 255: 37278.0\n",
            "Loss after epoch 256: 37420.0\n",
            "Loss after epoch 257: 36925.0\n",
            "Loss after epoch 258: 37550.0\n",
            "Loss after epoch 259: 37175.0\n",
            "Loss after epoch 260: 37497.0\n",
            "Loss after epoch 261: 37367.0\n",
            "Loss after epoch 262: 36838.0\n",
            "Loss after epoch 263: 37944.0\n",
            "Loss after epoch 264: 38072.0\n",
            "Loss after epoch 265: 38257.0\n",
            "Loss after epoch 266: 37817.0\n",
            "Loss after epoch 267: 37911.0\n",
            "Loss after epoch 268: 37567.0\n",
            "Loss after epoch 269: 37769.0\n",
            "Loss after epoch 270: 37388.0\n",
            "Loss after epoch 271: 36413.0\n",
            "Loss after epoch 272: 37255.0\n",
            "Loss after epoch 273: 37403.0\n",
            "Loss after epoch 274: 37318.0\n",
            "Loss after epoch 275: 37590.0\n",
            "Loss after epoch 276: 37447.0\n",
            "Loss after epoch 277: 37720.0\n",
            "Loss after epoch 278: 36780.0\n",
            "Loss after epoch 279: 38314.0\n",
            "Loss after epoch 280: 37293.0\n",
            "Loss after epoch 281: 36975.0\n",
            "Loss after epoch 282: 37476.0\n",
            "Loss after epoch 283: 37533.0\n",
            "Loss after epoch 284: 38348.0\n",
            "Loss after epoch 285: 37871.0\n",
            "Loss after epoch 286: 37555.0\n",
            "Loss after epoch 287: 37387.0\n",
            "Loss after epoch 288: 37629.0\n",
            "Loss after epoch 289: 37769.0\n",
            "Loss after epoch 290: 37520.0\n",
            "Loss after epoch 291: 37028.0\n",
            "Loss after epoch 292: 37079.0\n",
            "Loss after epoch 293: 36889.0\n",
            "Loss after epoch 294: 38042.0\n",
            "Loss after epoch 295: 37726.0\n",
            "Loss after epoch 296: 37144.0\n",
            "Loss after epoch 297: 37062.0\n",
            "Loss after epoch 298: 37425.0\n",
            "Loss after epoch 299: 37384.0\n",
            "Loss after epoch 300: 36840.0\n",
            "Loss after epoch 301: 37577.0\n",
            "Loss after epoch 302: 37468.0\n",
            "Loss after epoch 303: 37369.0\n",
            "Loss after epoch 304: 37473.0\n",
            "Loss after epoch 305: 37279.0\n",
            "Loss after epoch 306: 37334.0\n",
            "Loss after epoch 307: 36687.0\n",
            "Loss after epoch 308: 37876.0\n",
            "Loss after epoch 309: 37670.0\n",
            "Loss after epoch 310: 37361.0\n",
            "Loss after epoch 311: 37438.0\n",
            "Loss after epoch 312: 38281.0\n",
            "Loss after epoch 313: 37746.0\n",
            "Loss after epoch 314: 36914.0\n",
            "Loss after epoch 315: 38067.0\n",
            "Loss after epoch 316: 38402.0\n",
            "Loss after epoch 317: 36821.0\n",
            "Loss after epoch 318: 38215.0\n",
            "Loss after epoch 319: 37452.0\n",
            "Loss after epoch 320: 37351.0\n",
            "Loss after epoch 321: 37399.0\n",
            "Loss after epoch 322: 37359.0\n",
            "Loss after epoch 323: 37195.0\n",
            "Loss after epoch 324: 37490.0\n",
            "Loss after epoch 325: 38279.0\n",
            "Loss after epoch 326: 37627.0\n",
            "Loss after epoch 327: 37735.0\n",
            "Loss after epoch 328: 37376.0\n",
            "Loss after epoch 329: 37962.0\n",
            "Loss after epoch 330: 37050.0\n",
            "Loss after epoch 331: 37256.0\n",
            "Loss after epoch 332: 37350.0\n",
            "Loss after epoch 333: 37463.0\n",
            "Loss after epoch 334: 37480.0\n",
            "Loss after epoch 335: 37119.0\n",
            "Loss after epoch 336: 37554.0\n",
            "Loss after epoch 337: 37314.0\n",
            "Loss after epoch 338: 37320.0\n",
            "Loss after epoch 339: 36821.0\n",
            "Loss after epoch 340: 36974.0\n",
            "Loss after epoch 341: 36988.0\n",
            "Loss after epoch 342: 37202.0\n",
            "Loss after epoch 343: 36828.0\n",
            "Loss after epoch 344: 37766.0\n",
            "Loss after epoch 345: 37703.0\n",
            "Loss after epoch 346: 37664.0\n",
            "Loss after epoch 347: 37743.0\n",
            "Loss after epoch 348: 37587.0\n",
            "Loss after epoch 349: 37729.0\n",
            "Loss after epoch 350: 37598.0\n",
            "Loss after epoch 351: 37446.0\n",
            "Loss after epoch 352: 37320.0\n",
            "Loss after epoch 353: 37680.0\n",
            "Loss after epoch 354: 37072.0\n",
            "Loss after epoch 355: 37247.0\n",
            "Loss after epoch 356: 37343.0\n",
            "Loss after epoch 357: 38181.0\n",
            "Loss after epoch 358: 37603.0\n",
            "Loss after epoch 359: 37397.0\n",
            "Loss after epoch 360: 37500.0\n",
            "Loss after epoch 361: 36648.0\n",
            "Loss after epoch 362: 37223.0\n",
            "Loss after epoch 363: 36919.0\n",
            "Loss after epoch 364: 37636.0\n",
            "Loss after epoch 365: 37072.0\n",
            "Loss after epoch 366: 37435.0\n",
            "Loss after epoch 367: 37439.0\n",
            "Loss after epoch 368: 37368.0\n",
            "Loss after epoch 369: 37620.0\n",
            "Loss after epoch 370: 37475.0\n",
            "Loss after epoch 371: 36712.0\n",
            "Loss after epoch 372: 37394.0\n",
            "Loss after epoch 373: 37597.0\n",
            "Loss after epoch 374: 37482.0\n",
            "Loss after epoch 375: 38075.0\n",
            "Loss after epoch 376: 37666.0\n",
            "Loss after epoch 377: 37006.0\n",
            "Loss after epoch 378: 37229.0\n",
            "Loss after epoch 379: 36802.0\n",
            "Loss after epoch 380: 37423.0\n",
            "Loss after epoch 381: 37813.0\n",
            "Loss after epoch 382: 37522.0\n",
            "Loss after epoch 383: 37028.0\n",
            "Loss after epoch 384: 36311.0\n",
            "Loss after epoch 385: 37407.0\n",
            "Loss after epoch 386: 37272.0\n",
            "Loss after epoch 387: 37029.0\n",
            "Loss after epoch 388: 37362.0\n",
            "Loss after epoch 389: 37363.0\n",
            "Loss after epoch 390: 36901.0\n",
            "Loss after epoch 391: 37676.0\n",
            "Loss after epoch 392: 37570.0\n",
            "Loss after epoch 393: 37801.0\n",
            "Loss after epoch 394: 36912.0\n",
            "Loss after epoch 395: 36579.0\n",
            "Loss after epoch 396: 37398.0\n",
            "Loss after epoch 397: 37120.0\n",
            "Loss after epoch 398: 37093.0\n",
            "Loss after epoch 399: 37435.0\n",
            "Loss after epoch 400: 37044.0\n",
            "Loss after epoch 401: 36747.0\n",
            "Loss after epoch 402: 36549.0\n",
            "Loss after epoch 403: 36768.0\n",
            "Loss after epoch 404: 37088.0\n",
            "Loss after epoch 405: 37146.0\n",
            "Loss after epoch 406: 37154.0\n",
            "Loss after epoch 407: 36944.0\n",
            "Loss after epoch 408: 37254.0\n",
            "Loss after epoch 409: 37038.0\n",
            "Loss after epoch 410: 34270.0\n",
            "Loss after epoch 411: 34880.0\n",
            "Loss after epoch 412: 34156.0\n",
            "Loss after epoch 413: 33640.0\n",
            "Loss after epoch 414: 34648.0\n",
            "Loss after epoch 415: 34522.0\n",
            "Loss after epoch 416: 35278.0\n",
            "Loss after epoch 417: 33860.0\n",
            "Loss after epoch 418: 34550.0\n",
            "Loss after epoch 419: 33918.0\n",
            "Loss after epoch 420: 34522.0\n",
            "Loss after epoch 421: 34286.0\n",
            "Loss after epoch 422: 34746.0\n",
            "Loss after epoch 423: 33838.0\n",
            "Loss after epoch 424: 33854.0\n",
            "Loss after epoch 425: 35440.0\n",
            "Loss after epoch 426: 34100.0\n",
            "Loss after epoch 427: 34448.0\n",
            "Loss after epoch 428: 34320.0\n",
            "Loss after epoch 429: 33728.0\n",
            "Loss after epoch 430: 33762.0\n",
            "Loss after epoch 431: 34620.0\n",
            "Loss after epoch 432: 34162.0\n",
            "Loss after epoch 433: 34400.0\n",
            "Loss after epoch 434: 34794.0\n",
            "Loss after epoch 435: 34236.0\n",
            "Loss after epoch 436: 34806.0\n",
            "Loss after epoch 437: 34464.0\n",
            "Loss after epoch 438: 34914.0\n",
            "Loss after epoch 439: 34442.0\n",
            "Loss after epoch 440: 33508.0\n",
            "Loss after epoch 441: 34506.0\n",
            "Loss after epoch 442: 34738.0\n",
            "Loss after epoch 443: 34464.0\n",
            "Loss after epoch 444: 34172.0\n",
            "Loss after epoch 445: 34938.0\n",
            "Loss after epoch 446: 34312.0\n",
            "Loss after epoch 447: 34684.0\n",
            "Loss after epoch 448: 34378.0\n",
            "Loss after epoch 449: 34022.0\n",
            "Loss after epoch 450: 35296.0\n",
            "Loss after epoch 451: 33812.0\n",
            "Loss after epoch 452: 34638.0\n",
            "Loss after epoch 453: 34080.0\n",
            "Loss after epoch 454: 34634.0\n",
            "Loss after epoch 455: 33794.0\n",
            "Loss after epoch 456: 34350.0\n",
            "Loss after epoch 457: 35038.0\n",
            "Loss after epoch 458: 33572.0\n",
            "Loss after epoch 459: 34626.0\n",
            "Loss after epoch 460: 34742.0\n",
            "Loss after epoch 461: 34330.0\n",
            "Loss after epoch 462: 34306.0\n",
            "Loss after epoch 463: 34912.0\n",
            "Loss after epoch 464: 34570.0\n",
            "Loss after epoch 465: 34412.0\n",
            "Loss after epoch 466: 33824.0\n",
            "Loss after epoch 467: 34716.0\n",
            "Loss after epoch 468: 33934.0\n",
            "Loss after epoch 469: 34496.0\n",
            "Loss after epoch 470: 34598.0\n",
            "Loss after epoch 471: 34634.0\n",
            "Loss after epoch 472: 34770.0\n",
            "Loss after epoch 473: 34000.0\n",
            "Loss after epoch 474: 34346.0\n",
            "Loss after epoch 475: 34600.0\n",
            "Loss after epoch 476: 34568.0\n",
            "Loss after epoch 477: 33770.0\n",
            "Loss after epoch 478: 34176.0\n",
            "Loss after epoch 479: 33848.0\n",
            "Loss after epoch 480: 34958.0\n",
            "Loss after epoch 481: 34770.0\n",
            "Loss after epoch 482: 34414.0\n",
            "Loss after epoch 483: 33310.0\n",
            "Loss after epoch 484: 34952.0\n",
            "Loss after epoch 485: 33908.0\n",
            "Loss after epoch 486: 34126.0\n",
            "Loss after epoch 487: 33968.0\n",
            "Loss after epoch 488: 34964.0\n",
            "Loss after epoch 489: 34226.0\n",
            "Loss after epoch 490: 33722.0\n",
            "Loss after epoch 491: 33824.0\n",
            "Loss after epoch 492: 34512.0\n",
            "Loss after epoch 493: 34234.0\n",
            "Loss after epoch 494: 34526.0\n",
            "Loss after epoch 495: 33806.0\n",
            "Loss after epoch 496: 35178.0\n",
            "Loss after epoch 497: 33818.0\n",
            "Loss after epoch 498: 34552.0\n",
            "Loss after epoch 499: 34158.0\n",
            "Loss after epoch 500: 34022.0\n",
            "Loss after epoch 501: 34996.0\n",
            "Loss after epoch 502: 34308.0\n",
            "Loss after epoch 503: 35204.0\n",
            "Loss after epoch 504: 33976.0\n",
            "Loss after epoch 505: 33958.0\n",
            "Loss after epoch 506: 34060.0\n",
            "Loss after epoch 507: 33840.0\n",
            "Loss after epoch 508: 34776.0\n",
            "Loss after epoch 509: 33936.0\n",
            "Loss after epoch 510: 34950.0\n",
            "Loss after epoch 511: 33912.0\n",
            "Loss after epoch 512: 34328.0\n",
            "Loss after epoch 513: 33756.0\n",
            "Loss after epoch 514: 33880.0\n",
            "Loss after epoch 515: 33872.0\n",
            "Loss after epoch 516: 34498.0\n",
            "Loss after epoch 517: 34088.0\n",
            "Loss after epoch 518: 33976.0\n",
            "Loss after epoch 519: 34112.0\n",
            "Loss after epoch 520: 35084.0\n",
            "Loss after epoch 521: 33592.0\n",
            "Loss after epoch 522: 34368.0\n",
            "Loss after epoch 523: 34590.0\n",
            "Loss after epoch 524: 33554.0\n",
            "Loss after epoch 525: 33828.0\n",
            "Loss after epoch 526: 33876.0\n",
            "Loss after epoch 527: 34172.0\n",
            "Loss after epoch 528: 34186.0\n",
            "Loss after epoch 529: 34358.0\n",
            "Loss after epoch 530: 34966.0\n",
            "Loss after epoch 531: 33878.0\n",
            "Loss after epoch 532: 34270.0\n",
            "Loss after epoch 533: 34140.0\n",
            "Loss after epoch 534: 34682.0\n",
            "Loss after epoch 535: 34308.0\n",
            "Loss after epoch 536: 34304.0\n",
            "Loss after epoch 537: 34642.0\n",
            "Loss after epoch 538: 34898.0\n",
            "Loss after epoch 539: 34766.0\n",
            "Loss after epoch 540: 34760.0\n",
            "Loss after epoch 541: 34222.0\n",
            "Loss after epoch 542: 33822.0\n",
            "Loss after epoch 543: 34038.0\n",
            "Loss after epoch 544: 34716.0\n",
            "Loss after epoch 545: 34630.0\n",
            "Loss after epoch 546: 34592.0\n",
            "Loss after epoch 547: 34054.0\n",
            "Loss after epoch 548: 34198.0\n",
            "Loss after epoch 549: 34248.0\n",
            "Loss after epoch 550: 34316.0\n",
            "Loss after epoch 551: 34092.0\n",
            "Loss after epoch 552: 34838.0\n",
            "Loss after epoch 553: 34218.0\n",
            "Loss after epoch 554: 34134.0\n",
            "Loss after epoch 555: 34690.0\n",
            "Loss after epoch 556: 33854.0\n",
            "Loss after epoch 557: 34946.0\n",
            "Loss after epoch 558: 33868.0\n",
            "Loss after epoch 559: 34564.0\n",
            "Loss after epoch 560: 34350.0\n",
            "Loss after epoch 561: 33958.0\n",
            "Loss after epoch 562: 33986.0\n",
            "Loss after epoch 563: 33320.0\n",
            "Loss after epoch 564: 33854.0\n",
            "Loss after epoch 565: 34430.0\n",
            "Loss after epoch 566: 33446.0\n",
            "Loss after epoch 567: 33940.0\n",
            "Loss after epoch 568: 33438.0\n",
            "Loss after epoch 569: 34256.0\n",
            "Loss after epoch 570: 34500.0\n",
            "Loss after epoch 571: 33912.0\n",
            "Loss after epoch 572: 33746.0\n",
            "Loss after epoch 573: 34984.0\n",
            "Loss after epoch 574: 34804.0\n",
            "Loss after epoch 575: 33772.0\n",
            "Loss after epoch 576: 34428.0\n",
            "Loss after epoch 577: 34746.0\n",
            "Loss after epoch 578: 34232.0\n",
            "Loss after epoch 579: 33922.0\n",
            "Loss after epoch 580: 33838.0\n",
            "Loss after epoch 581: 33958.0\n",
            "Loss after epoch 582: 34118.0\n",
            "Loss after epoch 583: 34424.0\n",
            "Loss after epoch 584: 34468.0\n",
            "Loss after epoch 585: 34152.0\n",
            "Loss after epoch 586: 33878.0\n",
            "Loss after epoch 587: 34504.0\n",
            "Loss after epoch 588: 34322.0\n",
            "Loss after epoch 589: 34196.0\n",
            "Loss after epoch 590: 34512.0\n",
            "Loss after epoch 591: 34328.0\n",
            "Loss after epoch 592: 33890.0\n",
            "Loss after epoch 593: 34100.0\n",
            "Loss after epoch 594: 33858.0\n",
            "Loss after epoch 595: 33862.0\n",
            "Loss after epoch 596: 33004.0\n",
            "Loss after epoch 597: 34290.0\n",
            "Loss after epoch 598: 34470.0\n",
            "Loss after epoch 599: 34018.0\n",
            "Loss after epoch 600: 34090.0\n",
            "Loss after epoch 601: 34390.0\n",
            "Loss after epoch 602: 34280.0\n",
            "Loss after epoch 603: 34272.0\n",
            "Loss after epoch 604: 33710.0\n",
            "Loss after epoch 605: 33824.0\n",
            "Loss after epoch 606: 33606.0\n",
            "Loss after epoch 607: 34208.0\n",
            "Loss after epoch 608: 34520.0\n",
            "Loss after epoch 609: 34396.0\n",
            "Loss after epoch 610: 34654.0\n",
            "Loss after epoch 611: 34070.0\n",
            "Loss after epoch 612: 33546.0\n",
            "Loss after epoch 613: 33902.0\n",
            "Loss after epoch 614: 34586.0\n",
            "Loss after epoch 615: 34542.0\n",
            "Loss after epoch 616: 34056.0\n",
            "Loss after epoch 617: 33326.0\n",
            "Loss after epoch 618: 33756.0\n",
            "Loss after epoch 619: 34578.0\n",
            "Loss after epoch 620: 33008.0\n",
            "Loss after epoch 621: 33608.0\n",
            "Loss after epoch 622: 33834.0\n",
            "Loss after epoch 623: 34538.0\n",
            "Loss after epoch 624: 34720.0\n",
            "Loss after epoch 625: 33546.0\n",
            "Loss after epoch 626: 33940.0\n",
            "Loss after epoch 627: 34134.0\n",
            "Loss after epoch 628: 34126.0\n",
            "Loss after epoch 629: 33906.0\n",
            "Loss after epoch 630: 34328.0\n",
            "Loss after epoch 631: 33740.0\n",
            "Loss after epoch 632: 33624.0\n",
            "Loss after epoch 633: 33626.0\n",
            "Loss after epoch 634: 34874.0\n",
            "Loss after epoch 635: 34906.0\n",
            "Loss after epoch 636: 33744.0\n",
            "Loss after epoch 637: 33266.0\n",
            "Loss after epoch 638: 33876.0\n",
            "Loss after epoch 639: 34690.0\n",
            "Loss after epoch 640: 33920.0\n",
            "Loss after epoch 641: 34020.0\n",
            "Loss after epoch 642: 34014.0\n",
            "Loss after epoch 643: 34634.0\n",
            "Loss after epoch 644: 35022.0\n",
            "Loss after epoch 645: 33750.0\n",
            "Loss after epoch 646: 34020.0\n",
            "Loss after epoch 647: 33856.0\n",
            "Loss after epoch 648: 34258.0\n",
            "Loss after epoch 649: 33604.0\n",
            "Loss after epoch 650: 33710.0\n",
            "Loss after epoch 651: 34382.0\n",
            "Loss after epoch 652: 33622.0\n",
            "Loss after epoch 653: 34000.0\n",
            "Loss after epoch 654: 34476.0\n",
            "Loss after epoch 655: 34110.0\n",
            "Loss after epoch 656: 34214.0\n",
            "Loss after epoch 657: 34192.0\n",
            "Loss after epoch 658: 34988.0\n",
            "Loss after epoch 659: 33970.0\n",
            "Loss after epoch 660: 33952.0\n",
            "Loss after epoch 661: 33774.0\n",
            "Loss after epoch 662: 33958.0\n",
            "Loss after epoch 663: 33684.0\n",
            "Loss after epoch 664: 34230.0\n",
            "Loss after epoch 665: 33580.0\n",
            "Loss after epoch 666: 33168.0\n",
            "Loss after epoch 667: 33684.0\n",
            "Loss after epoch 668: 33794.0\n",
            "Loss after epoch 669: 33686.0\n",
            "Loss after epoch 670: 33700.0\n",
            "Loss after epoch 671: 33980.0\n",
            "Loss after epoch 672: 34674.0\n",
            "Loss after epoch 673: 33570.0\n",
            "Loss after epoch 674: 34228.0\n",
            "Loss after epoch 675: 34030.0\n",
            "Loss after epoch 676: 33776.0\n",
            "Loss after epoch 677: 33134.0\n",
            "Loss after epoch 678: 34570.0\n",
            "Loss after epoch 679: 33792.0\n",
            "Loss after epoch 680: 33116.0\n",
            "Loss after epoch 681: 33678.0\n",
            "Loss after epoch 682: 33782.0\n",
            "Loss after epoch 683: 33182.0\n",
            "Loss after epoch 684: 34474.0\n",
            "Loss after epoch 685: 33678.0\n",
            "Loss after epoch 686: 33446.0\n",
            "Loss after epoch 687: 33700.0\n",
            "Loss after epoch 688: 34504.0\n",
            "Loss after epoch 689: 34240.0\n",
            "Loss after epoch 690: 33286.0\n",
            "Loss after epoch 691: 34070.0\n",
            "Loss after epoch 692: 34174.0\n",
            "Loss after epoch 693: 34460.0\n",
            "Loss after epoch 694: 33806.0\n",
            "Loss after epoch 695: 33494.0\n",
            "Loss after epoch 696: 34528.0\n",
            "Loss after epoch 697: 34182.0\n",
            "Loss after epoch 698: 33476.0\n",
            "Loss after epoch 699: 34304.0\n",
            "Loss after epoch 700: 34222.0\n",
            "Loss after epoch 701: 33702.0\n",
            "Loss after epoch 702: 34074.0\n",
            "Loss after epoch 703: 33526.0\n",
            "Loss after epoch 704: 33724.0\n",
            "Loss after epoch 705: 34040.0\n",
            "Loss after epoch 706: 33740.0\n",
            "Loss after epoch 707: 34148.0\n",
            "Loss after epoch 708: 33450.0\n",
            "Loss after epoch 709: 33312.0\n",
            "Loss after epoch 710: 34192.0\n",
            "Loss after epoch 711: 34400.0\n",
            "Loss after epoch 712: 33592.0\n",
            "Loss after epoch 713: 33036.0\n",
            "Loss after epoch 714: 33482.0\n",
            "Loss after epoch 715: 34200.0\n",
            "Loss after epoch 716: 34228.0\n",
            "Loss after epoch 717: 34254.0\n",
            "Loss after epoch 718: 33896.0\n",
            "Loss after epoch 719: 33844.0\n",
            "Loss after epoch 720: 33894.0\n",
            "Loss after epoch 721: 34190.0\n",
            "Loss after epoch 722: 33944.0\n",
            "Loss after epoch 723: 34144.0\n",
            "Loss after epoch 724: 33726.0\n",
            "Loss after epoch 725: 33880.0\n",
            "Loss after epoch 726: 33844.0\n",
            "Loss after epoch 727: 33986.0\n",
            "Loss after epoch 728: 33292.0\n",
            "Loss after epoch 729: 34020.0\n",
            "Loss after epoch 730: 34280.0\n",
            "Loss after epoch 731: 34040.0\n",
            "Loss after epoch 732: 34390.0\n",
            "Loss after epoch 733: 33876.0\n",
            "Loss after epoch 734: 33916.0\n",
            "Loss after epoch 735: 34300.0\n",
            "Loss after epoch 736: 34374.0\n",
            "Loss after epoch 737: 33548.0\n",
            "Loss after epoch 738: 34030.0\n",
            "Loss after epoch 739: 32938.0\n",
            "Loss after epoch 740: 33356.0\n",
            "Loss after epoch 741: 34302.0\n",
            "Loss after epoch 742: 33640.0\n",
            "Loss after epoch 743: 33786.0\n",
            "Loss after epoch 744: 33472.0\n",
            "Loss after epoch 745: 33666.0\n",
            "Loss after epoch 746: 33694.0\n",
            "Loss after epoch 747: 33344.0\n",
            "Loss after epoch 748: 33982.0\n",
            "Loss after epoch 749: 33752.0\n",
            "Loss after epoch 750: 33982.0\n",
            "Loss after epoch 751: 33978.0\n",
            "Loss after epoch 752: 33652.0\n",
            "Loss after epoch 753: 33160.0\n",
            "Loss after epoch 754: 33952.0\n",
            "Loss after epoch 755: 34578.0\n",
            "Loss after epoch 756: 33896.0\n",
            "Loss after epoch 757: 33428.0\n",
            "Loss after epoch 758: 33708.0\n",
            "Loss after epoch 759: 34136.0\n",
            "Loss after epoch 760: 33350.0\n",
            "Loss after epoch 761: 33006.0\n",
            "Loss after epoch 762: 33508.0\n",
            "Loss after epoch 763: 33882.0\n",
            "Loss after epoch 764: 33368.0\n",
            "Loss after epoch 765: 33924.0\n",
            "Loss after epoch 766: 33132.0\n",
            "Loss after epoch 767: 34544.0\n",
            "Loss after epoch 768: 33068.0\n",
            "Loss after epoch 769: 33442.0\n",
            "Loss after epoch 770: 34250.0\n",
            "Loss after epoch 771: 33678.0\n",
            "Loss after epoch 772: 34672.0\n",
            "Loss after epoch 773: 33512.0\n",
            "Loss after epoch 774: 33608.0\n",
            "Loss after epoch 775: 33328.0\n",
            "Loss after epoch 776: 33976.0\n",
            "Loss after epoch 777: 33444.0\n",
            "Loss after epoch 778: 33922.0\n",
            "Loss after epoch 779: 33328.0\n",
            "Loss after epoch 780: 33618.0\n",
            "Loss after epoch 781: 33610.0\n",
            "Loss after epoch 782: 33818.0\n",
            "Loss after epoch 783: 33024.0\n",
            "Loss after epoch 784: 33228.0\n",
            "Loss after epoch 785: 34050.0\n",
            "Loss after epoch 786: 33944.0\n",
            "Loss after epoch 787: 34434.0\n",
            "Loss after epoch 788: 33880.0\n",
            "Loss after epoch 789: 33878.0\n",
            "Loss after epoch 790: 33456.0\n",
            "Loss after epoch 791: 34080.0\n",
            "Loss after epoch 792: 33540.0\n",
            "Loss after epoch 793: 33138.0\n",
            "Loss after epoch 794: 33822.0\n",
            "Loss after epoch 795: 33700.0\n",
            "Loss after epoch 796: 34280.0\n",
            "Loss after epoch 797: 33868.0\n",
            "Loss after epoch 798: 33782.0\n",
            "Loss after epoch 799: 33718.0\n",
            "Loss after epoch 800: 34072.0\n",
            "Loss after epoch 801: 33826.0\n",
            "Loss after epoch 802: 34016.0\n",
            "Loss after epoch 803: 33290.0\n",
            "Loss after epoch 804: 33636.0\n",
            "Loss after epoch 805: 33948.0\n",
            "Loss after epoch 806: 34000.0\n",
            "Loss after epoch 807: 34396.0\n",
            "Loss after epoch 808: 32618.0\n",
            "Loss after epoch 809: 33214.0\n",
            "Loss after epoch 810: 33404.0\n",
            "Loss after epoch 811: 33744.0\n",
            "Loss after epoch 812: 33666.0\n",
            "Loss after epoch 813: 33200.0\n",
            "Loss after epoch 814: 33752.0\n",
            "Loss after epoch 815: 33784.0\n",
            "Loss after epoch 816: 33488.0\n",
            "Loss after epoch 817: 33360.0\n",
            "Loss after epoch 818: 34484.0\n",
            "Loss after epoch 819: 33296.0\n",
            "Loss after epoch 820: 34154.0\n",
            "Loss after epoch 821: 33266.0\n",
            "Loss after epoch 822: 33762.0\n",
            "Loss after epoch 823: 33726.0\n",
            "Loss after epoch 824: 33354.0\n",
            "Loss after epoch 825: 33404.0\n",
            "Loss after epoch 826: 34072.0\n",
            "Loss after epoch 827: 33776.0\n",
            "Loss after epoch 828: 33386.0\n",
            "Loss after epoch 829: 34134.0\n",
            "Loss after epoch 830: 33774.0\n",
            "Loss after epoch 831: 33770.0\n",
            "Loss after epoch 832: 33682.0\n",
            "Loss after epoch 833: 33048.0\n",
            "Loss after epoch 834: 33574.0\n",
            "Loss after epoch 835: 33784.0\n",
            "Loss after epoch 836: 33216.0\n",
            "Loss after epoch 837: 33798.0\n",
            "Loss after epoch 838: 33772.0\n",
            "Loss after epoch 839: 34080.0\n",
            "Loss after epoch 840: 33312.0\n",
            "Loss after epoch 841: 33388.0\n",
            "Loss after epoch 842: 34096.0\n",
            "Loss after epoch 843: 33954.0\n",
            "Loss after epoch 844: 33682.0\n",
            "Loss after epoch 845: 32710.0\n",
            "Loss after epoch 846: 33348.0\n",
            "Loss after epoch 847: 34456.0\n",
            "Loss after epoch 848: 33522.0\n",
            "Loss after epoch 849: 33602.0\n",
            "Loss after epoch 850: 33468.0\n",
            "Loss after epoch 851: 33722.0\n",
            "Loss after epoch 852: 33824.0\n",
            "Loss after epoch 853: 33730.0\n",
            "Loss after epoch 854: 34382.0\n",
            "Loss after epoch 855: 33546.0\n",
            "Loss after epoch 856: 33114.0\n",
            "Loss after epoch 857: 33322.0\n",
            "Loss after epoch 858: 33740.0\n",
            "Loss after epoch 859: 33210.0\n",
            "Loss after epoch 860: 33552.0\n",
            "Loss after epoch 861: 33662.0\n",
            "Loss after epoch 862: 33594.0\n",
            "Loss after epoch 863: 33214.0\n",
            "Loss after epoch 864: 33614.0\n",
            "Loss after epoch 865: 34164.0\n",
            "Loss after epoch 866: 33102.0\n",
            "Loss after epoch 867: 33078.0\n",
            "Loss after epoch 868: 33550.0\n",
            "Loss after epoch 869: 33644.0\n",
            "Loss after epoch 870: 33566.0\n",
            "Loss after epoch 871: 33160.0\n",
            "Loss after epoch 872: 33298.0\n",
            "Loss after epoch 873: 33368.0\n",
            "Loss after epoch 874: 33082.0\n",
            "Loss after epoch 875: 33880.0\n",
            "Loss after epoch 876: 33230.0\n",
            "Loss after epoch 877: 33800.0\n",
            "Loss after epoch 878: 33356.0\n",
            "Loss after epoch 879: 32854.0\n",
            "Loss after epoch 880: 33958.0\n",
            "Loss after epoch 881: 33822.0\n",
            "Loss after epoch 882: 33270.0\n",
            "Loss after epoch 883: 33900.0\n",
            "Loss after epoch 884: 32854.0\n",
            "Loss after epoch 885: 33544.0\n",
            "Loss after epoch 886: 33068.0\n",
            "Loss after epoch 887: 33516.0\n",
            "Loss after epoch 888: 32966.0\n",
            "Loss after epoch 889: 33936.0\n",
            "Loss after epoch 890: 33964.0\n",
            "Loss after epoch 891: 33202.0\n",
            "Loss after epoch 892: 33446.0\n",
            "Loss after epoch 893: 33296.0\n",
            "Loss after epoch 894: 33392.0\n",
            "Loss after epoch 895: 32876.0\n",
            "Loss after epoch 896: 33170.0\n",
            "Loss after epoch 897: 33464.0\n",
            "Loss after epoch 898: 33492.0\n",
            "Loss after epoch 899: 32754.0\n",
            "Loss after epoch 900: 33396.0\n",
            "Loss after epoch 901: 33314.0\n",
            "Loss after epoch 902: 33200.0\n",
            "Loss after epoch 903: 32582.0\n",
            "Loss after epoch 904: 28712.0\n",
            "Loss after epoch 905: 29836.0\n",
            "Loss after epoch 906: 28964.0\n",
            "Loss after epoch 907: 30040.0\n",
            "Loss after epoch 908: 29896.0\n",
            "Loss after epoch 909: 29664.0\n",
            "Loss after epoch 910: 29272.0\n",
            "Loss after epoch 911: 29912.0\n",
            "Loss after epoch 912: 29544.0\n",
            "Loss after epoch 913: 28728.0\n",
            "Loss after epoch 914: 30464.0\n",
            "Loss after epoch 915: 29276.0\n",
            "Loss after epoch 916: 29576.0\n",
            "Loss after epoch 917: 30504.0\n",
            "Loss after epoch 918: 29972.0\n",
            "Loss after epoch 919: 28744.0\n",
            "Loss after epoch 920: 28812.0\n",
            "Loss after epoch 921: 29140.0\n",
            "Loss after epoch 922: 28176.0\n",
            "Loss after epoch 923: 28804.0\n",
            "Loss after epoch 924: 28296.0\n",
            "Loss after epoch 925: 29888.0\n",
            "Loss after epoch 926: 30028.0\n",
            "Loss after epoch 927: 29416.0\n",
            "Loss after epoch 928: 29512.0\n",
            "Loss after epoch 929: 29048.0\n",
            "Loss after epoch 930: 29840.0\n",
            "Loss after epoch 931: 29032.0\n",
            "Loss after epoch 932: 29560.0\n",
            "Loss after epoch 933: 29908.0\n",
            "Loss after epoch 934: 29408.0\n",
            "Loss after epoch 935: 29588.0\n",
            "Loss after epoch 936: 29120.0\n",
            "Loss after epoch 937: 29852.0\n",
            "Loss after epoch 938: 28900.0\n",
            "Loss after epoch 939: 28924.0\n",
            "Loss after epoch 940: 28796.0\n",
            "Loss after epoch 941: 28384.0\n",
            "Loss after epoch 942: 28544.0\n",
            "Loss after epoch 943: 29020.0\n",
            "Loss after epoch 944: 29388.0\n",
            "Loss after epoch 945: 29188.0\n",
            "Loss after epoch 946: 29292.0\n",
            "Loss after epoch 947: 29800.0\n",
            "Loss after epoch 948: 29164.0\n",
            "Loss after epoch 949: 28636.0\n",
            "Loss after epoch 950: 29364.0\n",
            "Loss after epoch 951: 29188.0\n",
            "Loss after epoch 952: 27948.0\n",
            "Loss after epoch 953: 30080.0\n",
            "Loss after epoch 954: 28648.0\n",
            "Loss after epoch 955: 29792.0\n",
            "Loss after epoch 956: 29312.0\n",
            "Loss after epoch 957: 30116.0\n",
            "Loss after epoch 958: 29064.0\n",
            "Loss after epoch 959: 29532.0\n",
            "Loss after epoch 960: 29012.0\n",
            "Loss after epoch 961: 29420.0\n",
            "Loss after epoch 962: 29180.0\n",
            "Loss after epoch 963: 28248.0\n",
            "Loss after epoch 964: 28892.0\n",
            "Loss after epoch 965: 29356.0\n",
            "Loss after epoch 966: 28192.0\n",
            "Loss after epoch 967: 29612.0\n",
            "Loss after epoch 968: 28904.0\n",
            "Loss after epoch 969: 29192.0\n",
            "Loss after epoch 970: 28764.0\n",
            "Loss after epoch 971: 30020.0\n",
            "Loss after epoch 972: 28836.0\n",
            "Loss after epoch 973: 29016.0\n",
            "Loss after epoch 974: 29188.0\n",
            "Loss after epoch 975: 29824.0\n",
            "Loss after epoch 976: 29776.0\n",
            "Loss after epoch 977: 29064.0\n",
            "Loss after epoch 978: 29440.0\n",
            "Loss after epoch 979: 28884.0\n",
            "Loss after epoch 980: 29532.0\n",
            "Loss after epoch 981: 29400.0\n",
            "Loss after epoch 982: 28680.0\n",
            "Loss after epoch 983: 28524.0\n",
            "Loss after epoch 984: 28992.0\n",
            "Loss after epoch 985: 29144.0\n",
            "Loss after epoch 986: 29368.0\n",
            "Loss after epoch 987: 29512.0\n",
            "Loss after epoch 988: 28604.0\n",
            "Loss after epoch 989: 28228.0\n",
            "Loss after epoch 990: 29728.0\n",
            "Loss after epoch 991: 29180.0\n",
            "Loss after epoch 992: 28900.0\n",
            "Loss after epoch 993: 29024.0\n",
            "Loss after epoch 994: 29072.0\n",
            "Loss after epoch 995: 29760.0\n",
            "Loss after epoch 996: 29396.0\n",
            "Loss after epoch 997: 29460.0\n",
            "Loss after epoch 998: 29072.0\n",
            "Loss after epoch 999: 28828.0\n",
            "Loss after epoch 1000: 28576.0\n",
            "Loss after epoch 1001: 28888.0\n",
            "Loss after epoch 1002: 29052.0\n",
            "Loss after epoch 1003: 28168.0\n",
            "Loss after epoch 1004: 29968.0\n",
            "Loss after epoch 1005: 29644.0\n",
            "Loss after epoch 1006: 29300.0\n",
            "Loss after epoch 1007: 28908.0\n",
            "Loss after epoch 1008: 28416.0\n",
            "Loss after epoch 1009: 28976.0\n",
            "Loss after epoch 1010: 28692.0\n",
            "Loss after epoch 1011: 27836.0\n",
            "Loss after epoch 1012: 28876.0\n",
            "Loss after epoch 1013: 29036.0\n",
            "Loss after epoch 1014: 28780.0\n",
            "Loss after epoch 1015: 29056.0\n",
            "Loss after epoch 1016: 29280.0\n",
            "Loss after epoch 1017: 29136.0\n",
            "Loss after epoch 1018: 28784.0\n",
            "Loss after epoch 1019: 29920.0\n",
            "Loss after epoch 1020: 29340.0\n",
            "Loss after epoch 1021: 29524.0\n",
            "Loss after epoch 1022: 28764.0\n",
            "Loss after epoch 1023: 28376.0\n",
            "Loss after epoch 1024: 29752.0\n",
            "Loss after epoch 1025: 29268.0\n",
            "Loss after epoch 1026: 29400.0\n",
            "Loss after epoch 1027: 29816.0\n",
            "Loss after epoch 1028: 29792.0\n",
            "Loss after epoch 1029: 29968.0\n",
            "Loss after epoch 1030: 28844.0\n",
            "Loss after epoch 1031: 29592.0\n",
            "Loss after epoch 1032: 29560.0\n",
            "Loss after epoch 1033: 30072.0\n",
            "Loss after epoch 1034: 29076.0\n",
            "Loss after epoch 1035: 29376.0\n",
            "Loss after epoch 1036: 29144.0\n",
            "Loss after epoch 1037: 29536.0\n",
            "Loss after epoch 1038: 28948.0\n",
            "Loss after epoch 1039: 29400.0\n",
            "Loss after epoch 1040: 28896.0\n",
            "Loss after epoch 1041: 29108.0\n",
            "Loss after epoch 1042: 29020.0\n",
            "Loss after epoch 1043: 29524.0\n",
            "Loss after epoch 1044: 28996.0\n",
            "Loss after epoch 1045: 28408.0\n",
            "Loss after epoch 1046: 28148.0\n",
            "Loss after epoch 1047: 29348.0\n",
            "Loss after epoch 1048: 28300.0\n",
            "Loss after epoch 1049: 29616.0\n",
            "Loss after epoch 1050: 28568.0\n",
            "Loss after epoch 1051: 28280.0\n",
            "Loss after epoch 1052: 30000.0\n",
            "Loss after epoch 1053: 28644.0\n",
            "Loss after epoch 1054: 29156.0\n",
            "Loss after epoch 1055: 29296.0\n",
            "Loss after epoch 1056: 28040.0\n",
            "Loss after epoch 1057: 28848.0\n",
            "Loss after epoch 1058: 28292.0\n",
            "Loss after epoch 1059: 28504.0\n",
            "Loss after epoch 1060: 28588.0\n",
            "Loss after epoch 1061: 28996.0\n",
            "Loss after epoch 1062: 28520.0\n",
            "Loss after epoch 1063: 28376.0\n",
            "Loss after epoch 1064: 29576.0\n",
            "Loss after epoch 1065: 29480.0\n",
            "Loss after epoch 1066: 29100.0\n",
            "Loss after epoch 1067: 28784.0\n",
            "Loss after epoch 1068: 29864.0\n",
            "Loss after epoch 1069: 28980.0\n",
            "Loss after epoch 1070: 28460.0\n",
            "Loss after epoch 1071: 28548.0\n",
            "Loss after epoch 1072: 29252.0\n",
            "Loss after epoch 1073: 28824.0\n",
            "Loss after epoch 1074: 28980.0\n",
            "Loss after epoch 1075: 30192.0\n",
            "Loss after epoch 1076: 29156.0\n",
            "Loss after epoch 1077: 28660.0\n",
            "Loss after epoch 1078: 29384.0\n",
            "Loss after epoch 1079: 29204.0\n",
            "Loss after epoch 1080: 28388.0\n",
            "Loss after epoch 1081: 29132.0\n",
            "Loss after epoch 1082: 28856.0\n",
            "Loss after epoch 1083: 29196.0\n",
            "Loss after epoch 1084: 29484.0\n",
            "Loss after epoch 1085: 28432.0\n",
            "Loss after epoch 1086: 28920.0\n",
            "Loss after epoch 1087: 28336.0\n",
            "Loss after epoch 1088: 28544.0\n",
            "Loss after epoch 1089: 29748.0\n",
            "Loss after epoch 1090: 28564.0\n",
            "Loss after epoch 1091: 28804.0\n",
            "Loss after epoch 1092: 29048.0\n",
            "Loss after epoch 1093: 29236.0\n",
            "Loss after epoch 1094: 28840.0\n",
            "Loss after epoch 1095: 28988.0\n",
            "Loss after epoch 1096: 29320.0\n",
            "Loss after epoch 1097: 29212.0\n",
            "Loss after epoch 1098: 28564.0\n",
            "Loss after epoch 1099: 28920.0\n",
            "Loss after epoch 1100: 28492.0\n",
            "Loss after epoch 1101: 29152.0\n",
            "Loss after epoch 1102: 29056.0\n",
            "Loss after epoch 1103: 29172.0\n",
            "Loss after epoch 1104: 29004.0\n",
            "Loss after epoch 1105: 29560.0\n",
            "Loss after epoch 1106: 29116.0\n",
            "Loss after epoch 1107: 29616.0\n",
            "Loss after epoch 1108: 27892.0\n",
            "Loss after epoch 1109: 27840.0\n",
            "Loss after epoch 1110: 28184.0\n",
            "Loss after epoch 1111: 29184.0\n",
            "Loss after epoch 1112: 28688.0\n",
            "Loss after epoch 1113: 28980.0\n",
            "Loss after epoch 1114: 28908.0\n",
            "Loss after epoch 1115: 28372.0\n",
            "Loss after epoch 1116: 29304.0\n",
            "Loss after epoch 1117: 28964.0\n",
            "Loss after epoch 1118: 29432.0\n",
            "Loss after epoch 1119: 28940.0\n",
            "Loss after epoch 1120: 28484.0\n",
            "Loss after epoch 1121: 29384.0\n",
            "Loss after epoch 1122: 29444.0\n",
            "Loss after epoch 1123: 28328.0\n",
            "Loss after epoch 1124: 29688.0\n",
            "Loss after epoch 1125: 28732.0\n",
            "Loss after epoch 1126: 29108.0\n",
            "Loss after epoch 1127: 27672.0\n",
            "Loss after epoch 1128: 28956.0\n",
            "Loss after epoch 1129: 27936.0\n",
            "Loss after epoch 1130: 29240.0\n",
            "Loss after epoch 1131: 28504.0\n",
            "Loss after epoch 1132: 28160.0\n",
            "Loss after epoch 1133: 28376.0\n",
            "Loss after epoch 1134: 29240.0\n",
            "Loss after epoch 1135: 28412.0\n",
            "Loss after epoch 1136: 28520.0\n",
            "Loss after epoch 1137: 29848.0\n",
            "Loss after epoch 1138: 28760.0\n",
            "Loss after epoch 1139: 28468.0\n",
            "Loss after epoch 1140: 29220.0\n",
            "Loss after epoch 1141: 29212.0\n",
            "Loss after epoch 1142: 29132.0\n",
            "Loss after epoch 1143: 28900.0\n",
            "Loss after epoch 1144: 28192.0\n",
            "Loss after epoch 1145: 29008.0\n",
            "Loss after epoch 1146: 28656.0\n",
            "Loss after epoch 1147: 28124.0\n",
            "Loss after epoch 1148: 28684.0\n",
            "Loss after epoch 1149: 28900.0\n",
            "Loss after epoch 1150: 28976.0\n",
            "Loss after epoch 1151: 28968.0\n",
            "Loss after epoch 1152: 28896.0\n",
            "Loss after epoch 1153: 28760.0\n",
            "Loss after epoch 1154: 28708.0\n",
            "Loss after epoch 1155: 27644.0\n",
            "Loss after epoch 1156: 28912.0\n",
            "Loss after epoch 1157: 28840.0\n",
            "Loss after epoch 1158: 28668.0\n",
            "Loss after epoch 1159: 27712.0\n",
            "Loss after epoch 1160: 29076.0\n",
            "Loss after epoch 1161: 28780.0\n",
            "Loss after epoch 1162: 27844.0\n",
            "Loss after epoch 1163: 28760.0\n",
            "Loss after epoch 1164: 28968.0\n",
            "Loss after epoch 1165: 28640.0\n",
            "Loss after epoch 1166: 29344.0\n",
            "Loss after epoch 1167: 28004.0\n",
            "Loss after epoch 1168: 28316.0\n",
            "Loss after epoch 1169: 28336.0\n",
            "Loss after epoch 1170: 28600.0\n",
            "Loss after epoch 1171: 28160.0\n",
            "Loss after epoch 1172: 28860.0\n",
            "Loss after epoch 1173: 28564.0\n",
            "Loss after epoch 1174: 28612.0\n",
            "Loss after epoch 1175: 28920.0\n",
            "Loss after epoch 1176: 29200.0\n",
            "Loss after epoch 1177: 28724.0\n",
            "Loss after epoch 1178: 29140.0\n",
            "Loss after epoch 1179: 28536.0\n",
            "Loss after epoch 1180: 28468.0\n",
            "Loss after epoch 1181: 28520.0\n",
            "Loss after epoch 1182: 28848.0\n",
            "Loss after epoch 1183: 29372.0\n",
            "Loss after epoch 1184: 28672.0\n",
            "Loss after epoch 1185: 29008.0\n",
            "Loss after epoch 1186: 28112.0\n",
            "Loss after epoch 1187: 29128.0\n",
            "Loss after epoch 1188: 28352.0\n",
            "Loss after epoch 1189: 28724.0\n",
            "Loss after epoch 1190: 28440.0\n",
            "Loss after epoch 1191: 28544.0\n",
            "Loss after epoch 1192: 29116.0\n",
            "Loss after epoch 1193: 29044.0\n",
            "Loss after epoch 1194: 29136.0\n",
            "Loss after epoch 1195: 28604.0\n",
            "Loss after epoch 1196: 29052.0\n",
            "Loss after epoch 1197: 28172.0\n",
            "Loss after epoch 1198: 28456.0\n",
            "Loss after epoch 1199: 27908.0\n",
            "Loss after epoch 1200: 27868.0\n",
            "Loss after epoch 1201: 28280.0\n",
            "Loss after epoch 1202: 27928.0\n",
            "Loss after epoch 1203: 29236.0\n",
            "Loss after epoch 1204: 28548.0\n",
            "Loss after epoch 1205: 29120.0\n",
            "Loss after epoch 1206: 28084.0\n",
            "Loss after epoch 1207: 29320.0\n",
            "Loss after epoch 1208: 27940.0\n",
            "Loss after epoch 1209: 28416.0\n",
            "Loss after epoch 1210: 28036.0\n",
            "Loss after epoch 1211: 28984.0\n",
            "Loss after epoch 1212: 28976.0\n",
            "Loss after epoch 1213: 28852.0\n",
            "Loss after epoch 1214: 28268.0\n",
            "Loss after epoch 1215: 28892.0\n",
            "Loss after epoch 1216: 28384.0\n",
            "Loss after epoch 1217: 29156.0\n",
            "Loss after epoch 1218: 29328.0\n",
            "Loss after epoch 1219: 28932.0\n",
            "Loss after epoch 1220: 28164.0\n",
            "Loss after epoch 1221: 28972.0\n",
            "Loss after epoch 1222: 28572.0\n",
            "Loss after epoch 1223: 27596.0\n",
            "Loss after epoch 1224: 27952.0\n",
            "Loss after epoch 1225: 28592.0\n",
            "Loss after epoch 1226: 27800.0\n",
            "Loss after epoch 1227: 29604.0\n",
            "Loss after epoch 1228: 28796.0\n",
            "Loss after epoch 1229: 28096.0\n",
            "Loss after epoch 1230: 28000.0\n",
            "Loss after epoch 1231: 28256.0\n",
            "Loss after epoch 1232: 28788.0\n",
            "Loss after epoch 1233: 29040.0\n",
            "Loss after epoch 1234: 28368.0\n",
            "Loss after epoch 1235: 28276.0\n",
            "Loss after epoch 1236: 27968.0\n",
            "Loss after epoch 1237: 28784.0\n",
            "Loss after epoch 1238: 27960.0\n",
            "Loss after epoch 1239: 28504.0\n",
            "Loss after epoch 1240: 28796.0\n",
            "Loss after epoch 1241: 28592.0\n",
            "Loss after epoch 1242: 27708.0\n",
            "Loss after epoch 1243: 28712.0\n",
            "Loss after epoch 1244: 28508.0\n",
            "Loss after epoch 1245: 28920.0\n",
            "Loss after epoch 1246: 28668.0\n",
            "Loss after epoch 1247: 28316.0\n",
            "Loss after epoch 1248: 28460.0\n",
            "Loss after epoch 1249: 28800.0\n",
            "Loss after epoch 1250: 27800.0\n",
            "Loss after epoch 1251: 27684.0\n",
            "Loss after epoch 1252: 28756.0\n",
            "Loss after epoch 1253: 28016.0\n",
            "Loss after epoch 1254: 30352.0\n",
            "Loss after epoch 1255: 28080.0\n",
            "Loss after epoch 1256: 28508.0\n",
            "Loss after epoch 1257: 28664.0\n",
            "Loss after epoch 1258: 28132.0\n",
            "Loss after epoch 1259: 29068.0\n",
            "Loss after epoch 1260: 27868.0\n",
            "Loss after epoch 1261: 29236.0\n",
            "Loss after epoch 1262: 28080.0\n",
            "Loss after epoch 1263: 28656.0\n",
            "Loss after epoch 1264: 28496.0\n",
            "Loss after epoch 1265: 28936.0\n",
            "Loss after epoch 1266: 28528.0\n",
            "Loss after epoch 1267: 29244.0\n",
            "Loss after epoch 1268: 29740.0\n",
            "Loss after epoch 1269: 28492.0\n",
            "Loss after epoch 1270: 27592.0\n",
            "Loss after epoch 1271: 28932.0\n",
            "Loss after epoch 1272: 27528.0\n",
            "Loss after epoch 1273: 27840.0\n",
            "Loss after epoch 1274: 27816.0\n",
            "Loss after epoch 1275: 28676.0\n",
            "Loss after epoch 1276: 28968.0\n",
            "Loss after epoch 1277: 28156.0\n",
            "Loss after epoch 1278: 27916.0\n",
            "Loss after epoch 1279: 28836.0\n",
            "Loss after epoch 1280: 28976.0\n",
            "Loss after epoch 1281: 28880.0\n",
            "Loss after epoch 1282: 27408.0\n",
            "Loss after epoch 1283: 29064.0\n",
            "Loss after epoch 1284: 27540.0\n",
            "Loss after epoch 1285: 28868.0\n",
            "Loss after epoch 1286: 27512.0\n",
            "Loss after epoch 1287: 28524.0\n",
            "Loss after epoch 1288: 28084.0\n",
            "Loss after epoch 1289: 28112.0\n",
            "Loss after epoch 1290: 28220.0\n",
            "Loss after epoch 1291: 28600.0\n",
            "Loss after epoch 1292: 27544.0\n",
            "Loss after epoch 1293: 27564.0\n",
            "Loss after epoch 1294: 28076.0\n",
            "Loss after epoch 1295: 28356.0\n",
            "Loss after epoch 1296: 28192.0\n",
            "Loss after epoch 1297: 27864.0\n",
            "Loss after epoch 1298: 28940.0\n",
            "Loss after epoch 1299: 28944.0\n",
            "Loss after epoch 1300: 27780.0\n",
            "Loss after epoch 1301: 28168.0\n",
            "Loss after epoch 1302: 28588.0\n",
            "Loss after epoch 1303: 28600.0\n",
            "Loss after epoch 1304: 27900.0\n",
            "Loss after epoch 1305: 28608.0\n",
            "Loss after epoch 1306: 27788.0\n",
            "Loss after epoch 1307: 28504.0\n",
            "Loss after epoch 1308: 27656.0\n",
            "Loss after epoch 1309: 28284.0\n",
            "Loss after epoch 1310: 27892.0\n",
            "Loss after epoch 1311: 28272.0\n",
            "Loss after epoch 1312: 28256.0\n",
            "Loss after epoch 1313: 28656.0\n",
            "Loss after epoch 1314: 28604.0\n",
            "Loss after epoch 1315: 28528.0\n",
            "Loss after epoch 1316: 28744.0\n",
            "Loss after epoch 1317: 28004.0\n",
            "Loss after epoch 1318: 28668.0\n",
            "Loss after epoch 1319: 29652.0\n",
            "Loss after epoch 1320: 27884.0\n",
            "Loss after epoch 1321: 27816.0\n",
            "Loss after epoch 1322: 27664.0\n",
            "Loss after epoch 1323: 27572.0\n",
            "Loss after epoch 1324: 28708.0\n",
            "Loss after epoch 1325: 28416.0\n",
            "Loss after epoch 1326: 28576.0\n",
            "Loss after epoch 1327: 27936.0\n",
            "Loss after epoch 1328: 28236.0\n",
            "Loss after epoch 1329: 27780.0\n",
            "Loss after epoch 1330: 28684.0\n",
            "Loss after epoch 1331: 28860.0\n",
            "Loss after epoch 1332: 28704.0\n",
            "Loss after epoch 1333: 28336.0\n",
            "Loss after epoch 1334: 27828.0\n",
            "Loss after epoch 1335: 28468.0\n",
            "Loss after epoch 1336: 27832.0\n",
            "Loss after epoch 1337: 27928.0\n",
            "Loss after epoch 1338: 28020.0\n",
            "Loss after epoch 1339: 27904.0\n",
            "Loss after epoch 1340: 28484.0\n",
            "Loss after epoch 1341: 27320.0\n",
            "Loss after epoch 1342: 28160.0\n",
            "Loss after epoch 1343: 28124.0\n",
            "Loss after epoch 1344: 27684.0\n",
            "Loss after epoch 1345: 27900.0\n",
            "Loss after epoch 1346: 28364.0\n",
            "Loss after epoch 1347: 28724.0\n",
            "Loss after epoch 1348: 27736.0\n",
            "Loss after epoch 1349: 28264.0\n",
            "Loss after epoch 1350: 28476.0\n",
            "Loss after epoch 1351: 28660.0\n",
            "Loss after epoch 1352: 27804.0\n",
            "Loss after epoch 1353: 28260.0\n",
            "Loss after epoch 1354: 28416.0\n",
            "Loss after epoch 1355: 28692.0\n",
            "Loss after epoch 1356: 27956.0\n",
            "Loss after epoch 1357: 28920.0\n",
            "Loss after epoch 1358: 28228.0\n",
            "Loss after epoch 1359: 28872.0\n",
            "Loss after epoch 1360: 29004.0\n",
            "Loss after epoch 1361: 28568.0\n",
            "Loss after epoch 1362: 28024.0\n",
            "Loss after epoch 1363: 27960.0\n",
            "Loss after epoch 1364: 27684.0\n",
            "Loss after epoch 1365: 28296.0\n",
            "Loss after epoch 1366: 28328.0\n",
            "Loss after epoch 1367: 27608.0\n",
            "Loss after epoch 1368: 28656.0\n",
            "Loss after epoch 1369: 27316.0\n",
            "Loss after epoch 1370: 27688.0\n",
            "Loss after epoch 1371: 28392.0\n",
            "Loss after epoch 1372: 28400.0\n",
            "Loss after epoch 1373: 27860.0\n",
            "Loss after epoch 1374: 27520.0\n",
            "Loss after epoch 1375: 27992.0\n",
            "Loss after epoch 1376: 27864.0\n",
            "Loss after epoch 1377: 28108.0\n",
            "Loss after epoch 1378: 27984.0\n",
            "Loss after epoch 1379: 29388.0\n",
            "Loss after epoch 1380: 28172.0\n",
            "Loss after epoch 1381: 28280.0\n",
            "Loss after epoch 1382: 27516.0\n",
            "Loss after epoch 1383: 28144.0\n",
            "Loss after epoch 1384: 28060.0\n",
            "Loss after epoch 1385: 28260.0\n",
            "Loss after epoch 1386: 27960.0\n",
            "Loss after epoch 1387: 27756.0\n",
            "Loss after epoch 1388: 28552.0\n",
            "Loss after epoch 1389: 27220.0\n",
            "Loss after epoch 1390: 27956.0\n",
            "Loss after epoch 1391: 27684.0\n",
            "Loss after epoch 1392: 28956.0\n",
            "Loss after epoch 1393: 27212.0\n",
            "Loss after epoch 1394: 28640.0\n",
            "Loss after epoch 1395: 28540.0\n",
            "Loss after epoch 1396: 27880.0\n",
            "Loss after epoch 1397: 28228.0\n",
            "Loss after epoch 1398: 29016.0\n",
            "Loss after epoch 1399: 28676.0\n",
            "Loss after epoch 1400: 28184.0\n",
            "Loss after epoch 1401: 28068.0\n",
            "Loss after epoch 1402: 27720.0\n",
            "Loss after epoch 1403: 27912.0\n",
            "Loss after epoch 1404: 27056.0\n",
            "Loss after epoch 1405: 26856.0\n",
            "Loss after epoch 1406: 27908.0\n",
            "Loss after epoch 1407: 27864.0\n",
            "Loss after epoch 1408: 27560.0\n",
            "Loss after epoch 1409: 27928.0\n",
            "Loss after epoch 1410: 26864.0\n",
            "Loss after epoch 1411: 27556.0\n",
            "Loss after epoch 1412: 28268.0\n",
            "Loss after epoch 1413: 27456.0\n",
            "Loss after epoch 1414: 27360.0\n",
            "Loss after epoch 1415: 27592.0\n",
            "Loss after epoch 1416: 27824.0\n",
            "Loss after epoch 1417: 28036.0\n",
            "Loss after epoch 1418: 27984.0\n",
            "Loss after epoch 1419: 27008.0\n",
            "Loss after epoch 1420: 27992.0\n",
            "Loss after epoch 1421: 28604.0\n",
            "Loss after epoch 1422: 27348.0\n",
            "Loss after epoch 1423: 28232.0\n",
            "Loss after epoch 1424: 28168.0\n",
            "Loss after epoch 1425: 27520.0\n",
            "Loss after epoch 1426: 27600.0\n",
            "Loss after epoch 1427: 28568.0\n",
            "Loss after epoch 1428: 28676.0\n",
            "Loss after epoch 1429: 28208.0\n",
            "Loss after epoch 1430: 28908.0\n",
            "Loss after epoch 1431: 27924.0\n",
            "Loss after epoch 1432: 28472.0\n",
            "Loss after epoch 1433: 27492.0\n",
            "Loss after epoch 1434: 27336.0\n",
            "Loss after epoch 1435: 28216.0\n",
            "Loss after epoch 1436: 27732.0\n",
            "Loss after epoch 1437: 28076.0\n",
            "Loss after epoch 1438: 27544.0\n",
            "Loss after epoch 1439: 27308.0\n",
            "Loss after epoch 1440: 27284.0\n",
            "Loss after epoch 1441: 28204.0\n",
            "Loss after epoch 1442: 27588.0\n",
            "Loss after epoch 1443: 28568.0\n",
            "Loss after epoch 1444: 26748.0\n",
            "Loss after epoch 1445: 28188.0\n",
            "Loss after epoch 1446: 28948.0\n",
            "Loss after epoch 1447: 28012.0\n",
            "Loss after epoch 1448: 27800.0\n",
            "Loss after epoch 1449: 27392.0\n",
            "Loss after epoch 1450: 27480.0\n",
            "Loss after epoch 1451: 27380.0\n",
            "Loss after epoch 1452: 27824.0\n",
            "Loss after epoch 1453: 27388.0\n",
            "Loss after epoch 1454: 28520.0\n",
            "Loss after epoch 1455: 27964.0\n",
            "Loss after epoch 1456: 27604.0\n",
            "Loss after epoch 1457: 27404.0\n",
            "Loss after epoch 1458: 27640.0\n",
            "Loss after epoch 1459: 28448.0\n",
            "Loss after epoch 1460: 26976.0\n",
            "Loss after epoch 1461: 27008.0\n",
            "Loss after epoch 1462: 28068.0\n",
            "Loss after epoch 1463: 28568.0\n",
            "Loss after epoch 1464: 27808.0\n",
            "Loss after epoch 1465: 28472.0\n",
            "Loss after epoch 1466: 27644.0\n",
            "Loss after epoch 1467: 27300.0\n",
            "Loss after epoch 1468: 28876.0\n",
            "Loss after epoch 1469: 27640.0\n",
            "Loss after epoch 1470: 27588.0\n",
            "Loss after epoch 1471: 27832.0\n",
            "Loss after epoch 1472: 27600.0\n",
            "Loss after epoch 1473: 26756.0\n",
            "Loss after epoch 1474: 28468.0\n",
            "Loss after epoch 1475: 28296.0\n",
            "Loss after epoch 1476: 26504.0\n",
            "Loss after epoch 1477: 27644.0\n",
            "Loss after epoch 1478: 27572.0\n",
            "Loss after epoch 1479: 27128.0\n",
            "Loss after epoch 1480: 28020.0\n",
            "Loss after epoch 1481: 27688.0\n",
            "Loss after epoch 1482: 27900.0\n",
            "Loss after epoch 1483: 27748.0\n",
            "Loss after epoch 1484: 27512.0\n",
            "Loss after epoch 1485: 27116.0\n",
            "Loss after epoch 1486: 28188.0\n",
            "Loss after epoch 1487: 27932.0\n",
            "Loss after epoch 1488: 27572.0\n",
            "Loss after epoch 1489: 27832.0\n",
            "Loss after epoch 1490: 27488.0\n",
            "Loss after epoch 1491: 27700.0\n",
            "Loss after epoch 1492: 27772.0\n",
            "Loss after epoch 1493: 26816.0\n",
            "Loss after epoch 1494: 26884.0\n",
            "Loss after epoch 1495: 27448.0\n",
            "Loss after epoch 1496: 27316.0\n",
            "Loss after epoch 1497: 27692.0\n",
            "Loss after epoch 1498: 27980.0\n",
            "Loss after epoch 1499: 28068.0\n",
            "Loss after epoch 1500: 28180.0\n",
            "Loss after epoch 1501: 27832.0\n",
            "Loss after epoch 1502: 28160.0\n",
            "Loss after epoch 1503: 28100.0\n",
            "Loss after epoch 1504: 28232.0\n",
            "Loss after epoch 1505: 27288.0\n",
            "Loss after epoch 1506: 27952.0\n",
            "Loss after epoch 1507: 27892.0\n",
            "Loss after epoch 1508: 27852.0\n",
            "Loss after epoch 1509: 28268.0\n",
            "Loss after epoch 1510: 27164.0\n",
            "Loss after epoch 1511: 27244.0\n",
            "Loss after epoch 1512: 27644.0\n",
            "Loss after epoch 1513: 27356.0\n",
            "Loss after epoch 1514: 27108.0\n",
            "Loss after epoch 1515: 27092.0\n",
            "Loss after epoch 1516: 27848.0\n",
            "Loss after epoch 1517: 26904.0\n",
            "Loss after epoch 1518: 28556.0\n",
            "Loss after epoch 1519: 28476.0\n",
            "Loss after epoch 1520: 28044.0\n",
            "Loss after epoch 1521: 27512.0\n",
            "Loss after epoch 1522: 27456.0\n",
            "Loss after epoch 1523: 28068.0\n",
            "Loss after epoch 1524: 27536.0\n",
            "Loss after epoch 1525: 26920.0\n",
            "Loss after epoch 1526: 28384.0\n",
            "Loss after epoch 1527: 26632.0\n",
            "Loss after epoch 1528: 27996.0\n",
            "Loss after epoch 1529: 28460.0\n",
            "Loss after epoch 1530: 27324.0\n",
            "Loss after epoch 1531: 28880.0\n",
            "Loss after epoch 1532: 27192.0\n",
            "Loss after epoch 1533: 27364.0\n",
            "Loss after epoch 1534: 27944.0\n",
            "Loss after epoch 1535: 27444.0\n",
            "Loss after epoch 1536: 27664.0\n",
            "Loss after epoch 1537: 27248.0\n",
            "Loss after epoch 1538: 27556.0\n",
            "Loss after epoch 1539: 26888.0\n",
            "Loss after epoch 1540: 26696.0\n",
            "Loss after epoch 1541: 27916.0\n",
            "Loss after epoch 1542: 26916.0\n",
            "Loss after epoch 1543: 28172.0\n",
            "Loss after epoch 1544: 27624.0\n",
            "Loss after epoch 1545: 28228.0\n",
            "Loss after epoch 1546: 28036.0\n",
            "Loss after epoch 1547: 27368.0\n",
            "Loss after epoch 1548: 27704.0\n",
            "Loss after epoch 1549: 28368.0\n",
            "Loss after epoch 1550: 27488.0\n",
            "Loss after epoch 1551: 27900.0\n",
            "Loss after epoch 1552: 27784.0\n",
            "Loss after epoch 1553: 27456.0\n",
            "Loss after epoch 1554: 27544.0\n",
            "Loss after epoch 1555: 27516.0\n",
            "Loss after epoch 1556: 27708.0\n",
            "Loss after epoch 1557: 27680.0\n",
            "Loss after epoch 1558: 26876.0\n",
            "Loss after epoch 1559: 27012.0\n",
            "Loss after epoch 1560: 27972.0\n",
            "Loss after epoch 1561: 27736.0\n",
            "Loss after epoch 1562: 27604.0\n",
            "Loss after epoch 1563: 27256.0\n",
            "Loss after epoch 1564: 26736.0\n",
            "Loss after epoch 1565: 28824.0\n",
            "Loss after epoch 1566: 27468.0\n",
            "Loss after epoch 1567: 26984.0\n",
            "Loss after epoch 1568: 27736.0\n",
            "Loss after epoch 1569: 27580.0\n",
            "Loss after epoch 1570: 26936.0\n",
            "Loss after epoch 1571: 27912.0\n",
            "Loss after epoch 1572: 28056.0\n",
            "Loss after epoch 1573: 28004.0\n",
            "Loss after epoch 1574: 27272.0\n",
            "Loss after epoch 1575: 27536.0\n",
            "Loss after epoch 1576: 26548.0\n",
            "Loss after epoch 1577: 27644.0\n",
            "Loss after epoch 1578: 27696.0\n",
            "Loss after epoch 1579: 27052.0\n",
            "Loss after epoch 1580: 27180.0\n",
            "Loss after epoch 1581: 26872.0\n",
            "Loss after epoch 1582: 27096.0\n",
            "Loss after epoch 1583: 27528.0\n",
            "Loss after epoch 1584: 27688.0\n",
            "Loss after epoch 1585: 26388.0\n",
            "Loss after epoch 1586: 28080.0\n",
            "Loss after epoch 1587: 27316.0\n",
            "Loss after epoch 1588: 27456.0\n",
            "Loss after epoch 1589: 27336.0\n",
            "Loss after epoch 1590: 27464.0\n",
            "Loss after epoch 1591: 27628.0\n",
            "Loss after epoch 1592: 27192.0\n",
            "Loss after epoch 1593: 27340.0\n",
            "Loss after epoch 1594: 27000.0\n",
            "Loss after epoch 1595: 27120.0\n",
            "Loss after epoch 1596: 26944.0\n",
            "Loss after epoch 1597: 26964.0\n",
            "Loss after epoch 1598: 26696.0\n",
            "Loss after epoch 1599: 27244.0\n",
            "Loss after epoch 1600: 27796.0\n",
            "Loss after epoch 1601: 27324.0\n",
            "Loss after epoch 1602: 26836.0\n",
            "Loss after epoch 1603: 26236.0\n",
            "Loss after epoch 1604: 26760.0\n",
            "Loss after epoch 1605: 27072.0\n",
            "Loss after epoch 1606: 26532.0\n",
            "Loss after epoch 1607: 27124.0\n",
            "Loss after epoch 1608: 27580.0\n",
            "Loss after epoch 1609: 26912.0\n",
            "Loss after epoch 1610: 27320.0\n",
            "Loss after epoch 1611: 27276.0\n",
            "Loss after epoch 1612: 27724.0\n",
            "Loss after epoch 1613: 27164.0\n",
            "Loss after epoch 1614: 27788.0\n",
            "Loss after epoch 1615: 26656.0\n",
            "Loss after epoch 1616: 27612.0\n",
            "Loss after epoch 1617: 27324.0\n",
            "Loss after epoch 1618: 26916.0\n",
            "Loss after epoch 1619: 27348.0\n",
            "Loss after epoch 1620: 26956.0\n",
            "Loss after epoch 1621: 26176.0\n",
            "Loss after epoch 1622: 27440.0\n",
            "Loss after epoch 1623: 28060.0\n",
            "Loss after epoch 1624: 27268.0\n",
            "Loss after epoch 1625: 26284.0\n",
            "Loss after epoch 1626: 26912.0\n",
            "Loss after epoch 1627: 26856.0\n",
            "Loss after epoch 1628: 27372.0\n",
            "Loss after epoch 1629: 27436.0\n",
            "Loss after epoch 1630: 28192.0\n",
            "Loss after epoch 1631: 27448.0\n",
            "Loss after epoch 1632: 27920.0\n",
            "Loss after epoch 1633: 27776.0\n",
            "Loss after epoch 1634: 26972.0\n",
            "Loss after epoch 1635: 26960.0\n",
            "Loss after epoch 1636: 27176.0\n",
            "Loss after epoch 1637: 27072.0\n",
            "Loss after epoch 1638: 28444.0\n",
            "Loss after epoch 1639: 27124.0\n",
            "Loss after epoch 1640: 27012.0\n",
            "Loss after epoch 1641: 27924.0\n",
            "Loss after epoch 1642: 27068.0\n",
            "Loss after epoch 1643: 27376.0\n",
            "Loss after epoch 1644: 27680.0\n",
            "Loss after epoch 1645: 27236.0\n",
            "Loss after epoch 1646: 28328.0\n",
            "Loss after epoch 1647: 27020.0\n",
            "Loss after epoch 1648: 27244.0\n",
            "Loss after epoch 1649: 27460.0\n",
            "Loss after epoch 1650: 28100.0\n",
            "Loss after epoch 1651: 26124.0\n",
            "Loss after epoch 1652: 26992.0\n",
            "Loss after epoch 1653: 27328.0\n",
            "Loss after epoch 1654: 26984.0\n",
            "Loss after epoch 1655: 27364.0\n",
            "Loss after epoch 1656: 27724.0\n",
            "Loss after epoch 1657: 27580.0\n",
            "Loss after epoch 1658: 26960.0\n",
            "Loss after epoch 1659: 27156.0\n",
            "Loss after epoch 1660: 27520.0\n",
            "Loss after epoch 1661: 26956.0\n",
            "Loss after epoch 1662: 27116.0\n",
            "Loss after epoch 1663: 27972.0\n",
            "Loss after epoch 1664: 27864.0\n",
            "Loss after epoch 1665: 26264.0\n",
            "Loss after epoch 1666: 27668.0\n",
            "Loss after epoch 1667: 26740.0\n",
            "Loss after epoch 1668: 27216.0\n",
            "Loss after epoch 1669: 27660.0\n",
            "Loss after epoch 1670: 27032.0\n",
            "Loss after epoch 1671: 27944.0\n",
            "Loss after epoch 1672: 27728.0\n",
            "Loss after epoch 1673: 27224.0\n",
            "Loss after epoch 1674: 27560.0\n",
            "Loss after epoch 1675: 28560.0\n",
            "Loss after epoch 1676: 27620.0\n",
            "Loss after epoch 1677: 27596.0\n",
            "Loss after epoch 1678: 26668.0\n",
            "Loss after epoch 1679: 26944.0\n",
            "Loss after epoch 1680: 26240.0\n",
            "Loss after epoch 1681: 27076.0\n",
            "Loss after epoch 1682: 27292.0\n",
            "Loss after epoch 1683: 27688.0\n",
            "Loss after epoch 1684: 27044.0\n",
            "Loss after epoch 1685: 26184.0\n",
            "Loss after epoch 1686: 26516.0\n",
            "Loss after epoch 1687: 26436.0\n",
            "Loss after epoch 1688: 27368.0\n",
            "Loss after epoch 1689: 26764.0\n",
            "Loss after epoch 1690: 27268.0\n",
            "Loss after epoch 1691: 27108.0\n",
            "Loss after epoch 1692: 26504.0\n",
            "Loss after epoch 1693: 27504.0\n",
            "Loss after epoch 1694: 27044.0\n",
            "Loss after epoch 1695: 27152.0\n",
            "Loss after epoch 1696: 26768.0\n",
            "Loss after epoch 1697: 27076.0\n",
            "Loss after epoch 1698: 27440.0\n",
            "Loss after epoch 1699: 27932.0\n",
            "Loss after epoch 1700: 27208.0\n",
            "Loss after epoch 1701: 26932.0\n",
            "Loss after epoch 1702: 26224.0\n",
            "Loss after epoch 1703: 26176.0\n",
            "Loss after epoch 1704: 27604.0\n",
            "Loss after epoch 1705: 26592.0\n",
            "Loss after epoch 1706: 26748.0\n",
            "Loss after epoch 1707: 26492.0\n",
            "Loss after epoch 1708: 26636.0\n",
            "Loss after epoch 1709: 27664.0\n",
            "Loss after epoch 1710: 27584.0\n",
            "Loss after epoch 1711: 26092.0\n",
            "Loss after epoch 1712: 26512.0\n",
            "Loss after epoch 1713: 27384.0\n",
            "Loss after epoch 1714: 27464.0\n",
            "Loss after epoch 1715: 27164.0\n",
            "Loss after epoch 1716: 26736.0\n",
            "Loss after epoch 1717: 27060.0\n",
            "Loss after epoch 1718: 27260.0\n",
            "Loss after epoch 1719: 26348.0\n",
            "Loss after epoch 1720: 28084.0\n",
            "Loss after epoch 1721: 27048.0\n",
            "Loss after epoch 1722: 27324.0\n",
            "Loss after epoch 1723: 26668.0\n",
            "Loss after epoch 1724: 26036.0\n",
            "Loss after epoch 1725: 26748.0\n",
            "Loss after epoch 1726: 26908.0\n",
            "Loss after epoch 1727: 26524.0\n",
            "Loss after epoch 1728: 28060.0\n",
            "Loss after epoch 1729: 26308.0\n",
            "Loss after epoch 1730: 27236.0\n",
            "Loss after epoch 1731: 26640.0\n",
            "Loss after epoch 1732: 26572.0\n",
            "Loss after epoch 1733: 26792.0\n",
            "Loss after epoch 1734: 26760.0\n",
            "Loss after epoch 1735: 27408.0\n",
            "Loss after epoch 1736: 27496.0\n",
            "Loss after epoch 1737: 27160.0\n",
            "Loss after epoch 1738: 26024.0\n",
            "Loss after epoch 1739: 26624.0\n",
            "Loss after epoch 1740: 26956.0\n",
            "Loss after epoch 1741: 26776.0\n",
            "Loss after epoch 1742: 26884.0\n",
            "Loss after epoch 1743: 27048.0\n",
            "Loss after epoch 1744: 26952.0\n",
            "Loss after epoch 1745: 26908.0\n",
            "Loss after epoch 1746: 26712.0\n",
            "Loss after epoch 1747: 26212.0\n",
            "Loss after epoch 1748: 26540.0\n",
            "Loss after epoch 1749: 27232.0\n",
            "Loss after epoch 1750: 26940.0\n",
            "Loss after epoch 1751: 26960.0\n",
            "Loss after epoch 1752: 27072.0\n",
            "Loss after epoch 1753: 27632.0\n",
            "Loss after epoch 1754: 26764.0\n",
            "Loss after epoch 1755: 26472.0\n",
            "Loss after epoch 1756: 26716.0\n",
            "Loss after epoch 1757: 27004.0\n",
            "Loss after epoch 1758: 26396.0\n",
            "Loss after epoch 1759: 26816.0\n",
            "Loss after epoch 1760: 27600.0\n",
            "Loss after epoch 1761: 27632.0\n",
            "Loss after epoch 1762: 27240.0\n",
            "Loss after epoch 1763: 27088.0\n",
            "Loss after epoch 1764: 26504.0\n",
            "Loss after epoch 1765: 27248.0\n",
            "Loss after epoch 1766: 27564.0\n",
            "Loss after epoch 1767: 26496.0\n",
            "Loss after epoch 1768: 26852.0\n",
            "Loss after epoch 1769: 26968.0\n",
            "Loss after epoch 1770: 26700.0\n",
            "Loss after epoch 1771: 26728.0\n",
            "Loss after epoch 1772: 26524.0\n",
            "Loss after epoch 1773: 25908.0\n",
            "Loss after epoch 1774: 26740.0\n",
            "Loss after epoch 1775: 26728.0\n",
            "Loss after epoch 1776: 26992.0\n",
            "Loss after epoch 1777: 26616.0\n",
            "Loss after epoch 1778: 26792.0\n",
            "Loss after epoch 1779: 27236.0\n",
            "Loss after epoch 1780: 26980.0\n",
            "Loss after epoch 1781: 26432.0\n",
            "Loss after epoch 1782: 27308.0\n",
            "Loss after epoch 1783: 25992.0\n",
            "Loss after epoch 1784: 26516.0\n",
            "Loss after epoch 1785: 27332.0\n",
            "Loss after epoch 1786: 26452.0\n",
            "Loss after epoch 1787: 27064.0\n",
            "Loss after epoch 1788: 27880.0\n",
            "Loss after epoch 1789: 27068.0\n",
            "Loss after epoch 1790: 27388.0\n",
            "Loss after epoch 1791: 27064.0\n",
            "Loss after epoch 1792: 26572.0\n",
            "Loss after epoch 1793: 26472.0\n",
            "Loss after epoch 1794: 27160.0\n",
            "Loss after epoch 1795: 26856.0\n",
            "Loss after epoch 1796: 26300.0\n",
            "Loss after epoch 1797: 27076.0\n",
            "Loss after epoch 1798: 27036.0\n",
            "Loss after epoch 1799: 26796.0\n",
            "Loss after epoch 1800: 27024.0\n",
            "Loss after epoch 1801: 26820.0\n",
            "Loss after epoch 1802: 27528.0\n",
            "Loss after epoch 1803: 27852.0\n",
            "Loss after epoch 1804: 26592.0\n",
            "Loss after epoch 1805: 26552.0\n",
            "Loss after epoch 1806: 27828.0\n",
            "Loss after epoch 1807: 26900.0\n",
            "Loss after epoch 1808: 26376.0\n",
            "Loss after epoch 1809: 26788.0\n",
            "Loss after epoch 1810: 26968.0\n",
            "Loss after epoch 1811: 26404.0\n",
            "Loss after epoch 1812: 26380.0\n",
            "Loss after epoch 1813: 26484.0\n",
            "Loss after epoch 1814: 27344.0\n",
            "Loss after epoch 1815: 26552.0\n",
            "Loss after epoch 1816: 26712.0\n",
            "Loss after epoch 1817: 27284.0\n",
            "Loss after epoch 1818: 26692.0\n",
            "Loss after epoch 1819: 26228.0\n",
            "Loss after epoch 1820: 27064.0\n",
            "Loss after epoch 1821: 26900.0\n",
            "Loss after epoch 1822: 27040.0\n",
            "Loss after epoch 1823: 27028.0\n",
            "Loss after epoch 1824: 25904.0\n",
            "Loss after epoch 1825: 27604.0\n",
            "Loss after epoch 1826: 26840.0\n",
            "Loss after epoch 1827: 26304.0\n",
            "Loss after epoch 1828: 26040.0\n",
            "Loss after epoch 1829: 26436.0\n",
            "Loss after epoch 1830: 26728.0\n",
            "Loss after epoch 1831: 26392.0\n",
            "Loss after epoch 1832: 26304.0\n",
            "Loss after epoch 1833: 25932.0\n",
            "Loss after epoch 1834: 26584.0\n",
            "Loss after epoch 1835: 26756.0\n",
            "Loss after epoch 1836: 26536.0\n",
            "Loss after epoch 1837: 25884.0\n",
            "Loss after epoch 1838: 26148.0\n",
            "Loss after epoch 1839: 26716.0\n",
            "Loss after epoch 1840: 26472.0\n",
            "Loss after epoch 1841: 26504.0\n",
            "Loss after epoch 1842: 26444.0\n",
            "Loss after epoch 1843: 26748.0\n",
            "Loss after epoch 1844: 27428.0\n",
            "Loss after epoch 1845: 26568.0\n",
            "Loss after epoch 1846: 26416.0\n",
            "Loss after epoch 1847: 27076.0\n",
            "Loss after epoch 1848: 26484.0\n",
            "Loss after epoch 1849: 27332.0\n",
            "Loss after epoch 1850: 27236.0\n",
            "Loss after epoch 1851: 26820.0\n",
            "Loss after epoch 1852: 26268.0\n",
            "Loss after epoch 1853: 26160.0\n",
            "Loss after epoch 1854: 26544.0\n",
            "Loss after epoch 1855: 26012.0\n",
            "Loss after epoch 1856: 26472.0\n",
            "Loss after epoch 1857: 26892.0\n",
            "Loss after epoch 1858: 26904.0\n",
            "Loss after epoch 1859: 25980.0\n",
            "Loss after epoch 1860: 26788.0\n",
            "Loss after epoch 1861: 26588.0\n",
            "Loss after epoch 1862: 26420.0\n",
            "Loss after epoch 1863: 27680.0\n",
            "Loss after epoch 1864: 25936.0\n",
            "Loss after epoch 1865: 26736.0\n",
            "Loss after epoch 1866: 26292.0\n",
            "Loss after epoch 1867: 25820.0\n",
            "Loss after epoch 1868: 26752.0\n",
            "Loss after epoch 1869: 26524.0\n",
            "Loss after epoch 1870: 26208.0\n",
            "Loss after epoch 1871: 26612.0\n",
            "Loss after epoch 1872: 26168.0\n",
            "Loss after epoch 1873: 26680.0\n",
            "Loss after epoch 1874: 26244.0\n",
            "Loss after epoch 1875: 26228.0\n",
            "Loss after epoch 1876: 26772.0\n",
            "Loss after epoch 1877: 25524.0\n",
            "Loss after epoch 1878: 26892.0\n",
            "Loss after epoch 1879: 26108.0\n",
            "Loss after epoch 1880: 27104.0\n",
            "Loss after epoch 1881: 26504.0\n",
            "Loss after epoch 1882: 26592.0\n",
            "Loss after epoch 1883: 26488.0\n",
            "Loss after epoch 1884: 26264.0\n",
            "Loss after epoch 1885: 26796.0\n",
            "Loss after epoch 1886: 26316.0\n",
            "Loss after epoch 1887: 27372.0\n",
            "Loss after epoch 1888: 25600.0\n",
            "Loss after epoch 1889: 26524.0\n",
            "Loss after epoch 1890: 26088.0\n",
            "Loss after epoch 1891: 25560.0\n",
            "Loss after epoch 1892: 26896.0\n",
            "Loss after epoch 1893: 26712.0\n",
            "Loss after epoch 1894: 26740.0\n",
            "Loss after epoch 1895: 26004.0\n",
            "Loss after epoch 1896: 26516.0\n",
            "Loss after epoch 1897: 25992.0\n",
            "Loss after epoch 1898: 27564.0\n",
            "Loss after epoch 1899: 26828.0\n",
            "Loss after epoch 1900: 25588.0\n",
            "Loss after epoch 1901: 26332.0\n",
            "Loss after epoch 1902: 25876.0\n",
            "Loss after epoch 1903: 26668.0\n",
            "Loss after epoch 1904: 27436.0\n",
            "Loss after epoch 1905: 25740.0\n",
            "Loss after epoch 1906: 26136.0\n",
            "Loss after epoch 1907: 26708.0\n",
            "Loss after epoch 1908: 25828.0\n",
            "Loss after epoch 1909: 25872.0\n",
            "Loss after epoch 1910: 26868.0\n",
            "Loss after epoch 1911: 25792.0\n",
            "Loss after epoch 1912: 25128.0\n",
            "Loss after epoch 1913: 27236.0\n",
            "Loss after epoch 1914: 26808.0\n",
            "Loss after epoch 1915: 25164.0\n",
            "Loss after epoch 1916: 26000.0\n",
            "Loss after epoch 1917: 26132.0\n",
            "Loss after epoch 1918: 25924.0\n",
            "Loss after epoch 1919: 25568.0\n",
            "Loss after epoch 1920: 25720.0\n",
            "Loss after epoch 1921: 26220.0\n",
            "Loss after epoch 1922: 25404.0\n",
            "Loss after epoch 1923: 26776.0\n",
            "Loss after epoch 1924: 26376.0\n",
            "Loss after epoch 1925: 27432.0\n",
            "Loss after epoch 1926: 26000.0\n",
            "Loss after epoch 1927: 25628.0\n",
            "Loss after epoch 1928: 26316.0\n",
            "Loss after epoch 1929: 26936.0\n",
            "Loss after epoch 1930: 26148.0\n",
            "Loss after epoch 1931: 26368.0\n",
            "Loss after epoch 1932: 26968.0\n",
            "Loss after epoch 1933: 25904.0\n",
            "Loss after epoch 1934: 25420.0\n",
            "Loss after epoch 1935: 25448.0\n",
            "Loss after epoch 1936: 26532.0\n",
            "Loss after epoch 1937: 26028.0\n",
            "Loss after epoch 1938: 26740.0\n",
            "Loss after epoch 1939: 25908.0\n",
            "Loss after epoch 1940: 26256.0\n",
            "Loss after epoch 1941: 26076.0\n",
            "Loss after epoch 1942: 26020.0\n",
            "Loss after epoch 1943: 26164.0\n",
            "Loss after epoch 1944: 25588.0\n",
            "Loss after epoch 1945: 27000.0\n",
            "Loss after epoch 1946: 25908.0\n",
            "Loss after epoch 1947: 26528.0\n",
            "Loss after epoch 1948: 25520.0\n",
            "Loss after epoch 1949: 25724.0\n",
            "Loss after epoch 1950: 26268.0\n",
            "Loss after epoch 1951: 26152.0\n",
            "Loss after epoch 1952: 26528.0\n",
            "Loss after epoch 1953: 26532.0\n",
            "Loss after epoch 1954: 25588.0\n",
            "Loss after epoch 1955: 26800.0\n",
            "Loss after epoch 1956: 26432.0\n",
            "Loss after epoch 1957: 26540.0\n",
            "Loss after epoch 1958: 26436.0\n",
            "Loss after epoch 1959: 26608.0\n",
            "Loss after epoch 1960: 27276.0\n",
            "Loss after epoch 1961: 26216.0\n",
            "Loss after epoch 1962: 25392.0\n",
            "Loss after epoch 1963: 26032.0\n",
            "Loss after epoch 1964: 25636.0\n",
            "Loss after epoch 1965: 25944.0\n",
            "Loss after epoch 1966: 26304.0\n",
            "Loss after epoch 1967: 26128.0\n",
            "Loss after epoch 1968: 25548.0\n",
            "Loss after epoch 1969: 25676.0\n",
            "Loss after epoch 1970: 27128.0\n",
            "Loss after epoch 1971: 26076.0\n",
            "Loss after epoch 1972: 25792.0\n",
            "Loss after epoch 1973: 25976.0\n",
            "Loss after epoch 1974: 27080.0\n",
            "Loss after epoch 1975: 25652.0\n",
            "Loss after epoch 1976: 27048.0\n",
            "Loss after epoch 1977: 25816.0\n",
            "Loss after epoch 1978: 26040.0\n",
            "Loss after epoch 1979: 26132.0\n",
            "Loss after epoch 1980: 25572.0\n",
            "Loss after epoch 1981: 25168.0\n",
            "Loss after epoch 1982: 25732.0\n",
            "Loss after epoch 1983: 26256.0\n",
            "Loss after epoch 1984: 26264.0\n",
            "Loss after epoch 1985: 26392.0\n",
            "Loss after epoch 1986: 25736.0\n",
            "Loss after epoch 1987: 25544.0\n",
            "Loss after epoch 1988: 26556.0\n",
            "Loss after epoch 1989: 26404.0\n",
            "Loss after epoch 1990: 26236.0\n",
            "Loss after epoch 1991: 26124.0\n",
            "Loss after epoch 1992: 26656.0\n",
            "Loss after epoch 1993: 26200.0\n",
            "Loss after epoch 1994: 25456.0\n",
            "Loss after epoch 1995: 25492.0\n",
            "Loss after epoch 1996: 25352.0\n",
            "Loss after epoch 1997: 26216.0\n",
            "Loss after epoch 1998: 26052.0\n",
            "Loss after epoch 1999: 25912.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14172892, 31558000)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=2000,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Palabras que MÁS se relacionan con:"
      ],
      "metadata": {
        "id": "Yiisu2l-K2yq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4487b0-b194-4b15-c6fc-bf8333fd7177"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('desconocido', 0.4206427335739136),\n",
              " ('dormir', 0.40307942032814026),\n",
              " ('las', 0.3775336444377899),\n",
              " ('hijo', 0.37557804584503174),\n",
              " ('perdido', 0.3592827320098877),\n",
              " ('por', 0.35831478238105774),\n",
              " ('su', 0.3566811680793762),\n",
              " ('hablando', 0.34511977434158325),\n",
              " ('cómo', 0.3413276970386505),\n",
              " ('se', 0.33921492099761963),\n",
              " ('antes', 0.33032849431037903),\n",
              " ('dar', 0.32867902517318726),\n",
              " ('que', 0.32863420248031616),\n",
              " ('visto', 0.32785165309906006),\n",
              " ('de', 0.32713747024536133)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"armadura\"], topn=15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"caballero\"], topn=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilAol2EM7JS7",
        "outputId": "18608143-7927-4178-9ae1-b9220ee2aa0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('el', 0.9100741744041443),\n",
              " ('y', 0.7135035395622253),\n",
              " ('se', 0.697830080986023),\n",
              " ('que', 0.691400945186615),\n",
              " ('con', 0.6633176803588867),\n",
              " ('no', 0.6305489540100098),\n",
              " ('de', 0.6275771260261536),\n",
              " ('la', 0.5857557654380798),\n",
              " ('en', 0.5838313102722168),\n",
              " ('lo', 0.5596433281898499),\n",
              " ('una', 0.5123971104621887),\n",
              " ('le', 0.49254947900772095),\n",
              " ('pero', 0.47723114490509033),\n",
              " ('a', 0.4770013093948364),\n",
              " ('un', 0.4724651575088501),\n",
              " ('merlín', 0.46773457527160645),\n",
              " ('del', 0.46628692746162415),\n",
              " ('su', 0.4240797460079193),\n",
              " ('más', 0.4204378128051758),\n",
              " ('por', 0.40873292088508606),\n",
              " ('reflexionó', 0.3988945186138153),\n",
              " ('al', 0.3885550796985626),\n",
              " ('las', 0.3833645284175873),\n",
              " ('dragón', 0.34439218044281006),\n",
              " ('levadizo', 0.33261507749557495)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"Julieta\"], topn=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "VNqtcpj4gzOv",
        "outputId": "0d614fb2-dab0-45d1-d7a2-2749e7ba710d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-fa357d3983c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Julieta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'Julieta' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"julieta\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds5nWI1FJ5Sp",
        "outputId": "995a397d-13af-4d77-e9bb-5f45a519cfe7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bueno', 0.5286751389503479),\n",
              " ('cristóbal', 0.464471697807312),\n",
              " ('amaba', 0.4467121362686157),\n",
              " ('aquello', 0.4390237033367157),\n",
              " ('has', 0.4186362326145172),\n",
              " ('amado', 0.41749903559684753),\n",
              " ('parte', 0.41709965467453003),\n",
              " ('habían', 0.4003604054450989),\n",
              " ('había', 0.3948251008987427),\n",
              " ('comenzó', 0.3940368890762329),\n",
              " ('aunque', 0.3743031620979309),\n",
              " ('generoso', 0.36302709579467773),\n",
              " ('roca', 0.3550640642642975),\n",
              " ('porque', 0.35332396626472473),\n",
              " ('damiselas', 0.3496323823928833)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DT4Rvno2mD65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5498dd-3c44-43a6-829e-0b027487b9ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bolsalegre', 0.5076074004173279),\n",
              " ('voluntad', 0.5027350187301636),\n",
              " ('rebeca', 0.45809024572372437),\n",
              " ('animales', 0.4499671459197998),\n",
              " ('movió', 0.42289525270462036),\n",
              " ('cola', 0.41460537910461426),\n",
              " ('has', 0.3995417058467865),\n",
              " ('merlín', 0.39647236466407776),\n",
              " ('corriendo', 0.3798247277736664),\n",
              " ('hablando', 0.3734656572341919),\n",
              " ('habéis', 0.3685861825942993),\n",
              " ('mientras', 0.36806005239486694),\n",
              " ('profundamente', 0.3672880232334137),\n",
              " ('durante', 0.34975317120552063),\n",
              " ('estas', 0.3477833867073059)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"ardilla\"], topn=15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"paloma\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj_hT8Fk4zmM",
        "outputId": "5f67bad1-e749-4a05-c3cb-ff7528904561"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('veces', 0.47220340371131897),\n",
              " ('misma', 0.4371826648712158),\n",
              " ('tengo', 0.42593175172805786),\n",
              " ('abrió', 0.42142271995544434),\n",
              " ('yelmo', 0.4200170636177063),\n",
              " ('mientras', 0.41435688734054565),\n",
              " ('¡no', 0.40630313754081726),\n",
              " ('batalla', 0.4023904502391815),\n",
              " ('decir', 0.4005279541015625),\n",
              " ('sería', 0.39540383219718933)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"rebeca\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPRF3TPwgqId",
        "outputId": "62a9ce74-c055-4a39-8013-3ab9f7df16a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ardilla', 0.45809024572372437),\n",
              " ('os', 0.4470615088939667),\n",
              " ('pasado', 0.40667232871055603),\n",
              " ('corriendo', 0.3913290202617645),\n",
              " ('regresar', 0.3882126808166504),\n",
              " ('coraje', 0.3814336657524109),\n",
              " ('les', 0.38104188442230225),\n",
              " ('poco', 0.37193557620048523),\n",
              " ('sería', 0.3710494637489319),\n",
              " ('caballo', 0.3606563210487366)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XPLDPgzBmQXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e7c23c-6d49-43c5-c92e-336f52845699"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('que', 0.5417777299880981),\n",
              " ('no', 0.4886833429336548),\n",
              " ('a', 0.482021301984787),\n",
              " ('el', 0.4684999883174896),\n",
              " ('caballero', 0.46773457527160645),\n",
              " ('volvió', 0.4648396074771881),\n",
              " ('con', 0.44246166944503784),\n",
              " ('y', 0.4374358355998993),\n",
              " ('más', 0.4266934096813202),\n",
              " ('la', 0.42156243324279785)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"merlín\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"castillo\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FggALHFhV8E",
        "outputId": "fdf5ab17-5fab-4894-8b2d-eb5c7080e185"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('silencio', 0.5889235734939575),\n",
              " ('conocimiento', 0.4494462013244629),\n",
              " ('algún', 0.39977821707725525),\n",
              " ('en', 0.3894762396812439),\n",
              " ('otro', 0.3894018828868866),\n",
              " ('elegante', 0.38670530915260315),\n",
              " ('habitación', 0.37799423933029175),\n",
              " ('siguiente', 0.3675212562084198),\n",
              " ('lejana', 0.36694976687431335),\n",
              " ('eres', 0.3629086911678314)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"miedo\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8b_2-qchnz6",
        "outputId": "f70620db-7456-43c7-e4a5-90cf0dab14a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('quiero', 0.4689388573169708),\n",
              " ('sorprendido', 0.4624476730823517),\n",
              " ('duda', 0.45101019740104675),\n",
              " ('osadía', 0.4323931932449341),\n",
              " ('pared', 0.3943994343280792),\n",
              " ('ninguna', 0.38416358828544617),\n",
              " ('conocimiento', 0.37872570753097534),\n",
              " ('voluntad', 0.3626060485839844),\n",
              " ('matar', 0.3616790771484375),\n",
              " ('uno', 0.3580966591835022),\n",
              " ('podéis', 0.35476362705230713),\n",
              " ('mejores', 0.35433998703956604),\n",
              " ('humor', 0.3541971743106842),\n",
              " ('rió', 0.353187620639801),\n",
              " ('primero', 0.33694350719451904)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"espada\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY9hgRqKiZfz",
        "outputId": "6cdaa649-46d4-4639-c100-6c1549dc01e7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('necesidad', 0.5047368407249451),\n",
              " ('bastante', 0.4999467730522156),\n",
              " ('sentía', 0.4881383776664734),\n",
              " ('amor', 0.46951523423194885),\n",
              " ('embargo', 0.46818917989730835),\n",
              " ('tal', 0.43259966373443604),\n",
              " ('cosas', 0.43148982524871826),\n",
              " ('mente', 0.4310183823108673),\n",
              " ('amado', 0.42093923687934875),\n",
              " ('mañana', 0.419707328081131),\n",
              " ('alguien', 0.41115665435791016),\n",
              " ('iba', 0.41035065054893494),\n",
              " ('mala', 0.4055016338825226),\n",
              " ('rostro', 0.4053732752799988),\n",
              " ('tendréis', 0.40151190757751465)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"rey\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDA9_hQvi2gE",
        "outputId": "ec2fda5d-c29b-4d6f-b52f-7ff5fb4d9628"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('podido', 0.46318283677101135),\n",
              " ('abrir', 0.4416574537754059),\n",
              " ('volver', 0.42374688386917114),\n",
              " ('algún', 0.4059978425502777),\n",
              " ('sonido', 0.4035577178001404),\n",
              " ('lado', 0.3973800539970398),\n",
              " ('bufón', 0.38295355439186096),\n",
              " ('listo', 0.3813322186470032),\n",
              " ('quiero', 0.3783131241798401),\n",
              " ('habéis', 0.36647385358810425),\n",
              " ('siempre', 0.36580580472946167),\n",
              " ('dolor', 0.35669922828674316),\n",
              " ('debe', 0.35661113262176514),\n",
              " ('antes', 0.35227739810943604),\n",
              " ('hasta', 0.3489934504032135)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"dragón\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdkpxkA6pPVX",
        "outputId": "bb55cb64-6fa2-4cf4-b2a0-0664c5d1c1a5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('puente', 0.5119661092758179),\n",
              " ('ellos', 0.41364559531211853),\n",
              " ('matar', 0.4121808409690857),\n",
              " ('culpa', 0.3969680666923523),\n",
              " ('oscuridad', 0.3915013074874878),\n",
              " ('demostrar', 0.3860476315021515),\n",
              " ('ser', 0.37833371758461),\n",
              " ('conocimiento', 0.37556883692741394),\n",
              " ('dragones', 0.37185269594192505),\n",
              " ('algo', 0.368404746055603),\n",
              " ('barba', 0.3663462698459625),\n",
              " ('gritó', 0.3631519675254822),\n",
              " ('sonido', 0.362311452627182),\n",
              " ('enorme', 0.3616534173488617),\n",
              " ('corazón', 0.3552550971508026)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"cima\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xztGNnCyqQ28",
        "outputId": "f772b501-d943-4276-b33e-d0d81d58594c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pie', 0.5558347105979919),\n",
              " ('ante', 0.4995821714401245),\n",
              " ('mala', 0.4658677279949188),\n",
              " ('montaña', 0.4478739798069),\n",
              " ('dio', 0.4461289346218109),\n",
              " ('casi', 0.4450017809867859),\n",
              " ('partir', 0.4394036531448364),\n",
              " ('puerta', 0.43754714727401733),\n",
              " ('verdad', 0.43472200632095337),\n",
              " ('llegar', 0.4296117126941681),\n",
              " ('entró', 0.426874577999115),\n",
              " ('mano', 0.4150473475456238),\n",
              " ('toda', 0.403726190328598),\n",
              " ('él', 0.3979846239089966),\n",
              " ('intentando', 0.39131104946136475)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Palabras que MENOS se relacionan con:"
      ],
      "metadata": {
        "id": "ElZH6pM5LG-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"armadura\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Eeomapu8Jy",
        "outputId": "0bdef139-007a-4d4f-cd7b-48b9b1e40e0b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('estás', 0.19449090957641602),\n",
              " ('preguntó', 0.18878579139709473),\n",
              " ('replicó', 0.18050797283649445),\n",
              " ('puente', 0.16912253201007843),\n",
              " ('apareció', 0.12834787368774414),\n",
              " ('levadizo', 0.12659820914268494),\n",
              " ('espejo', 0.12258513271808624),\n",
              " ('palabras', 0.11936280876398087),\n",
              " ('oído', 0.11345125734806061),\n",
              " ('desapareció', 0.11028817296028137)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"caballero\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtqhB1eTLVEw",
        "outputId": "004b66c4-ddce-46a1-efa0-9d1d435c4519"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('menudo', 0.07658691704273224),\n",
              " ('tal', 0.048528701066970825),\n",
              " ('tanto', 0.043880559504032135),\n",
              " ('tendréis', 0.03867993876338005),\n",
              " ('debe', 0.03566401079297066),\n",
              " ('aún', 0.03362351655960083),\n",
              " ('viaje', 0.030147971585392952),\n",
              " ('intentando', 0.028880717232823372),\n",
              " ('atrapado', 0.02594609372317791),\n",
              " ('gente', 0.025839220732450485)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"julieta\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsF3wPuVLOXR",
        "outputId": "0831d3f2-5a56-4b43-b2a4-356335b1b4cb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gran', 0.1591128706932068),\n",
              " ('silencio', 0.14780810475349426),\n",
              " ('ha', 0.1434696465730667),\n",
              " ('cualquier', 0.136907160282135),\n",
              " ('parece', 0.13090702891349792),\n",
              " ('mago', 0.12591831386089325),\n",
              " ('mucho', 0.12521511316299438),\n",
              " ('nueces', 0.12454205006361008),\n",
              " ('sólo', 0.12194715440273285),\n",
              " ('reino', 0.10996676981449127)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(negative=[\"cristóbal\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1rneHukqYph",
        "outputId": "f0fc2932-869a-42f9-b066-ad39ee34c6d0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('donde', 0.2829255759716034),\n",
              " ('años', 0.22068147361278534),\n",
              " ('he', 0.19093184173107147),\n",
              " ('reino', 0.14993730187416077),\n",
              " ('estado', 0.14713265001773834),\n",
              " ('del', 0.10750675201416016),\n",
              " ('siquiera', 0.10437033325433731),\n",
              " ('hayáis', 0.1005595475435257),\n",
              " ('explicó', 0.08825932443141937),\n",
              " ('hecho', 0.07882867753505707),\n",
              " ('durante', 0.07732099294662476),\n",
              " ('e', 0.06898357719182968),\n",
              " ('siempre', 0.06534640491008759),\n",
              " ('silencio', 0.06443005800247192),\n",
              " ('acero', 0.06317701935768127)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(negative=[\"animales\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsBb_nxVhD4u",
        "outputId": "61a98588-deb2-4b5d-d7af-9cf6178e63bc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('demostrar', 0.2156834751367569),\n",
              " ('toda', 0.19132380187511444),\n",
              " ('o', 0.1755378693342209),\n",
              " ('tenía', 0.12786075472831726),\n",
              " ('fuera', 0.12543225288391113),\n",
              " ('decir', 0.11582417786121368),\n",
              " ('¿qué', 0.10951532423496246),\n",
              " ('¿no', 0.09081094712018967),\n",
              " ('respondió', 0.08287039399147034),\n",
              " ('todo', 0.0800456702709198),\n",
              " ('comprender', 0.074195995926857),\n",
              " ('amor', 0.05940845236182213),\n",
              " ('parte', 0.058707669377326965),\n",
              " ('¿y', 0.05792577564716339),\n",
              " ('ella', 0.05751252919435501)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores con TSNE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA    \n",
        "from sklearn.manifold import TSNE                   \n",
        "import numpy as np                                  \n",
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2  \n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index2word)  \n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NCCXtDpcugmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "55278d22-afc9-4e6b-8794-29fa0975275d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"eefed56c-99f9-48b9-80f3-980662d9c2f4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eefed56c-99f9-48b9-80f3-980662d9c2f4\")) {                    Plotly.newPlot(                        \"eefed56c-99f9-48b9-80f3-980662d9c2f4\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"el\",\"que\",\"de\",\"la\",\"y\",\"caballero\",\"a\",\"no\",\"en\",\"se\",\"con\",\"su\",\"una\",\"lo\",\"por\",\"un\",\"del\",\"hab\\u00eda\",\"para\",\"m\\u00e1s\",\"le\",\"merl\\u00edn\",\"dijo\",\"los\",\"al\",\"las\",\"es\",\"era\",\"pero\",\"armadura\",\"estaba\",\"castillo\",\"ardilla\",\"rebeca\",\"si\",\"vez\",\"cuando\",\"como\",\"me\",\"todo\",\"julieta\",\"tiempo\",\"sam\",\"yo\",\"pregunt\\u00f3\",\"sus\",\"os\",\"mismo\",\"\\u00e9l\",\"ser\",\"tan\",\"esto\",\"sobre\",\"eso\",\"rey\",\"otra\",\"s\\u00ed\",\"mi\",\"ten\\u00eda\",\"uno\",\"qu\\u00e9\",\"sin\",\"verdad\",\"ahora\",\"replic\\u00f3\",\"esta\",\"pod\\u00eda\",\"drag\\u00f3n\",\"porque\",\"s\\u00f3lo\",\"puerta\",\"tambi\\u00e9n\",\"voz\",\"este\",\"crist\\u00f3bal\",\"ver\",\"decir\",\"aqu\\u00ed\",\"ya\",\"hacia\",\"ni\",\"mago\",\"vos\",\"sendero\",\"muy\",\"fue\",\"vida\",\"\\u00bfc\\u00f3mo\",\"mientras\",\"hecho\",\"as\\u00ed\",\"mir\\u00f3\",\"\\u00bfqu\\u00e9\",\"conocimiento\",\"nunca\",\"silencio\",\"cada\",\"visera\",\"te\",\"cuenta\",\"est\\u00e1is\",\"cabeza\",\"mucho\",\"puede\",\"luz\",\"nada\",\"cosas\",\"ella\",\"momento\",\"dio\",\"animales\",\"bueno\",\"hacer\",\"o\",\"d\\u00eda\",\"he\",\"respondi\\u00f3\",\"todos\",\"ese\",\"parec\\u00eda\",\"ambici\\u00f3n\",\"durante\",\"siempre\",\"antes\",\"\\u00e1rbol\",\"toda\",\"todas\",\"camino\",\"l\\u00e1grimas\",\"caballo\",\"tener\",\"yelmo\",\"estoy\",\"pie\",\"caer\",\"hab\\u00e9is\",\"luego\",\"est\\u00e1\",\"habitaci\\u00f3n\",\"poco\",\"t\\u00fa\",\"realmente\",\"fuera\",\"herrero\",\"manera\",\"vuestro\",\"coraz\\u00f3n\",\"pues\",\"sab\\u00eda\",\"amor\",\"miedo\",\"vuestra\",\"mente\",\"poder\",\"entonces\",\"tengo\",\"\\u00bfpor\",\"sentido\",\"c\\u00f3mo\",\"hablar\",\"castillos\",\"vio\",\"ha\",\"solo\",\"bien\",\"soy\",\"barba\",\"fuego\",\"despu\\u00e9s\",\"gente\",\"haber\",\"batalla\",\"hasta\",\"gran\",\"podr\\u00eda\",\"medida\",\"son\",\"\\u00bfy\",\"aprender\",\"simplemente\",\"sol\",\"otro\",\"ojos\",\"puedo\",\"atrapado\",\"sinti\\u00f3\",\"grit\\u00f3\",\"comenz\\u00f3\",\"hab\\u00edan\",\"eran\",\"lugar\",\"pens\\u00f3\",\"desde\",\"cima\",\"bolsalegre\",\"hombro\",\"ir\",\"hay\",\"o\\u00edr\",\"dos\"],\"x\":[-0.6648610234260559,-0.5420695543289185,-0.5523019433021545,-0.6085730195045471,-0.6443528532981873,-0.6224433183670044,-0.5927465558052063,-0.5200095772743225,-0.7176274061203003,-0.6770915389060974,-0.6169821619987488,-0.6890344023704529,-0.7544698119163513,-0.46309134364128113,-0.5940994620323181,-0.7350960373878479,-1.172330617904663,-0.37421682476997375,-0.7705570459365845,-0.7972305417060852,-0.3805631399154663,-0.34093981981277466,-0.4182893931865692,-0.8877146244049072,-0.6423388719558716,0.07452227175235748,-0.39421579241752625,-0.7830909490585327,-0.3913429081439972,-0.44050681591033936,-0.5042920708656311,-1.703635573387146,-1.1363937854766846,-1.079318881034851,0.11973483860492706,-0.93941330909729,-1.2254029512405396,0.32139748334884644,0.6181579232215881,0.41468602418899536,0.761833667755127,-0.2400401085615158,1.1862804889678955,2.829265832901001,1.6966118812561035,-1.260546088218689,0.11852063983678818,-0.4542461037635803,-0.6430860757827759,-0.49060073494911194,-2.3991336822509766,-1.8534971475601196,0.07720917463302612,-1.1116900444030762,-1.318884015083313,-0.689419686794281,0.8970560431480408,-0.4925950765609741,-0.4017246961593628,-0.9287725687026978,0.5348093509674072,2.035193920135498,-1.0373085737228394,-0.40965166687965393,-0.3860150873661041,-0.29036349058151245,-0.18016640841960907,-0.038035523146390915,-0.26420074701309204,-0.8554617166519165,-3.814450740814209,0.4163671135902405,3.2094595432281494,-2.5620005130767822,0.1607377529144287,-0.5736117362976074,-1.4825705289840698,-0.2871488034725189,-0.6167372465133667,-1.789055585861206,-0.36352604627609253,-1.9124696254730225,-0.8127022385597229,-2.6893131732940674,2.6544549465179443,-0.5961798429489136,-0.49878209829330444,2.763805389404297,-0.2721216678619385,0.07295302301645279,-0.7182714939117432,-1.6414682865142822,-0.06833495199680328,-1.8516860008239746,-0.6964043974876404,-1.9344173669815063,0.1309662163257599,1.7815563678741455,1.3928189277648926,-2.5686848163604736,-0.7281023859977722,-1.9751408100128174,-2.8739864826202393,0.13302628695964813,-1.122847318649292,2.187509298324585,-0.7427250146865845,0.834774911403656,-3.674677610397339,-0.20458970963954926,-1.2221217155456543,1.0066142082214355,-0.44169649481773376,-3.328786849975586,0.2892704904079437,1.0015026330947876,-0.24178166687488556,-0.666601836681366,-2.554391622543335,-0.3693588972091675,-1.4562456607818604,-0.46132412552833557,-0.5123568773269653,-1.1153219938278198,-2.29641056060791,-0.08808986842632294,0.25524666905403137,-1.8926963806152344,0.040253568440675735,-1.159754991531372,-2.2529218196868896,-1.2539784908294678,-3.9327738285064697,-2.175119400024414,-1.0265172719955444,0.37181034684181213,-0.26446533203125,-1.7940423488616943,-4.182239055633545,0.6828665733337402,2.3556060791015625,1.5604056119918823,2.2265515327453613,2.5810301303863525,0.45792779326438904,-1.2073729038238525,-1.5390281677246094,-2.391746759414673,0.17420120537281036,1.569556713104248,-1.2169065475463867,0.18393340706825256,-0.5221235752105713,-3.4263782501220703,2.0292809009552,0.07171959429979324,0.4848366975784302,-3.278801918029785,-0.2517027258872986,-1.0571317672729492,-1.5034817457199097,-2.996856451034546,-1.4754610061645508,-1.9011396169662476,-1.1615500450134277,2.514730215072632,0.45232418179512024,-2.390359878540039,-2.3517305850982666,0.5878617763519287,-2.395188331604004,-3.9794507026672363,-1.857136845588684,-1.7287588119506836,-0.974983811378479,-1.355957269668579,-1.8859927654266357,0.5888156890869141,0.8895022869110107,-1.2017769813537598,-4.489079475402832,-1.1770280599594116,-1.694013237953186,3.039719581604004,-0.6325344443321228,-1.3234999179840088,3.0361104011535645,1.0123282670974731,-0.1176467165350914,-0.7845420241355896,-3.4833507537841797,-1.173560619354248,-3.393101453781128,-2.218477249145508,-1.385436773300171,-2.8664486408233643,-0.4313546121120453,-1.3822499513626099,1.7377548217773438,-2.0620174407958984],\"xaxis\":\"x\",\"y\":[0.17500300705432892,0.24851474165916443,0.1852867603302002,0.1529456228017807,0.04445835202932358,0.15238814055919647,0.17144009470939636,0.36714300513267517,0.09718041121959686,-0.007783000357449055,0.15937946736812592,-0.1715947389602661,0.20440806448459625,0.4477653503417969,0.16768035292625427,0.122144415974617,0.3116178810596466,-0.4484347999095917,0.3906560242176056,0.16314972937107086,-0.33579713106155396,0.3763161599636078,1.2521413564682007,-0.08670388907194138,-0.023211726918816566,-0.008242836222052574,1.357508897781372,-0.11498305201530457,0.13998331129550934,-0.07135940343141556,-0.4275665879249573,0.12984752655029297,-1.2262461185455322,-0.3351188898086548,0.9832491874694824,-0.6242273449897766,0.8764522671699524,0.6985669136047363,1.7378053665161133,1.4119505882263184,-1.4450733661651611,0.014059988781809807,1.5478997230529785,1.6298567056655884,-0.5026454329490662,-2.517094850540161,1.0712766647338867,1.097619891166687,-0.3839416205883026,0.4416002333164215,1.884395956993103,1.7736449241638184,-0.13848645985126495,1.3813188076019287,1.268046259880066,0.16228444874286652,0.8157342672348022,1.3377411365509033,-0.3662082254886627,0.6057515740394592,3.9115612506866455,-2.0775551795959473,0.04354529455304146,0.6374127864837646,1.8825494050979614,0.722000002861023,0.3786020874977112,0.29455888271331787,0.4109848439693451,0.23180358111858368,0.7481106519699097,0.8401800990104675,0.3992394506931305,0.1900162696838379,-1.0052101612091064,0.9160318374633789,0.8762084245681763,1.7759114503860474,0.06930169463157654,-1.803507685661316,3.2162342071533203,0.8552483320236206,1.9597511291503906,0.09985458850860596,-0.2609701454639435,0.6841138601303101,-1.0186896324157715,1.101550579071045,-2.378697395324707,2.5079140663146973,2.2581710815429688,-0.39582332968711853,0.5277955532073975,0.24160301685333252,-0.02854863740503788,0.04587190970778465,-3.954409122467041,0.3222305178642273,2.558866024017334,2.6351423263549805,0.9918573498725891,-0.9270551800727844,1.3886573314666748,0.6873071193695068,0.3757716417312622,-0.015164656564593315,-2.8100504875183105,0.10617075860500336,-1.3303008079528809,-1.9018709659576416,-1.5451905727386475,-1.5197445154190063,0.4751761555671692,0.07056569308042526,-2.0681376457214355,2.932955265045166,1.3098288774490356,0.5945159792900085,-1.1532095670700073,-0.557140052318573,2.5208845138549805,-0.8700006008148193,1.1938892602920532,1.275240182876587,0.22622403502464294,-0.5778577327728271,-0.1264825463294983,-0.43858015537261963,-1.0712549686431885,-0.2272980511188507,0.0672563910484314,-0.2682604491710663,2.6191728115081787,-2.4109299182891846,-2.019357204437256,1.942143201828003,-1.3970521688461304,1.1360342502593994,-0.06805843859910965,-3.515186071395874,1.1661988496780396,0.8566545248031616,-1.005080223083496,-0.3582775890827179,-0.7147157192230225,1.7525992393493652,2.4349405765533447,4.105049133300781,-1.1318352222442627,-2.7818427085876465,0.46414005756378174,0.9862409234046936,-0.722853422164917,-0.13410285115242004,0.4464641511440277,3.870116949081421,3.977811813354492,1.413421392440796,-0.7644835710525513,0.6851902008056641,0.491868793964386,-1.3736302852630615,0.26460695266723633,1.6342942714691162,1.0021010637283325,1.8301962614059448,-0.12107540667057037,-0.4810522496700287,-1.910564661026001,-2.9874534606933594,1.0350545644760132,2.5057976245880127,1.0641487836837769,0.8614822030067444,3.5029823780059814,0.14704911410808563,-1.0395509004592896,4.005978584289551,2.0060229301452637,3.756981134414673,-0.9694640636444092,-0.5994474291801453,-2.918640375137329,-0.9477382898330688,1.284532904624939,-0.3283120095729828,1.8512890338897705,-1.3359150886535645,-2.1619882583618164,-1.119094729423523,0.9429283142089844,0.37251079082489014,1.5252690315246582,-2.3197834491729736,-1.5116093158721924,-2.2280805110931396,-0.28410425782203674,3.205580472946167,-0.4551267623901367,-0.9767054915428162],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('eefed56c-99f9-48b9-80f3-980662d9c2f4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Io4CW-a7r6Fx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELO NRO 2 A PROBAR (CBOW):"
      ],
      "metadata": {
        "id": "3V6jD-JDDqiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Armo modelo"
      ],
      "metadata": {
        "id": "z_lBBNIgwI3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso se usará CBOW\n",
        "w2v_model_2 = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario (si aparece menos de 5 veces, Gensim la descarta)\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     size=50,       # dimensionalidad de los vectores (de salida)\n",
        "                     negative=20,    # cantidad de negative samples (las más representativas)... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=0)           # modelo 0:CBOW  1:skipgram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X-CPfwoDnST",
        "outputId": "cc111e33-e31e-42bb-a290-23f433f0ef24"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buildear el vocabulario con los tokens\n",
        "w2v_model_2.build_vocab(sentence_tokens)"
      ],
      "metadata": {
        "id": "sHZadImwsSwg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Entreno modelo"
      ],
      "metadata": {
        "id": "JyU9D5QbwQBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model_2.train(sentence_tokens,\n",
        "                 total_examples=w2v_model_2.corpus_count,\n",
        "                 epochs=2000,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM1qzdwksrv2",
        "outputId": "560244aa-fe0f-4bb9-e25f-15bb0a4098b9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 70685.984375\n",
            "Loss after epoch 1: 32020.0625\n",
            "Loss after epoch 2: 30317.09375\n",
            "Loss after epoch 3: 29748.015625\n",
            "Loss after epoch 4: 29990.703125\n",
            "Loss after epoch 5: 29643.203125\n",
            "Loss after epoch 6: 29218.203125\n",
            "Loss after epoch 7: 29775.203125\n",
            "Loss after epoch 8: 29868.40625\n",
            "Loss after epoch 9: 29466.15625\n",
            "Loss after epoch 10: 29637.1875\n",
            "Loss after epoch 11: 29732.125\n",
            "Loss after epoch 12: 29511.71875\n",
            "Loss after epoch 13: 29564.4375\n",
            "Loss after epoch 14: 29664.15625\n",
            "Loss after epoch 15: 29317.8125\n",
            "Loss after epoch 16: 29320.09375\n",
            "Loss after epoch 17: 29017.3125\n",
            "Loss after epoch 18: 28557.375\n",
            "Loss after epoch 19: 27982.8125\n",
            "Loss after epoch 20: 27979.1875\n",
            "Loss after epoch 21: 27519.875\n",
            "Loss after epoch 22: 27354.625\n",
            "Loss after epoch 23: 26828.125\n",
            "Loss after epoch 24: 26464.875\n",
            "Loss after epoch 25: 25993.875\n",
            "Loss after epoch 26: 25708.875\n",
            "Loss after epoch 27: 25088.75\n",
            "Loss after epoch 28: 24647.5625\n",
            "Loss after epoch 29: 24376.5625\n",
            "Loss after epoch 30: 24079.875\n",
            "Loss after epoch 31: 23613.6875\n",
            "Loss after epoch 32: 23189.0\n",
            "Loss after epoch 33: 22673.1875\n",
            "Loss after epoch 34: 22533.1875\n",
            "Loss after epoch 35: 22354.625\n",
            "Loss after epoch 36: 21348.3125\n",
            "Loss after epoch 37: 20063.125\n",
            "Loss after epoch 38: 19917.625\n",
            "Loss after epoch 39: 19446.0\n",
            "Loss after epoch 40: 19755.75\n",
            "Loss after epoch 41: 19358.25\n",
            "Loss after epoch 42: 19379.875\n",
            "Loss after epoch 43: 19284.75\n",
            "Loss after epoch 44: 18734.5\n",
            "Loss after epoch 45: 18755.125\n",
            "Loss after epoch 46: 18563.375\n",
            "Loss after epoch 47: 18265.5\n",
            "Loss after epoch 48: 18123.0\n",
            "Loss after epoch 49: 18071.125\n",
            "Loss after epoch 50: 17751.0\n",
            "Loss after epoch 51: 17845.0\n",
            "Loss after epoch 52: 17729.5\n",
            "Loss after epoch 53: 17552.25\n",
            "Loss after epoch 54: 17527.75\n",
            "Loss after epoch 55: 17428.25\n",
            "Loss after epoch 56: 17406.75\n",
            "Loss after epoch 57: 17602.625\n",
            "Loss after epoch 58: 17130.875\n",
            "Loss after epoch 59: 17346.5\n",
            "Loss after epoch 60: 16904.125\n",
            "Loss after epoch 61: 16837.0\n",
            "Loss after epoch 62: 17223.625\n",
            "Loss after epoch 63: 16751.75\n",
            "Loss after epoch 64: 16955.0\n",
            "Loss after epoch 65: 17021.625\n",
            "Loss after epoch 66: 16695.25\n",
            "Loss after epoch 67: 16485.0\n",
            "Loss after epoch 68: 16735.25\n",
            "Loss after epoch 69: 16614.875\n",
            "Loss after epoch 70: 16422.75\n",
            "Loss after epoch 71: 16538.375\n",
            "Loss after epoch 72: 16724.625\n",
            "Loss after epoch 73: 16381.75\n",
            "Loss after epoch 74: 16552.125\n",
            "Loss after epoch 75: 16322.25\n",
            "Loss after epoch 76: 16573.25\n",
            "Loss after epoch 77: 16183.0\n",
            "Loss after epoch 78: 16441.25\n",
            "Loss after epoch 79: 16513.875\n",
            "Loss after epoch 80: 16002.625\n",
            "Loss after epoch 81: 16573.875\n",
            "Loss after epoch 82: 15974.5\n",
            "Loss after epoch 83: 16249.5\n",
            "Loss after epoch 84: 16363.25\n",
            "Loss after epoch 85: 16193.0\n",
            "Loss after epoch 86: 16184.625\n",
            "Loss after epoch 87: 16454.875\n",
            "Loss after epoch 88: 16221.625\n",
            "Loss after epoch 89: 16230.0\n",
            "Loss after epoch 90: 16083.0\n",
            "Loss after epoch 91: 15821.75\n",
            "Loss after epoch 92: 16020.875\n",
            "Loss after epoch 93: 15907.625\n",
            "Loss after epoch 94: 15982.875\n",
            "Loss after epoch 95: 16293.0\n",
            "Loss after epoch 96: 16395.875\n",
            "Loss after epoch 97: 15874.625\n",
            "Loss after epoch 98: 15303.0\n",
            "Loss after epoch 99: 15139.5\n",
            "Loss after epoch 100: 15273.5\n",
            "Loss after epoch 101: 15031.25\n",
            "Loss after epoch 102: 15263.5\n",
            "Loss after epoch 103: 15258.5\n",
            "Loss after epoch 104: 15087.75\n",
            "Loss after epoch 105: 15483.0\n",
            "Loss after epoch 106: 15357.25\n",
            "Loss after epoch 107: 15258.5\n",
            "Loss after epoch 108: 15382.0\n",
            "Loss after epoch 109: 15299.25\n",
            "Loss after epoch 110: 15142.0\n",
            "Loss after epoch 111: 14771.0\n",
            "Loss after epoch 112: 15174.0\n",
            "Loss after epoch 113: 15370.0\n",
            "Loss after epoch 114: 15378.0\n",
            "Loss after epoch 115: 15433.0\n",
            "Loss after epoch 116: 15404.25\n",
            "Loss after epoch 117: 15460.25\n",
            "Loss after epoch 118: 15430.75\n",
            "Loss after epoch 119: 15151.25\n",
            "Loss after epoch 120: 15370.75\n",
            "Loss after epoch 121: 15444.5\n",
            "Loss after epoch 122: 15424.25\n",
            "Loss after epoch 123: 15188.75\n",
            "Loss after epoch 124: 15217.25\n",
            "Loss after epoch 125: 15265.25\n",
            "Loss after epoch 126: 15609.75\n",
            "Loss after epoch 127: 15370.0\n",
            "Loss after epoch 128: 15373.0\n",
            "Loss after epoch 129: 15567.25\n",
            "Loss after epoch 130: 15151.5\n",
            "Loss after epoch 131: 15679.75\n",
            "Loss after epoch 132: 15693.25\n",
            "Loss after epoch 133: 15859.0\n",
            "Loss after epoch 134: 15541.25\n",
            "Loss after epoch 135: 15503.0\n",
            "Loss after epoch 136: 15618.5\n",
            "Loss after epoch 137: 15427.5\n",
            "Loss after epoch 138: 15560.5\n",
            "Loss after epoch 139: 15462.5\n",
            "Loss after epoch 140: 15020.0\n",
            "Loss after epoch 141: 15758.5\n",
            "Loss after epoch 142: 15630.0\n",
            "Loss after epoch 143: 15465.75\n",
            "Loss after epoch 144: 15761.25\n",
            "Loss after epoch 145: 15548.75\n",
            "Loss after epoch 146: 15884.0\n",
            "Loss after epoch 147: 15461.75\n",
            "Loss after epoch 148: 15200.75\n",
            "Loss after epoch 149: 15437.75\n",
            "Loss after epoch 150: 15703.75\n",
            "Loss after epoch 151: 15607.0\n",
            "Loss after epoch 152: 15855.0\n",
            "Loss after epoch 153: 15396.0\n",
            "Loss after epoch 154: 15749.5\n",
            "Loss after epoch 155: 15709.75\n",
            "Loss after epoch 156: 15694.0\n",
            "Loss after epoch 157: 15875.5\n",
            "Loss after epoch 158: 15526.25\n",
            "Loss after epoch 159: 15825.75\n",
            "Loss after epoch 160: 15434.5\n",
            "Loss after epoch 161: 15685.75\n",
            "Loss after epoch 162: 15303.5\n",
            "Loss after epoch 163: 15814.5\n",
            "Loss after epoch 164: 15459.75\n",
            "Loss after epoch 165: 15655.0\n",
            "Loss after epoch 166: 15507.75\n",
            "Loss after epoch 167: 15936.75\n",
            "Loss after epoch 168: 15467.75\n",
            "Loss after epoch 169: 15774.5\n",
            "Loss after epoch 170: 15992.75\n",
            "Loss after epoch 171: 15632.0\n",
            "Loss after epoch 172: 15633.0\n",
            "Loss after epoch 173: 15824.25\n",
            "Loss after epoch 174: 15859.0\n",
            "Loss after epoch 175: 15761.25\n",
            "Loss after epoch 176: 15683.0\n",
            "Loss after epoch 177: 16107.25\n",
            "Loss after epoch 178: 16033.25\n",
            "Loss after epoch 179: 15645.25\n",
            "Loss after epoch 180: 16064.5\n",
            "Loss after epoch 181: 16142.75\n",
            "Loss after epoch 182: 16117.5\n",
            "Loss after epoch 183: 15958.0\n",
            "Loss after epoch 184: 16121.5\n",
            "Loss after epoch 185: 16036.0\n",
            "Loss after epoch 186: 15978.75\n",
            "Loss after epoch 187: 15701.25\n",
            "Loss after epoch 188: 15898.5\n",
            "Loss after epoch 189: 16043.5\n",
            "Loss after epoch 190: 16281.25\n",
            "Loss after epoch 191: 16005.75\n",
            "Loss after epoch 192: 15678.25\n",
            "Loss after epoch 193: 16175.0\n",
            "Loss after epoch 194: 16167.75\n",
            "Loss after epoch 195: 16166.75\n",
            "Loss after epoch 196: 16048.75\n",
            "Loss after epoch 197: 15966.0\n",
            "Loss after epoch 198: 16112.5\n",
            "Loss after epoch 199: 16730.75\n",
            "Loss after epoch 200: 15748.0\n",
            "Loss after epoch 201: 16070.5\n",
            "Loss after epoch 202: 16159.75\n",
            "Loss after epoch 203: 16200.5\n",
            "Loss after epoch 204: 15860.75\n",
            "Loss after epoch 205: 16393.75\n",
            "Loss after epoch 206: 16289.25\n",
            "Loss after epoch 207: 16319.25\n",
            "Loss after epoch 208: 16050.5\n",
            "Loss after epoch 209: 15882.25\n",
            "Loss after epoch 210: 15864.75\n",
            "Loss after epoch 211: 16488.0\n",
            "Loss after epoch 212: 16081.75\n",
            "Loss after epoch 213: 15924.25\n",
            "Loss after epoch 214: 15803.0\n",
            "Loss after epoch 215: 15952.25\n",
            "Loss after epoch 216: 16191.0\n",
            "Loss after epoch 217: 15755.25\n",
            "Loss after epoch 218: 16234.75\n",
            "Loss after epoch 219: 16622.25\n",
            "Loss after epoch 220: 16550.0\n",
            "Loss after epoch 221: 16151.0\n",
            "Loss after epoch 222: 16251.0\n",
            "Loss after epoch 223: 16574.5\n",
            "Loss after epoch 224: 16065.0\n",
            "Loss after epoch 225: 16440.75\n",
            "Loss after epoch 226: 16535.25\n",
            "Loss after epoch 227: 16404.75\n",
            "Loss after epoch 228: 16350.25\n",
            "Loss after epoch 229: 16550.25\n",
            "Loss after epoch 230: 16212.75\n",
            "Loss after epoch 231: 15091.0\n",
            "Loss after epoch 232: 15292.0\n",
            "Loss after epoch 233: 15406.5\n",
            "Loss after epoch 234: 15335.5\n",
            "Loss after epoch 235: 15177.0\n",
            "Loss after epoch 236: 15213.0\n",
            "Loss after epoch 237: 15067.0\n",
            "Loss after epoch 238: 15343.0\n",
            "Loss after epoch 239: 15272.5\n",
            "Loss after epoch 240: 15642.5\n",
            "Loss after epoch 241: 15274.5\n",
            "Loss after epoch 242: 15060.5\n",
            "Loss after epoch 243: 15292.0\n",
            "Loss after epoch 244: 15465.0\n",
            "Loss after epoch 245: 15197.5\n",
            "Loss after epoch 246: 15416.5\n",
            "Loss after epoch 247: 15074.0\n",
            "Loss after epoch 248: 15556.5\n",
            "Loss after epoch 249: 15161.5\n",
            "Loss after epoch 250: 15624.5\n",
            "Loss after epoch 251: 15503.0\n",
            "Loss after epoch 252: 15613.5\n",
            "Loss after epoch 253: 15097.0\n",
            "Loss after epoch 254: 15122.0\n",
            "Loss after epoch 255: 15348.0\n",
            "Loss after epoch 256: 15501.0\n",
            "Loss after epoch 257: 15237.0\n",
            "Loss after epoch 258: 15588.5\n",
            "Loss after epoch 259: 15047.0\n",
            "Loss after epoch 260: 15256.0\n",
            "Loss after epoch 261: 15519.0\n",
            "Loss after epoch 262: 15235.0\n",
            "Loss after epoch 263: 15535.0\n",
            "Loss after epoch 264: 15570.0\n",
            "Loss after epoch 265: 15719.0\n",
            "Loss after epoch 266: 15306.5\n",
            "Loss after epoch 267: 15548.5\n",
            "Loss after epoch 268: 15544.0\n",
            "Loss after epoch 269: 15219.5\n",
            "Loss after epoch 270: 15244.5\n",
            "Loss after epoch 271: 15147.0\n",
            "Loss after epoch 272: 15551.5\n",
            "Loss after epoch 273: 15319.5\n",
            "Loss after epoch 274: 15291.0\n",
            "Loss after epoch 275: 15359.5\n",
            "Loss after epoch 276: 15470.0\n",
            "Loss after epoch 277: 15543.0\n",
            "Loss after epoch 278: 15318.0\n",
            "Loss after epoch 279: 15930.5\n",
            "Loss after epoch 280: 15191.5\n",
            "Loss after epoch 281: 15349.0\n",
            "Loss after epoch 282: 15453.5\n",
            "Loss after epoch 283: 15399.5\n",
            "Loss after epoch 284: 15764.0\n",
            "Loss after epoch 285: 15553.0\n",
            "Loss after epoch 286: 15629.5\n",
            "Loss after epoch 287: 15386.0\n",
            "Loss after epoch 288: 15407.0\n",
            "Loss after epoch 289: 16097.0\n",
            "Loss after epoch 290: 15707.0\n",
            "Loss after epoch 291: 15419.5\n",
            "Loss after epoch 292: 15736.5\n",
            "Loss after epoch 293: 15350.5\n",
            "Loss after epoch 294: 15606.0\n",
            "Loss after epoch 295: 15491.5\n",
            "Loss after epoch 296: 15555.0\n",
            "Loss after epoch 297: 15577.5\n",
            "Loss after epoch 298: 15755.5\n",
            "Loss after epoch 299: 15642.0\n",
            "Loss after epoch 300: 15724.0\n",
            "Loss after epoch 301: 15812.5\n",
            "Loss after epoch 302: 15653.5\n",
            "Loss after epoch 303: 15697.0\n",
            "Loss after epoch 304: 15989.5\n",
            "Loss after epoch 305: 15595.5\n",
            "Loss after epoch 306: 15421.0\n",
            "Loss after epoch 307: 15191.0\n",
            "Loss after epoch 308: 15774.0\n",
            "Loss after epoch 309: 15608.5\n",
            "Loss after epoch 310: 15678.5\n",
            "Loss after epoch 311: 15802.5\n",
            "Loss after epoch 312: 15772.0\n",
            "Loss after epoch 313: 15797.0\n",
            "Loss after epoch 314: 15413.0\n",
            "Loss after epoch 315: 15738.5\n",
            "Loss after epoch 316: 16075.0\n",
            "Loss after epoch 317: 15748.0\n",
            "Loss after epoch 318: 15744.0\n",
            "Loss after epoch 319: 15964.0\n",
            "Loss after epoch 320: 15760.0\n",
            "Loss after epoch 321: 15628.5\n",
            "Loss after epoch 322: 15824.0\n",
            "Loss after epoch 323: 15694.5\n",
            "Loss after epoch 324: 15600.5\n",
            "Loss after epoch 325: 15922.5\n",
            "Loss after epoch 326: 16044.0\n",
            "Loss after epoch 327: 16095.5\n",
            "Loss after epoch 328: 15728.5\n",
            "Loss after epoch 329: 15467.5\n",
            "Loss after epoch 330: 15561.0\n",
            "Loss after epoch 331: 15598.5\n",
            "Loss after epoch 332: 15584.5\n",
            "Loss after epoch 333: 15480.5\n",
            "Loss after epoch 334: 15595.5\n",
            "Loss after epoch 335: 15690.5\n",
            "Loss after epoch 336: 15829.5\n",
            "Loss after epoch 337: 15852.5\n",
            "Loss after epoch 338: 15852.5\n",
            "Loss after epoch 339: 16004.0\n",
            "Loss after epoch 340: 15550.5\n",
            "Loss after epoch 341: 15949.5\n",
            "Loss after epoch 342: 15732.5\n",
            "Loss after epoch 343: 15489.5\n",
            "Loss after epoch 344: 16404.0\n",
            "Loss after epoch 345: 16106.0\n",
            "Loss after epoch 346: 15694.5\n",
            "Loss after epoch 347: 15784.5\n",
            "Loss after epoch 348: 16241.5\n",
            "Loss after epoch 349: 16078.0\n",
            "Loss after epoch 350: 15860.0\n",
            "Loss after epoch 351: 16099.5\n",
            "Loss after epoch 352: 15306.0\n",
            "Loss after epoch 353: 15563.0\n",
            "Loss after epoch 354: 15326.5\n",
            "Loss after epoch 355: 15393.0\n",
            "Loss after epoch 356: 15632.5\n",
            "Loss after epoch 357: 15640.5\n",
            "Loss after epoch 358: 15749.5\n",
            "Loss after epoch 359: 15205.5\n",
            "Loss after epoch 360: 15534.0\n",
            "Loss after epoch 361: 15279.0\n",
            "Loss after epoch 362: 15341.0\n",
            "Loss after epoch 363: 15265.5\n",
            "Loss after epoch 364: 15489.0\n",
            "Loss after epoch 365: 15328.5\n",
            "Loss after epoch 366: 15389.5\n",
            "Loss after epoch 367: 15662.0\n",
            "Loss after epoch 368: 15512.5\n",
            "Loss after epoch 369: 15170.5\n",
            "Loss after epoch 370: 15141.0\n",
            "Loss after epoch 371: 15294.0\n",
            "Loss after epoch 372: 15226.0\n",
            "Loss after epoch 373: 15087.0\n",
            "Loss after epoch 374: 14918.0\n",
            "Loss after epoch 375: 15299.5\n",
            "Loss after epoch 376: 15591.0\n",
            "Loss after epoch 377: 14979.0\n",
            "Loss after epoch 378: 15160.5\n",
            "Loss after epoch 379: 15012.0\n",
            "Loss after epoch 380: 15370.5\n",
            "Loss after epoch 381: 15361.0\n",
            "Loss after epoch 382: 15394.5\n",
            "Loss after epoch 383: 15205.0\n",
            "Loss after epoch 384: 15126.5\n",
            "Loss after epoch 385: 15472.5\n",
            "Loss after epoch 386: 15188.0\n",
            "Loss after epoch 387: 15179.5\n",
            "Loss after epoch 388: 15471.5\n",
            "Loss after epoch 389: 15497.5\n",
            "Loss after epoch 390: 15516.5\n",
            "Loss after epoch 391: 15335.0\n",
            "Loss after epoch 392: 15749.0\n",
            "Loss after epoch 393: 15402.0\n",
            "Loss after epoch 394: 15806.5\n",
            "Loss after epoch 395: 15720.5\n",
            "Loss after epoch 396: 15240.0\n",
            "Loss after epoch 397: 15124.0\n",
            "Loss after epoch 398: 15325.0\n",
            "Loss after epoch 399: 15580.0\n",
            "Loss after epoch 400: 15729.0\n",
            "Loss after epoch 401: 15612.0\n",
            "Loss after epoch 402: 15984.5\n",
            "Loss after epoch 403: 15692.0\n",
            "Loss after epoch 404: 15319.0\n",
            "Loss after epoch 405: 15925.0\n",
            "Loss after epoch 406: 15736.0\n",
            "Loss after epoch 407: 16075.0\n",
            "Loss after epoch 408: 16176.5\n",
            "Loss after epoch 409: 15977.5\n",
            "Loss after epoch 410: 16214.0\n",
            "Loss after epoch 411: 16333.0\n",
            "Loss after epoch 412: 16214.0\n",
            "Loss after epoch 413: 15561.0\n",
            "Loss after epoch 414: 16006.0\n",
            "Loss after epoch 415: 15655.0\n",
            "Loss after epoch 416: 16258.0\n",
            "Loss after epoch 417: 15495.0\n",
            "Loss after epoch 418: 15722.5\n",
            "Loss after epoch 419: 15552.5\n",
            "Loss after epoch 420: 15876.0\n",
            "Loss after epoch 421: 15936.0\n",
            "Loss after epoch 422: 15992.5\n",
            "Loss after epoch 423: 15930.5\n",
            "Loss after epoch 424: 15745.0\n",
            "Loss after epoch 425: 16041.5\n",
            "Loss after epoch 426: 15746.0\n",
            "Loss after epoch 427: 15791.0\n",
            "Loss after epoch 428: 15972.5\n",
            "Loss after epoch 429: 15669.0\n",
            "Loss after epoch 430: 15987.0\n",
            "Loss after epoch 431: 16039.5\n",
            "Loss after epoch 432: 16151.0\n",
            "Loss after epoch 433: 16071.5\n",
            "Loss after epoch 434: 16350.0\n",
            "Loss after epoch 435: 16182.5\n",
            "Loss after epoch 436: 15869.0\n",
            "Loss after epoch 437: 16078.0\n",
            "Loss after epoch 438: 16570.5\n",
            "Loss after epoch 439: 16212.0\n",
            "Loss after epoch 440: 15593.0\n",
            "Loss after epoch 441: 15878.0\n",
            "Loss after epoch 442: 16051.0\n",
            "Loss after epoch 443: 15767.5\n",
            "Loss after epoch 444: 15848.5\n",
            "Loss after epoch 445: 16362.0\n",
            "Loss after epoch 446: 16054.5\n",
            "Loss after epoch 447: 16017.0\n",
            "Loss after epoch 448: 16158.5\n",
            "Loss after epoch 449: 15836.5\n",
            "Loss after epoch 450: 16467.5\n",
            "Loss after epoch 451: 16007.5\n",
            "Loss after epoch 452: 16393.5\n",
            "Loss after epoch 453: 15931.0\n",
            "Loss after epoch 454: 16164.0\n",
            "Loss after epoch 455: 15875.0\n",
            "Loss after epoch 456: 15909.5\n",
            "Loss after epoch 457: 16026.5\n",
            "Loss after epoch 458: 15542.0\n",
            "Loss after epoch 459: 15917.0\n",
            "Loss after epoch 460: 15933.5\n",
            "Loss after epoch 461: 15963.0\n",
            "Loss after epoch 462: 15953.5\n",
            "Loss after epoch 463: 15922.5\n",
            "Loss after epoch 464: 15598.5\n",
            "Loss after epoch 465: 16027.0\n",
            "Loss after epoch 466: 15941.0\n",
            "Loss after epoch 467: 16149.0\n",
            "Loss after epoch 468: 15980.0\n",
            "Loss after epoch 469: 16169.0\n",
            "Loss after epoch 470: 15670.0\n",
            "Loss after epoch 471: 15880.0\n",
            "Loss after epoch 472: 15752.0\n",
            "Loss after epoch 473: 15917.5\n",
            "Loss after epoch 474: 16004.5\n",
            "Loss after epoch 475: 16261.5\n",
            "Loss after epoch 476: 16180.0\n",
            "Loss after epoch 477: 15611.5\n",
            "Loss after epoch 478: 16032.5\n",
            "Loss after epoch 479: 15980.0\n",
            "Loss after epoch 480: 16128.5\n",
            "Loss after epoch 481: 16610.5\n",
            "Loss after epoch 482: 16498.5\n",
            "Loss after epoch 483: 15685.0\n",
            "Loss after epoch 484: 16080.5\n",
            "Loss after epoch 485: 15955.5\n",
            "Loss after epoch 486: 15797.5\n",
            "Loss after epoch 487: 15784.0\n",
            "Loss after epoch 488: 16014.0\n",
            "Loss after epoch 489: 16120.0\n",
            "Loss after epoch 490: 15909.0\n",
            "Loss after epoch 491: 15717.0\n",
            "Loss after epoch 492: 16145.5\n",
            "Loss after epoch 493: 16552.5\n",
            "Loss after epoch 494: 16201.5\n",
            "Loss after epoch 495: 16308.0\n",
            "Loss after epoch 496: 16133.5\n",
            "Loss after epoch 497: 15760.5\n",
            "Loss after epoch 498: 15877.5\n",
            "Loss after epoch 499: 15443.0\n",
            "Loss after epoch 500: 15615.0\n",
            "Loss after epoch 501: 15856.0\n",
            "Loss after epoch 502: 15849.0\n",
            "Loss after epoch 503: 15788.0\n",
            "Loss after epoch 504: 15844.0\n",
            "Loss after epoch 505: 15655.0\n",
            "Loss after epoch 506: 15556.0\n",
            "Loss after epoch 507: 15530.0\n",
            "Loss after epoch 508: 15930.0\n",
            "Loss after epoch 509: 15450.0\n",
            "Loss after epoch 510: 15691.0\n",
            "Loss after epoch 511: 15658.0\n",
            "Loss after epoch 512: 15688.0\n",
            "Loss after epoch 513: 15812.0\n",
            "Loss after epoch 514: 15562.0\n",
            "Loss after epoch 515: 15560.0\n",
            "Loss after epoch 516: 15624.0\n",
            "Loss after epoch 517: 15537.0\n",
            "Loss after epoch 518: 15467.0\n",
            "Loss after epoch 519: 15944.0\n",
            "Loss after epoch 520: 15983.0\n",
            "Loss after epoch 521: 15042.0\n",
            "Loss after epoch 522: 16041.0\n",
            "Loss after epoch 523: 16137.0\n",
            "Loss after epoch 524: 15957.0\n",
            "Loss after epoch 525: 15730.0\n",
            "Loss after epoch 526: 15973.0\n",
            "Loss after epoch 527: 15802.0\n",
            "Loss after epoch 528: 15819.0\n",
            "Loss after epoch 529: 15673.0\n",
            "Loss after epoch 530: 15841.0\n",
            "Loss after epoch 531: 15775.0\n",
            "Loss after epoch 532: 15431.0\n",
            "Loss after epoch 533: 15738.0\n",
            "Loss after epoch 534: 15696.0\n",
            "Loss after epoch 535: 15680.0\n",
            "Loss after epoch 536: 15648.0\n",
            "Loss after epoch 537: 15833.0\n",
            "Loss after epoch 538: 15908.0\n",
            "Loss after epoch 539: 15727.0\n",
            "Loss after epoch 540: 15655.0\n",
            "Loss after epoch 541: 15755.0\n",
            "Loss after epoch 542: 15756.0\n",
            "Loss after epoch 543: 15908.0\n",
            "Loss after epoch 544: 15902.0\n",
            "Loss after epoch 545: 15637.0\n",
            "Loss after epoch 546: 15829.0\n",
            "Loss after epoch 547: 15640.0\n",
            "Loss after epoch 548: 15722.0\n",
            "Loss after epoch 549: 15788.0\n",
            "Loss after epoch 550: 15826.0\n",
            "Loss after epoch 551: 15586.0\n",
            "Loss after epoch 552: 15682.0\n",
            "Loss after epoch 553: 16004.0\n",
            "Loss after epoch 554: 15723.0\n",
            "Loss after epoch 555: 15887.0\n",
            "Loss after epoch 556: 15877.0\n",
            "Loss after epoch 557: 15908.0\n",
            "Loss after epoch 558: 15869.0\n",
            "Loss after epoch 559: 15779.0\n",
            "Loss after epoch 560: 15701.0\n",
            "Loss after epoch 561: 15682.0\n",
            "Loss after epoch 562: 15740.0\n",
            "Loss after epoch 563: 15709.0\n",
            "Loss after epoch 564: 15850.0\n",
            "Loss after epoch 565: 16020.0\n",
            "Loss after epoch 566: 15396.0\n",
            "Loss after epoch 567: 15640.0\n",
            "Loss after epoch 568: 15633.0\n",
            "Loss after epoch 569: 15912.0\n",
            "Loss after epoch 570: 15722.0\n",
            "Loss after epoch 571: 16256.0\n",
            "Loss after epoch 572: 15507.0\n",
            "Loss after epoch 573: 16516.0\n",
            "Loss after epoch 574: 15780.0\n",
            "Loss after epoch 575: 15786.0\n",
            "Loss after epoch 576: 16029.0\n",
            "Loss after epoch 577: 16142.0\n",
            "Loss after epoch 578: 15238.0\n",
            "Loss after epoch 579: 15613.0\n",
            "Loss after epoch 580: 15697.0\n",
            "Loss after epoch 581: 14991.0\n",
            "Loss after epoch 582: 15697.0\n",
            "Loss after epoch 583: 16074.0\n",
            "Loss after epoch 584: 16244.0\n",
            "Loss after epoch 585: 16110.0\n",
            "Loss after epoch 586: 15828.0\n",
            "Loss after epoch 587: 15589.0\n",
            "Loss after epoch 588: 15685.0\n",
            "Loss after epoch 589: 15343.0\n",
            "Loss after epoch 590: 15790.0\n",
            "Loss after epoch 591: 15579.0\n",
            "Loss after epoch 592: 14884.0\n",
            "Loss after epoch 593: 15240.0\n",
            "Loss after epoch 594: 15133.0\n",
            "Loss after epoch 595: 15368.0\n",
            "Loss after epoch 596: 15350.0\n",
            "Loss after epoch 597: 15277.0\n",
            "Loss after epoch 598: 15182.0\n",
            "Loss after epoch 599: 15061.0\n",
            "Loss after epoch 600: 15283.0\n",
            "Loss after epoch 601: 15858.0\n",
            "Loss after epoch 602: 15373.0\n",
            "Loss after epoch 603: 15386.0\n",
            "Loss after epoch 604: 15392.0\n",
            "Loss after epoch 605: 15032.0\n",
            "Loss after epoch 606: 15294.0\n",
            "Loss after epoch 607: 15062.0\n",
            "Loss after epoch 608: 15339.0\n",
            "Loss after epoch 609: 15388.0\n",
            "Loss after epoch 610: 15444.0\n",
            "Loss after epoch 611: 15068.0\n",
            "Loss after epoch 612: 15188.0\n",
            "Loss after epoch 613: 15109.0\n",
            "Loss after epoch 614: 15441.0\n",
            "Loss after epoch 615: 15290.0\n",
            "Loss after epoch 616: 15342.0\n",
            "Loss after epoch 617: 15198.0\n",
            "Loss after epoch 618: 15335.0\n",
            "Loss after epoch 619: 15606.0\n",
            "Loss after epoch 620: 15318.0\n",
            "Loss after epoch 621: 14637.0\n",
            "Loss after epoch 622: 15620.0\n",
            "Loss after epoch 623: 15586.0\n",
            "Loss after epoch 624: 16031.0\n",
            "Loss after epoch 625: 15464.0\n",
            "Loss after epoch 626: 15778.0\n",
            "Loss after epoch 627: 15689.0\n",
            "Loss after epoch 628: 15716.0\n",
            "Loss after epoch 629: 15974.0\n",
            "Loss after epoch 630: 15901.0\n",
            "Loss after epoch 631: 15535.0\n",
            "Loss after epoch 632: 15693.0\n",
            "Loss after epoch 633: 15788.0\n",
            "Loss after epoch 634: 15791.0\n",
            "Loss after epoch 635: 15751.0\n",
            "Loss after epoch 636: 15462.0\n",
            "Loss after epoch 637: 15452.0\n",
            "Loss after epoch 638: 16048.0\n",
            "Loss after epoch 639: 15779.0\n",
            "Loss after epoch 640: 15706.0\n",
            "Loss after epoch 641: 15808.0\n",
            "Loss after epoch 642: 15989.0\n",
            "Loss after epoch 643: 15735.0\n",
            "Loss after epoch 644: 15810.0\n",
            "Loss after epoch 645: 15342.0\n",
            "Loss after epoch 646: 15896.0\n",
            "Loss after epoch 647: 15441.0\n",
            "Loss after epoch 648: 16141.0\n",
            "Loss after epoch 649: 15132.0\n",
            "Loss after epoch 650: 15367.0\n",
            "Loss after epoch 651: 15914.0\n",
            "Loss after epoch 652: 15503.0\n",
            "Loss after epoch 653: 15490.0\n",
            "Loss after epoch 654: 15243.0\n",
            "Loss after epoch 655: 15387.0\n",
            "Loss after epoch 656: 15639.0\n",
            "Loss after epoch 657: 15358.0\n",
            "Loss after epoch 658: 15835.0\n",
            "Loss after epoch 659: 15152.0\n",
            "Loss after epoch 660: 15785.0\n",
            "Loss after epoch 661: 15708.0\n",
            "Loss after epoch 662: 15449.0\n",
            "Loss after epoch 663: 15499.0\n",
            "Loss after epoch 664: 15665.0\n",
            "Loss after epoch 665: 15452.0\n",
            "Loss after epoch 666: 15006.0\n",
            "Loss after epoch 667: 15367.0\n",
            "Loss after epoch 668: 15157.0\n",
            "Loss after epoch 669: 15778.0\n",
            "Loss after epoch 670: 15366.0\n",
            "Loss after epoch 671: 15406.0\n",
            "Loss after epoch 672: 16088.0\n",
            "Loss after epoch 673: 16158.0\n",
            "Loss after epoch 674: 15738.0\n",
            "Loss after epoch 675: 15770.0\n",
            "Loss after epoch 676: 15440.0\n",
            "Loss after epoch 677: 15780.0\n",
            "Loss after epoch 678: 15335.0\n",
            "Loss after epoch 679: 15882.0\n",
            "Loss after epoch 680: 15606.0\n",
            "Loss after epoch 681: 15786.0\n",
            "Loss after epoch 682: 15979.0\n",
            "Loss after epoch 683: 15565.0\n",
            "Loss after epoch 684: 15918.0\n",
            "Loss after epoch 685: 15659.0\n",
            "Loss after epoch 686: 15731.0\n",
            "Loss after epoch 687: 15549.0\n",
            "Loss after epoch 688: 15702.0\n",
            "Loss after epoch 689: 15924.0\n",
            "Loss after epoch 690: 15785.0\n",
            "Loss after epoch 691: 15696.0\n",
            "Loss after epoch 692: 15765.0\n",
            "Loss after epoch 693: 15522.0\n",
            "Loss after epoch 694: 15173.0\n",
            "Loss after epoch 695: 15513.0\n",
            "Loss after epoch 696: 15818.0\n",
            "Loss after epoch 697: 15831.0\n",
            "Loss after epoch 698: 15487.0\n",
            "Loss after epoch 699: 15694.0\n",
            "Loss after epoch 700: 15575.0\n",
            "Loss after epoch 701: 15569.0\n",
            "Loss after epoch 702: 15847.0\n",
            "Loss after epoch 703: 15276.0\n",
            "Loss after epoch 704: 15435.0\n",
            "Loss after epoch 705: 15772.0\n",
            "Loss after epoch 706: 15677.0\n",
            "Loss after epoch 707: 15555.0\n",
            "Loss after epoch 708: 15597.0\n",
            "Loss after epoch 709: 15624.0\n",
            "Loss after epoch 710: 15911.0\n",
            "Loss after epoch 711: 15700.0\n",
            "Loss after epoch 712: 15441.0\n",
            "Loss after epoch 713: 15450.0\n",
            "Loss after epoch 714: 15438.0\n",
            "Loss after epoch 715: 16083.0\n",
            "Loss after epoch 716: 15852.0\n",
            "Loss after epoch 717: 15911.0\n",
            "Loss after epoch 718: 15497.0\n",
            "Loss after epoch 719: 15595.0\n",
            "Loss after epoch 720: 15710.0\n",
            "Loss after epoch 721: 15502.0\n",
            "Loss after epoch 722: 15408.0\n",
            "Loss after epoch 723: 15826.0\n",
            "Loss after epoch 724: 15541.0\n",
            "Loss after epoch 725: 15644.0\n",
            "Loss after epoch 726: 15055.0\n",
            "Loss after epoch 727: 15721.0\n",
            "Loss after epoch 728: 15597.0\n",
            "Loss after epoch 729: 15690.0\n",
            "Loss after epoch 730: 15919.0\n",
            "Loss after epoch 731: 15874.0\n",
            "Loss after epoch 732: 15963.0\n",
            "Loss after epoch 733: 15517.0\n",
            "Loss after epoch 734: 15993.0\n",
            "Loss after epoch 735: 15865.0\n",
            "Loss after epoch 736: 15845.0\n",
            "Loss after epoch 737: 15626.0\n",
            "Loss after epoch 738: 15562.0\n",
            "Loss after epoch 739: 15354.0\n",
            "Loss after epoch 740: 15615.0\n",
            "Loss after epoch 741: 15912.0\n",
            "Loss after epoch 742: 15323.0\n",
            "Loss after epoch 743: 15746.0\n",
            "Loss after epoch 744: 15373.0\n",
            "Loss after epoch 745: 15588.0\n",
            "Loss after epoch 746: 15860.0\n",
            "Loss after epoch 747: 15740.0\n",
            "Loss after epoch 748: 15403.0\n",
            "Loss after epoch 749: 15482.0\n",
            "Loss after epoch 750: 15937.0\n",
            "Loss after epoch 751: 15800.0\n",
            "Loss after epoch 752: 15723.0\n",
            "Loss after epoch 753: 15053.0\n",
            "Loss after epoch 754: 15352.0\n",
            "Loss after epoch 755: 15961.0\n",
            "Loss after epoch 756: 15627.0\n",
            "Loss after epoch 757: 15407.0\n",
            "Loss after epoch 758: 15846.0\n",
            "Loss after epoch 759: 15747.0\n",
            "Loss after epoch 760: 15541.0\n",
            "Loss after epoch 761: 15868.0\n",
            "Loss after epoch 762: 15055.0\n",
            "Loss after epoch 763: 15734.0\n",
            "Loss after epoch 764: 15060.0\n",
            "Loss after epoch 765: 15945.0\n",
            "Loss after epoch 766: 15573.0\n",
            "Loss after epoch 767: 15958.0\n",
            "Loss after epoch 768: 15449.0\n",
            "Loss after epoch 769: 15240.0\n",
            "Loss after epoch 770: 15896.0\n",
            "Loss after epoch 771: 15404.0\n",
            "Loss after epoch 772: 15566.0\n",
            "Loss after epoch 773: 15512.0\n",
            "Loss after epoch 774: 15508.0\n",
            "Loss after epoch 775: 15712.0\n",
            "Loss after epoch 776: 16078.0\n",
            "Loss after epoch 777: 15102.0\n",
            "Loss after epoch 778: 14985.0\n",
            "Loss after epoch 779: 15029.0\n",
            "Loss after epoch 780: 14897.0\n",
            "Loss after epoch 781: 14975.0\n",
            "Loss after epoch 782: 15364.0\n",
            "Loss after epoch 783: 15022.0\n",
            "Loss after epoch 784: 15464.0\n",
            "Loss after epoch 785: 15039.0\n",
            "Loss after epoch 786: 15084.0\n",
            "Loss after epoch 787: 15687.0\n",
            "Loss after epoch 788: 15642.0\n",
            "Loss after epoch 789: 15343.0\n",
            "Loss after epoch 790: 15287.0\n",
            "Loss after epoch 791: 15686.0\n",
            "Loss after epoch 792: 15508.0\n",
            "Loss after epoch 793: 15769.0\n",
            "Loss after epoch 794: 15518.0\n",
            "Loss after epoch 795: 15219.0\n",
            "Loss after epoch 796: 16042.0\n",
            "Loss after epoch 797: 15913.0\n",
            "Loss after epoch 798: 15677.0\n",
            "Loss after epoch 799: 16011.0\n",
            "Loss after epoch 800: 15755.0\n",
            "Loss after epoch 801: 15459.0\n",
            "Loss after epoch 802: 15999.0\n",
            "Loss after epoch 803: 15666.0\n",
            "Loss after epoch 804: 15562.0\n",
            "Loss after epoch 805: 15370.0\n",
            "Loss after epoch 806: 15773.0\n",
            "Loss after epoch 807: 15699.0\n",
            "Loss after epoch 808: 15242.0\n",
            "Loss after epoch 809: 15202.0\n",
            "Loss after epoch 810: 15082.0\n",
            "Loss after epoch 811: 15162.0\n",
            "Loss after epoch 812: 15076.0\n",
            "Loss after epoch 813: 14794.0\n",
            "Loss after epoch 814: 15295.0\n",
            "Loss after epoch 815: 15001.0\n",
            "Loss after epoch 816: 15320.0\n",
            "Loss after epoch 817: 15151.0\n",
            "Loss after epoch 818: 14863.0\n",
            "Loss after epoch 819: 15120.0\n",
            "Loss after epoch 820: 14905.0\n",
            "Loss after epoch 821: 15281.0\n",
            "Loss after epoch 822: 14794.0\n",
            "Loss after epoch 823: 15055.0\n",
            "Loss after epoch 824: 14913.0\n",
            "Loss after epoch 825: 15205.0\n",
            "Loss after epoch 826: 15220.0\n",
            "Loss after epoch 827: 15191.0\n",
            "Loss after epoch 828: 14826.0\n",
            "Loss after epoch 829: 15138.0\n",
            "Loss after epoch 830: 15045.0\n",
            "Loss after epoch 831: 15115.0\n",
            "Loss after epoch 832: 15235.0\n",
            "Loss after epoch 833: 14703.0\n",
            "Loss after epoch 834: 14630.0\n",
            "Loss after epoch 835: 15362.0\n",
            "Loss after epoch 836: 15145.0\n",
            "Loss after epoch 837: 14834.0\n",
            "Loss after epoch 838: 14764.0\n",
            "Loss after epoch 839: 14904.0\n",
            "Loss after epoch 840: 14706.0\n",
            "Loss after epoch 841: 14911.0\n",
            "Loss after epoch 842: 14895.0\n",
            "Loss after epoch 843: 14822.0\n",
            "Loss after epoch 844: 14784.0\n",
            "Loss after epoch 845: 14599.0\n",
            "Loss after epoch 846: 15322.0\n",
            "Loss after epoch 847: 14913.0\n",
            "Loss after epoch 848: 14806.0\n",
            "Loss after epoch 849: 15361.0\n",
            "Loss after epoch 850: 15180.0\n",
            "Loss after epoch 851: 15068.0\n",
            "Loss after epoch 852: 15091.0\n",
            "Loss after epoch 853: 15313.0\n",
            "Loss after epoch 854: 15483.0\n",
            "Loss after epoch 855: 14856.0\n",
            "Loss after epoch 856: 14521.0\n",
            "Loss after epoch 857: 14950.0\n",
            "Loss after epoch 858: 14903.0\n",
            "Loss after epoch 859: 15239.0\n",
            "Loss after epoch 860: 14926.0\n",
            "Loss after epoch 861: 14975.0\n",
            "Loss after epoch 862: 15022.0\n",
            "Loss after epoch 863: 14977.0\n",
            "Loss after epoch 864: 14737.0\n",
            "Loss after epoch 865: 15097.0\n",
            "Loss after epoch 866: 14523.0\n",
            "Loss after epoch 867: 15093.0\n",
            "Loss after epoch 868: 15009.0\n",
            "Loss after epoch 869: 14959.0\n",
            "Loss after epoch 870: 15146.0\n",
            "Loss after epoch 871: 14645.0\n",
            "Loss after epoch 872: 14775.0\n",
            "Loss after epoch 873: 14750.0\n",
            "Loss after epoch 874: 14393.0\n",
            "Loss after epoch 875: 14598.0\n",
            "Loss after epoch 876: 14776.0\n",
            "Loss after epoch 877: 15024.0\n",
            "Loss after epoch 878: 14692.0\n",
            "Loss after epoch 879: 14732.0\n",
            "Loss after epoch 880: 14960.0\n",
            "Loss after epoch 881: 14795.0\n",
            "Loss after epoch 882: 15153.0\n",
            "Loss after epoch 883: 15352.0\n",
            "Loss after epoch 884: 14692.0\n",
            "Loss after epoch 885: 14945.0\n",
            "Loss after epoch 886: 15033.0\n",
            "Loss after epoch 887: 14644.0\n",
            "Loss after epoch 888: 14590.0\n",
            "Loss after epoch 889: 14867.0\n",
            "Loss after epoch 890: 15345.0\n",
            "Loss after epoch 891: 14584.0\n",
            "Loss after epoch 892: 14745.0\n",
            "Loss after epoch 893: 15398.0\n",
            "Loss after epoch 894: 14835.0\n",
            "Loss after epoch 895: 14535.0\n",
            "Loss after epoch 896: 14804.0\n",
            "Loss after epoch 897: 15075.0\n",
            "Loss after epoch 898: 14885.0\n",
            "Loss after epoch 899: 14711.0\n",
            "Loss after epoch 900: 14696.0\n",
            "Loss after epoch 901: 14808.0\n",
            "Loss after epoch 902: 15153.0\n",
            "Loss after epoch 903: 14658.0\n",
            "Loss after epoch 904: 14839.0\n",
            "Loss after epoch 905: 15326.0\n",
            "Loss after epoch 906: 14820.0\n",
            "Loss after epoch 907: 14705.0\n",
            "Loss after epoch 908: 15056.0\n",
            "Loss after epoch 909: 15152.0\n",
            "Loss after epoch 910: 14489.0\n",
            "Loss after epoch 911: 14844.0\n",
            "Loss after epoch 912: 14892.0\n",
            "Loss after epoch 913: 14679.0\n",
            "Loss after epoch 914: 15190.0\n",
            "Loss after epoch 915: 14605.0\n",
            "Loss after epoch 916: 14781.0\n",
            "Loss after epoch 917: 14754.0\n",
            "Loss after epoch 918: 15196.0\n",
            "Loss after epoch 919: 14573.0\n",
            "Loss after epoch 920: 14724.0\n",
            "Loss after epoch 921: 15009.0\n",
            "Loss after epoch 922: 14566.0\n",
            "Loss after epoch 923: 14767.0\n",
            "Loss after epoch 924: 14892.0\n",
            "Loss after epoch 925: 15007.0\n",
            "Loss after epoch 926: 14480.0\n",
            "Loss after epoch 927: 14834.0\n",
            "Loss after epoch 928: 14942.0\n",
            "Loss after epoch 929: 14364.0\n",
            "Loss after epoch 930: 14908.0\n",
            "Loss after epoch 931: 14519.0\n",
            "Loss after epoch 932: 14708.0\n",
            "Loss after epoch 933: 14976.0\n",
            "Loss after epoch 934: 14429.0\n",
            "Loss after epoch 935: 14071.0\n",
            "Loss after epoch 936: 13893.0\n",
            "Loss after epoch 937: 13982.0\n",
            "Loss after epoch 938: 14236.0\n",
            "Loss after epoch 939: 14322.0\n",
            "Loss after epoch 940: 14225.0\n",
            "Loss after epoch 941: 14751.0\n",
            "Loss after epoch 942: 14393.0\n",
            "Loss after epoch 943: 14545.0\n",
            "Loss after epoch 944: 14814.0\n",
            "Loss after epoch 945: 14709.0\n",
            "Loss after epoch 946: 14903.0\n",
            "Loss after epoch 947: 14860.0\n",
            "Loss after epoch 948: 14741.0\n",
            "Loss after epoch 949: 14351.0\n",
            "Loss after epoch 950: 14412.0\n",
            "Loss after epoch 951: 14863.0\n",
            "Loss after epoch 952: 14235.0\n",
            "Loss after epoch 953: 14626.0\n",
            "Loss after epoch 954: 14294.0\n",
            "Loss after epoch 955: 14654.0\n",
            "Loss after epoch 956: 14354.0\n",
            "Loss after epoch 957: 14231.0\n",
            "Loss after epoch 958: 15025.0\n",
            "Loss after epoch 959: 14328.0\n",
            "Loss after epoch 960: 14590.0\n",
            "Loss after epoch 961: 14230.0\n",
            "Loss after epoch 962: 14553.0\n",
            "Loss after epoch 963: 14664.0\n",
            "Loss after epoch 964: 14388.0\n",
            "Loss after epoch 965: 14379.0\n",
            "Loss after epoch 966: 14560.0\n",
            "Loss after epoch 967: 14023.0\n",
            "Loss after epoch 968: 14427.0\n",
            "Loss after epoch 969: 14620.0\n",
            "Loss after epoch 970: 14713.0\n",
            "Loss after epoch 971: 14826.0\n",
            "Loss after epoch 972: 14323.0\n",
            "Loss after epoch 973: 14431.0\n",
            "Loss after epoch 974: 14780.0\n",
            "Loss after epoch 975: 14595.0\n",
            "Loss after epoch 976: 14568.0\n",
            "Loss after epoch 977: 14272.0\n",
            "Loss after epoch 978: 14412.0\n",
            "Loss after epoch 979: 14472.0\n",
            "Loss after epoch 980: 14457.0\n",
            "Loss after epoch 981: 14311.0\n",
            "Loss after epoch 982: 14131.0\n",
            "Loss after epoch 983: 14096.0\n",
            "Loss after epoch 984: 14626.0\n",
            "Loss after epoch 985: 14478.0\n",
            "Loss after epoch 986: 14500.0\n",
            "Loss after epoch 987: 14617.0\n",
            "Loss after epoch 988: 14262.0\n",
            "Loss after epoch 989: 14394.0\n",
            "Loss after epoch 990: 14311.0\n",
            "Loss after epoch 991: 14208.0\n",
            "Loss after epoch 992: 14360.0\n",
            "Loss after epoch 993: 14282.0\n",
            "Loss after epoch 994: 14567.0\n",
            "Loss after epoch 995: 14857.0\n",
            "Loss after epoch 996: 14585.0\n",
            "Loss after epoch 997: 14022.0\n",
            "Loss after epoch 998: 14642.0\n",
            "Loss after epoch 999: 14413.0\n",
            "Loss after epoch 1000: 14364.0\n",
            "Loss after epoch 1001: 14144.0\n",
            "Loss after epoch 1002: 14401.0\n",
            "Loss after epoch 1003: 14015.0\n",
            "Loss after epoch 1004: 14298.0\n",
            "Loss after epoch 1005: 14726.0\n",
            "Loss after epoch 1006: 14618.0\n",
            "Loss after epoch 1007: 14538.0\n",
            "Loss after epoch 1008: 14495.0\n",
            "Loss after epoch 1009: 14563.0\n",
            "Loss after epoch 1010: 14306.0\n",
            "Loss after epoch 1011: 14539.0\n",
            "Loss after epoch 1012: 14557.0\n",
            "Loss after epoch 1013: 14393.0\n",
            "Loss after epoch 1014: 14189.0\n",
            "Loss after epoch 1015: 14588.0\n",
            "Loss after epoch 1016: 13934.0\n",
            "Loss after epoch 1017: 14498.0\n",
            "Loss after epoch 1018: 14645.0\n",
            "Loss after epoch 1019: 14574.0\n",
            "Loss after epoch 1020: 14585.0\n",
            "Loss after epoch 1021: 15062.0\n",
            "Loss after epoch 1022: 14537.0\n",
            "Loss after epoch 1023: 14495.0\n",
            "Loss after epoch 1024: 14730.0\n",
            "Loss after epoch 1025: 14369.0\n",
            "Loss after epoch 1026: 14700.0\n",
            "Loss after epoch 1027: 14783.0\n",
            "Loss after epoch 1028: 14782.0\n",
            "Loss after epoch 1029: 14855.0\n",
            "Loss after epoch 1030: 14403.0\n",
            "Loss after epoch 1031: 14973.0\n",
            "Loss after epoch 1032: 14670.0\n",
            "Loss after epoch 1033: 14668.0\n",
            "Loss after epoch 1034: 14401.0\n",
            "Loss after epoch 1035: 14351.0\n",
            "Loss after epoch 1036: 14758.0\n",
            "Loss after epoch 1037: 14723.0\n",
            "Loss after epoch 1038: 14647.0\n",
            "Loss after epoch 1039: 15131.0\n",
            "Loss after epoch 1040: 14447.0\n",
            "Loss after epoch 1041: 14599.0\n",
            "Loss after epoch 1042: 14677.0\n",
            "Loss after epoch 1043: 14889.0\n",
            "Loss after epoch 1044: 14473.0\n",
            "Loss after epoch 1045: 14127.0\n",
            "Loss after epoch 1046: 14574.0\n",
            "Loss after epoch 1047: 14998.0\n",
            "Loss after epoch 1048: 14198.0\n",
            "Loss after epoch 1049: 12793.0\n",
            "Loss after epoch 1050: 11616.0\n",
            "Loss after epoch 1051: 11728.0\n",
            "Loss after epoch 1052: 12174.0\n",
            "Loss after epoch 1053: 11870.0\n",
            "Loss after epoch 1054: 12024.0\n",
            "Loss after epoch 1055: 12170.0\n",
            "Loss after epoch 1056: 12064.0\n",
            "Loss after epoch 1057: 12058.0\n",
            "Loss after epoch 1058: 11876.0\n",
            "Loss after epoch 1059: 11786.0\n",
            "Loss after epoch 1060: 11832.0\n",
            "Loss after epoch 1061: 11962.0\n",
            "Loss after epoch 1062: 11936.0\n",
            "Loss after epoch 1063: 12046.0\n",
            "Loss after epoch 1064: 12198.0\n",
            "Loss after epoch 1065: 12036.0\n",
            "Loss after epoch 1066: 11852.0\n",
            "Loss after epoch 1067: 11874.0\n",
            "Loss after epoch 1068: 11946.0\n",
            "Loss after epoch 1069: 12072.0\n",
            "Loss after epoch 1070: 11402.0\n",
            "Loss after epoch 1071: 11962.0\n",
            "Loss after epoch 1072: 12050.0\n",
            "Loss after epoch 1073: 11948.0\n",
            "Loss after epoch 1074: 11786.0\n",
            "Loss after epoch 1075: 12166.0\n",
            "Loss after epoch 1076: 11904.0\n",
            "Loss after epoch 1077: 11940.0\n",
            "Loss after epoch 1078: 11976.0\n",
            "Loss after epoch 1079: 12136.0\n",
            "Loss after epoch 1080: 11828.0\n",
            "Loss after epoch 1081: 11980.0\n",
            "Loss after epoch 1082: 11936.0\n",
            "Loss after epoch 1083: 11940.0\n",
            "Loss after epoch 1084: 11688.0\n",
            "Loss after epoch 1085: 11616.0\n",
            "Loss after epoch 1086: 11958.0\n",
            "Loss after epoch 1087: 11444.0\n",
            "Loss after epoch 1088: 11538.0\n",
            "Loss after epoch 1089: 12166.0\n",
            "Loss after epoch 1090: 11742.0\n",
            "Loss after epoch 1091: 11616.0\n",
            "Loss after epoch 1092: 11816.0\n",
            "Loss after epoch 1093: 11896.0\n",
            "Loss after epoch 1094: 12122.0\n",
            "Loss after epoch 1095: 11636.0\n",
            "Loss after epoch 1096: 12080.0\n",
            "Loss after epoch 1097: 11632.0\n",
            "Loss after epoch 1098: 11852.0\n",
            "Loss after epoch 1099: 11806.0\n",
            "Loss after epoch 1100: 12062.0\n",
            "Loss after epoch 1101: 11814.0\n",
            "Loss after epoch 1102: 12112.0\n",
            "Loss after epoch 1103: 11808.0\n",
            "Loss after epoch 1104: 11586.0\n",
            "Loss after epoch 1105: 11916.0\n",
            "Loss after epoch 1106: 12234.0\n",
            "Loss after epoch 1107: 12026.0\n",
            "Loss after epoch 1108: 11340.0\n",
            "Loss after epoch 1109: 11566.0\n",
            "Loss after epoch 1110: 11528.0\n",
            "Loss after epoch 1111: 11734.0\n",
            "Loss after epoch 1112: 11998.0\n",
            "Loss after epoch 1113: 11580.0\n",
            "Loss after epoch 1114: 11726.0\n",
            "Loss after epoch 1115: 11620.0\n",
            "Loss after epoch 1116: 12154.0\n",
            "Loss after epoch 1117: 11614.0\n",
            "Loss after epoch 1118: 11786.0\n",
            "Loss after epoch 1119: 11722.0\n",
            "Loss after epoch 1120: 11830.0\n",
            "Loss after epoch 1121: 11882.0\n",
            "Loss after epoch 1122: 11574.0\n",
            "Loss after epoch 1123: 11518.0\n",
            "Loss after epoch 1124: 12194.0\n",
            "Loss after epoch 1125: 11988.0\n",
            "Loss after epoch 1126: 11880.0\n",
            "Loss after epoch 1127: 11372.0\n",
            "Loss after epoch 1128: 11906.0\n",
            "Loss after epoch 1129: 11420.0\n",
            "Loss after epoch 1130: 12080.0\n",
            "Loss after epoch 1131: 12202.0\n",
            "Loss after epoch 1132: 11738.0\n",
            "Loss after epoch 1133: 11518.0\n",
            "Loss after epoch 1134: 12016.0\n",
            "Loss after epoch 1135: 11788.0\n",
            "Loss after epoch 1136: 11548.0\n",
            "Loss after epoch 1137: 12030.0\n",
            "Loss after epoch 1138: 11878.0\n",
            "Loss after epoch 1139: 11838.0\n",
            "Loss after epoch 1140: 11986.0\n",
            "Loss after epoch 1141: 11842.0\n",
            "Loss after epoch 1142: 11620.0\n",
            "Loss after epoch 1143: 11536.0\n",
            "Loss after epoch 1144: 11570.0\n",
            "Loss after epoch 1145: 11806.0\n",
            "Loss after epoch 1146: 11922.0\n",
            "Loss after epoch 1147: 11948.0\n",
            "Loss after epoch 1148: 11772.0\n",
            "Loss after epoch 1149: 11776.0\n",
            "Loss after epoch 1150: 11734.0\n",
            "Loss after epoch 1151: 11406.0\n",
            "Loss after epoch 1152: 11474.0\n",
            "Loss after epoch 1153: 11780.0\n",
            "Loss after epoch 1154: 11468.0\n",
            "Loss after epoch 1155: 11352.0\n",
            "Loss after epoch 1156: 11776.0\n",
            "Loss after epoch 1157: 11512.0\n",
            "Loss after epoch 1158: 11610.0\n",
            "Loss after epoch 1159: 11416.0\n",
            "Loss after epoch 1160: 11450.0\n",
            "Loss after epoch 1161: 11370.0\n",
            "Loss after epoch 1162: 11288.0\n",
            "Loss after epoch 1163: 11500.0\n",
            "Loss after epoch 1164: 11768.0\n",
            "Loss after epoch 1165: 11830.0\n",
            "Loss after epoch 1166: 12042.0\n",
            "Loss after epoch 1167: 11286.0\n",
            "Loss after epoch 1168: 11512.0\n",
            "Loss after epoch 1169: 11614.0\n",
            "Loss after epoch 1170: 11750.0\n",
            "Loss after epoch 1171: 11748.0\n",
            "Loss after epoch 1172: 11332.0\n",
            "Loss after epoch 1173: 11324.0\n",
            "Loss after epoch 1174: 11752.0\n",
            "Loss after epoch 1175: 11796.0\n",
            "Loss after epoch 1176: 11670.0\n",
            "Loss after epoch 1177: 11742.0\n",
            "Loss after epoch 1178: 11706.0\n",
            "Loss after epoch 1179: 11444.0\n",
            "Loss after epoch 1180: 11818.0\n",
            "Loss after epoch 1181: 11696.0\n",
            "Loss after epoch 1182: 11488.0\n",
            "Loss after epoch 1183: 11584.0\n",
            "Loss after epoch 1184: 11464.0\n",
            "Loss after epoch 1185: 11360.0\n",
            "Loss after epoch 1186: 11774.0\n",
            "Loss after epoch 1187: 11780.0\n",
            "Loss after epoch 1188: 11396.0\n",
            "Loss after epoch 1189: 11670.0\n",
            "Loss after epoch 1190: 11430.0\n",
            "Loss after epoch 1191: 11510.0\n",
            "Loss after epoch 1192: 11768.0\n",
            "Loss after epoch 1193: 11896.0\n",
            "Loss after epoch 1194: 11390.0\n",
            "Loss after epoch 1195: 11434.0\n",
            "Loss after epoch 1196: 11946.0\n",
            "Loss after epoch 1197: 11778.0\n",
            "Loss after epoch 1198: 11702.0\n",
            "Loss after epoch 1199: 11330.0\n",
            "Loss after epoch 1200: 11546.0\n",
            "Loss after epoch 1201: 11448.0\n",
            "Loss after epoch 1202: 11554.0\n",
            "Loss after epoch 1203: 11658.0\n",
            "Loss after epoch 1204: 11528.0\n",
            "Loss after epoch 1205: 11458.0\n",
            "Loss after epoch 1206: 11424.0\n",
            "Loss after epoch 1207: 11562.0\n",
            "Loss after epoch 1208: 11572.0\n",
            "Loss after epoch 1209: 11430.0\n",
            "Loss after epoch 1210: 11484.0\n",
            "Loss after epoch 1211: 11396.0\n",
            "Loss after epoch 1212: 11604.0\n",
            "Loss after epoch 1213: 11758.0\n",
            "Loss after epoch 1214: 11448.0\n",
            "Loss after epoch 1215: 11526.0\n",
            "Loss after epoch 1216: 11690.0\n",
            "Loss after epoch 1217: 11834.0\n",
            "Loss after epoch 1218: 11660.0\n",
            "Loss after epoch 1219: 11514.0\n",
            "Loss after epoch 1220: 11356.0\n",
            "Loss after epoch 1221: 11100.0\n",
            "Loss after epoch 1222: 11228.0\n",
            "Loss after epoch 1223: 11184.0\n",
            "Loss after epoch 1224: 11330.0\n",
            "Loss after epoch 1225: 11608.0\n",
            "Loss after epoch 1226: 11252.0\n",
            "Loss after epoch 1227: 11572.0\n",
            "Loss after epoch 1228: 11470.0\n",
            "Loss after epoch 1229: 11324.0\n",
            "Loss after epoch 1230: 11428.0\n",
            "Loss after epoch 1231: 11298.0\n",
            "Loss after epoch 1232: 11354.0\n",
            "Loss after epoch 1233: 11370.0\n",
            "Loss after epoch 1234: 11210.0\n",
            "Loss after epoch 1235: 11504.0\n",
            "Loss after epoch 1236: 11404.0\n",
            "Loss after epoch 1237: 11340.0\n",
            "Loss after epoch 1238: 11346.0\n",
            "Loss after epoch 1239: 11528.0\n",
            "Loss after epoch 1240: 11476.0\n",
            "Loss after epoch 1241: 11080.0\n",
            "Loss after epoch 1242: 11334.0\n",
            "Loss after epoch 1243: 11324.0\n",
            "Loss after epoch 1244: 11370.0\n",
            "Loss after epoch 1245: 11490.0\n",
            "Loss after epoch 1246: 11622.0\n",
            "Loss after epoch 1247: 11184.0\n",
            "Loss after epoch 1248: 11474.0\n",
            "Loss after epoch 1249: 11308.0\n",
            "Loss after epoch 1250: 11272.0\n",
            "Loss after epoch 1251: 11152.0\n",
            "Loss after epoch 1252: 11370.0\n",
            "Loss after epoch 1253: 11526.0\n",
            "Loss after epoch 1254: 11806.0\n",
            "Loss after epoch 1255: 11294.0\n",
            "Loss after epoch 1256: 11286.0\n",
            "Loss after epoch 1257: 11376.0\n",
            "Loss after epoch 1258: 11292.0\n",
            "Loss after epoch 1259: 11178.0\n",
            "Loss after epoch 1260: 11136.0\n",
            "Loss after epoch 1261: 11412.0\n",
            "Loss after epoch 1262: 11272.0\n",
            "Loss after epoch 1263: 11282.0\n",
            "Loss after epoch 1264: 11552.0\n",
            "Loss after epoch 1265: 11318.0\n",
            "Loss after epoch 1266: 11028.0\n",
            "Loss after epoch 1267: 11366.0\n",
            "Loss after epoch 1268: 11420.0\n",
            "Loss after epoch 1269: 11196.0\n",
            "Loss after epoch 1270: 11026.0\n",
            "Loss after epoch 1271: 11354.0\n",
            "Loss after epoch 1272: 11108.0\n",
            "Loss after epoch 1273: 11082.0\n",
            "Loss after epoch 1274: 10970.0\n",
            "Loss after epoch 1275: 11384.0\n",
            "Loss after epoch 1276: 11414.0\n",
            "Loss after epoch 1277: 11242.0\n",
            "Loss after epoch 1278: 11274.0\n",
            "Loss after epoch 1279: 11260.0\n",
            "Loss after epoch 1280: 11262.0\n",
            "Loss after epoch 1281: 11424.0\n",
            "Loss after epoch 1282: 11070.0\n",
            "Loss after epoch 1283: 11602.0\n",
            "Loss after epoch 1284: 11144.0\n",
            "Loss after epoch 1285: 11328.0\n",
            "Loss after epoch 1286: 11352.0\n",
            "Loss after epoch 1287: 11192.0\n",
            "Loss after epoch 1288: 11036.0\n",
            "Loss after epoch 1289: 11436.0\n",
            "Loss after epoch 1290: 11122.0\n",
            "Loss after epoch 1291: 11436.0\n",
            "Loss after epoch 1292: 10930.0\n",
            "Loss after epoch 1293: 11098.0\n",
            "Loss after epoch 1294: 11420.0\n",
            "Loss after epoch 1295: 11112.0\n",
            "Loss after epoch 1296: 11202.0\n",
            "Loss after epoch 1297: 11174.0\n",
            "Loss after epoch 1298: 11216.0\n",
            "Loss after epoch 1299: 11028.0\n",
            "Loss after epoch 1300: 10870.0\n",
            "Loss after epoch 1301: 11364.0\n",
            "Loss after epoch 1302: 11062.0\n",
            "Loss after epoch 1303: 11446.0\n",
            "Loss after epoch 1304: 10922.0\n",
            "Loss after epoch 1305: 11408.0\n",
            "Loss after epoch 1306: 11102.0\n",
            "Loss after epoch 1307: 11252.0\n",
            "Loss after epoch 1308: 11194.0\n",
            "Loss after epoch 1309: 11258.0\n",
            "Loss after epoch 1310: 11406.0\n",
            "Loss after epoch 1311: 11174.0\n",
            "Loss after epoch 1312: 11184.0\n",
            "Loss after epoch 1313: 11180.0\n",
            "Loss after epoch 1314: 11204.0\n",
            "Loss after epoch 1315: 11138.0\n",
            "Loss after epoch 1316: 11366.0\n",
            "Loss after epoch 1317: 11054.0\n",
            "Loss after epoch 1318: 11186.0\n",
            "Loss after epoch 1319: 11330.0\n",
            "Loss after epoch 1320: 11064.0\n",
            "Loss after epoch 1321: 11064.0\n",
            "Loss after epoch 1322: 11324.0\n",
            "Loss after epoch 1323: 11066.0\n",
            "Loss after epoch 1324: 11314.0\n",
            "Loss after epoch 1325: 11024.0\n",
            "Loss after epoch 1326: 11206.0\n",
            "Loss after epoch 1327: 11050.0\n",
            "Loss after epoch 1328: 10896.0\n",
            "Loss after epoch 1329: 10900.0\n",
            "Loss after epoch 1330: 11132.0\n",
            "Loss after epoch 1331: 11206.0\n",
            "Loss after epoch 1332: 11120.0\n",
            "Loss after epoch 1333: 10944.0\n",
            "Loss after epoch 1334: 10734.0\n",
            "Loss after epoch 1335: 11306.0\n",
            "Loss after epoch 1336: 11088.0\n",
            "Loss after epoch 1337: 11072.0\n",
            "Loss after epoch 1338: 11186.0\n",
            "Loss after epoch 1339: 11198.0\n",
            "Loss after epoch 1340: 11146.0\n",
            "Loss after epoch 1341: 10870.0\n",
            "Loss after epoch 1342: 11150.0\n",
            "Loss after epoch 1343: 10918.0\n",
            "Loss after epoch 1344: 10940.0\n",
            "Loss after epoch 1345: 10972.0\n",
            "Loss after epoch 1346: 10950.0\n",
            "Loss after epoch 1347: 11018.0\n",
            "Loss after epoch 1348: 11188.0\n",
            "Loss after epoch 1349: 10828.0\n",
            "Loss after epoch 1350: 11322.0\n",
            "Loss after epoch 1351: 11266.0\n",
            "Loss after epoch 1352: 11062.0\n",
            "Loss after epoch 1353: 11084.0\n",
            "Loss after epoch 1354: 10842.0\n",
            "Loss after epoch 1355: 11276.0\n",
            "Loss after epoch 1356: 11260.0\n",
            "Loss after epoch 1357: 11022.0\n",
            "Loss after epoch 1358: 11050.0\n",
            "Loss after epoch 1359: 10920.0\n",
            "Loss after epoch 1360: 11028.0\n",
            "Loss after epoch 1361: 10824.0\n",
            "Loss after epoch 1362: 10778.0\n",
            "Loss after epoch 1363: 10846.0\n",
            "Loss after epoch 1364: 10756.0\n",
            "Loss after epoch 1365: 10894.0\n",
            "Loss after epoch 1366: 11044.0\n",
            "Loss after epoch 1367: 10880.0\n",
            "Loss after epoch 1368: 10882.0\n",
            "Loss after epoch 1369: 11050.0\n",
            "Loss after epoch 1370: 10866.0\n",
            "Loss after epoch 1371: 11004.0\n",
            "Loss after epoch 1372: 11276.0\n",
            "Loss after epoch 1373: 11060.0\n",
            "Loss after epoch 1374: 10760.0\n",
            "Loss after epoch 1375: 10876.0\n",
            "Loss after epoch 1376: 10638.0\n",
            "Loss after epoch 1377: 11128.0\n",
            "Loss after epoch 1378: 10788.0\n",
            "Loss after epoch 1379: 10880.0\n",
            "Loss after epoch 1380: 10960.0\n",
            "Loss after epoch 1381: 10962.0\n",
            "Loss after epoch 1382: 10818.0\n",
            "Loss after epoch 1383: 11092.0\n",
            "Loss after epoch 1384: 10698.0\n",
            "Loss after epoch 1385: 10854.0\n",
            "Loss after epoch 1386: 11172.0\n",
            "Loss after epoch 1387: 10908.0\n",
            "Loss after epoch 1388: 10708.0\n",
            "Loss after epoch 1389: 10628.0\n",
            "Loss after epoch 1390: 10922.0\n",
            "Loss after epoch 1391: 10844.0\n",
            "Loss after epoch 1392: 11084.0\n",
            "Loss after epoch 1393: 10916.0\n",
            "Loss after epoch 1394: 10790.0\n",
            "Loss after epoch 1395: 11048.0\n",
            "Loss after epoch 1396: 10886.0\n",
            "Loss after epoch 1397: 10884.0\n",
            "Loss after epoch 1398: 10930.0\n",
            "Loss after epoch 1399: 10994.0\n",
            "Loss after epoch 1400: 10716.0\n",
            "Loss after epoch 1401: 10968.0\n",
            "Loss after epoch 1402: 11264.0\n",
            "Loss after epoch 1403: 11026.0\n",
            "Loss after epoch 1404: 10628.0\n",
            "Loss after epoch 1405: 10556.0\n",
            "Loss after epoch 1406: 10706.0\n",
            "Loss after epoch 1407: 10826.0\n",
            "Loss after epoch 1408: 10606.0\n",
            "Loss after epoch 1409: 10772.0\n",
            "Loss after epoch 1410: 10738.0\n",
            "Loss after epoch 1411: 10800.0\n",
            "Loss after epoch 1412: 10936.0\n",
            "Loss after epoch 1413: 10480.0\n",
            "Loss after epoch 1414: 10634.0\n",
            "Loss after epoch 1415: 10876.0\n",
            "Loss after epoch 1416: 10576.0\n",
            "Loss after epoch 1417: 10680.0\n",
            "Loss after epoch 1418: 10684.0\n",
            "Loss after epoch 1419: 10666.0\n",
            "Loss after epoch 1420: 10858.0\n",
            "Loss after epoch 1421: 10852.0\n",
            "Loss after epoch 1422: 10672.0\n",
            "Loss after epoch 1423: 10850.0\n",
            "Loss after epoch 1424: 10618.0\n",
            "Loss after epoch 1425: 10770.0\n",
            "Loss after epoch 1426: 10708.0\n",
            "Loss after epoch 1427: 10826.0\n",
            "Loss after epoch 1428: 11072.0\n",
            "Loss after epoch 1429: 10836.0\n",
            "Loss after epoch 1430: 10768.0\n",
            "Loss after epoch 1431: 10588.0\n",
            "Loss after epoch 1432: 10830.0\n",
            "Loss after epoch 1433: 10448.0\n",
            "Loss after epoch 1434: 10662.0\n",
            "Loss after epoch 1435: 10756.0\n",
            "Loss after epoch 1436: 10768.0\n",
            "Loss after epoch 1437: 10614.0\n",
            "Loss after epoch 1438: 10606.0\n",
            "Loss after epoch 1439: 10344.0\n",
            "Loss after epoch 1440: 10924.0\n",
            "Loss after epoch 1441: 10530.0\n",
            "Loss after epoch 1442: 10652.0\n",
            "Loss after epoch 1443: 10974.0\n",
            "Loss after epoch 1444: 10710.0\n",
            "Loss after epoch 1445: 10628.0\n",
            "Loss after epoch 1446: 10734.0\n",
            "Loss after epoch 1447: 10726.0\n",
            "Loss after epoch 1448: 10600.0\n",
            "Loss after epoch 1449: 10432.0\n",
            "Loss after epoch 1450: 10576.0\n",
            "Loss after epoch 1451: 10476.0\n",
            "Loss after epoch 1452: 10800.0\n",
            "Loss after epoch 1453: 10720.0\n",
            "Loss after epoch 1454: 10726.0\n",
            "Loss after epoch 1455: 10642.0\n",
            "Loss after epoch 1456: 10700.0\n",
            "Loss after epoch 1457: 10436.0\n",
            "Loss after epoch 1458: 10308.0\n",
            "Loss after epoch 1459: 10616.0\n",
            "Loss after epoch 1460: 10072.0\n",
            "Loss after epoch 1461: 10454.0\n",
            "Loss after epoch 1462: 10622.0\n",
            "Loss after epoch 1463: 10732.0\n",
            "Loss after epoch 1464: 10604.0\n",
            "Loss after epoch 1465: 10852.0\n",
            "Loss after epoch 1466: 10394.0\n",
            "Loss after epoch 1467: 10350.0\n",
            "Loss after epoch 1468: 10932.0\n",
            "Loss after epoch 1469: 10576.0\n",
            "Loss after epoch 1470: 10452.0\n",
            "Loss after epoch 1471: 10636.0\n",
            "Loss after epoch 1472: 10088.0\n",
            "Loss after epoch 1473: 10458.0\n",
            "Loss after epoch 1474: 10470.0\n",
            "Loss after epoch 1475: 10442.0\n",
            "Loss after epoch 1476: 10392.0\n",
            "Loss after epoch 1477: 10226.0\n",
            "Loss after epoch 1478: 10754.0\n",
            "Loss after epoch 1479: 10554.0\n",
            "Loss after epoch 1480: 10674.0\n",
            "Loss after epoch 1481: 10430.0\n",
            "Loss after epoch 1482: 10586.0\n",
            "Loss after epoch 1483: 10468.0\n",
            "Loss after epoch 1484: 10620.0\n",
            "Loss after epoch 1485: 10520.0\n",
            "Loss after epoch 1486: 10252.0\n",
            "Loss after epoch 1487: 10534.0\n",
            "Loss after epoch 1488: 10434.0\n",
            "Loss after epoch 1489: 10188.0\n",
            "Loss after epoch 1490: 10214.0\n",
            "Loss after epoch 1491: 10368.0\n",
            "Loss after epoch 1492: 10364.0\n",
            "Loss after epoch 1493: 10184.0\n",
            "Loss after epoch 1494: 10288.0\n",
            "Loss after epoch 1495: 10362.0\n",
            "Loss after epoch 1496: 10046.0\n",
            "Loss after epoch 1497: 10396.0\n",
            "Loss after epoch 1498: 10572.0\n",
            "Loss after epoch 1499: 10378.0\n",
            "Loss after epoch 1500: 10560.0\n",
            "Loss after epoch 1501: 10426.0\n",
            "Loss after epoch 1502: 10588.0\n",
            "Loss after epoch 1503: 10430.0\n",
            "Loss after epoch 1504: 10612.0\n",
            "Loss after epoch 1505: 10048.0\n",
            "Loss after epoch 1506: 10390.0\n",
            "Loss after epoch 1507: 10216.0\n",
            "Loss after epoch 1508: 10208.0\n",
            "Loss after epoch 1509: 10610.0\n",
            "Loss after epoch 1510: 10310.0\n",
            "Loss after epoch 1511: 10206.0\n",
            "Loss after epoch 1512: 10350.0\n",
            "Loss after epoch 1513: 10666.0\n",
            "Loss after epoch 1514: 10098.0\n",
            "Loss after epoch 1515: 10280.0\n",
            "Loss after epoch 1516: 10180.0\n",
            "Loss after epoch 1517: 10100.0\n",
            "Loss after epoch 1518: 10682.0\n",
            "Loss after epoch 1519: 10558.0\n",
            "Loss after epoch 1520: 10406.0\n",
            "Loss after epoch 1521: 10382.0\n",
            "Loss after epoch 1522: 10228.0\n",
            "Loss after epoch 1523: 10270.0\n",
            "Loss after epoch 1524: 10396.0\n",
            "Loss after epoch 1525: 10142.0\n",
            "Loss after epoch 1526: 10360.0\n",
            "Loss after epoch 1527: 10208.0\n",
            "Loss after epoch 1528: 10436.0\n",
            "Loss after epoch 1529: 10472.0\n",
            "Loss after epoch 1530: 10216.0\n",
            "Loss after epoch 1531: 10630.0\n",
            "Loss after epoch 1532: 10092.0\n",
            "Loss after epoch 1533: 10146.0\n",
            "Loss after epoch 1534: 10310.0\n",
            "Loss after epoch 1535: 10488.0\n",
            "Loss after epoch 1536: 10140.0\n",
            "Loss after epoch 1537: 10246.0\n",
            "Loss after epoch 1538: 10294.0\n",
            "Loss after epoch 1539: 9962.0\n",
            "Loss after epoch 1540: 10088.0\n",
            "Loss after epoch 1541: 10162.0\n",
            "Loss after epoch 1542: 10112.0\n",
            "Loss after epoch 1543: 10380.0\n",
            "Loss after epoch 1544: 10334.0\n",
            "Loss after epoch 1545: 10006.0\n",
            "Loss after epoch 1546: 10304.0\n",
            "Loss after epoch 1547: 10202.0\n",
            "Loss after epoch 1548: 10176.0\n",
            "Loss after epoch 1549: 10226.0\n",
            "Loss after epoch 1550: 10208.0\n",
            "Loss after epoch 1551: 10272.0\n",
            "Loss after epoch 1552: 10196.0\n",
            "Loss after epoch 1553: 10202.0\n",
            "Loss after epoch 1554: 10424.0\n",
            "Loss after epoch 1555: 10250.0\n",
            "Loss after epoch 1556: 10404.0\n",
            "Loss after epoch 1557: 10256.0\n",
            "Loss after epoch 1558: 9972.0\n",
            "Loss after epoch 1559: 10032.0\n",
            "Loss after epoch 1560: 10334.0\n",
            "Loss after epoch 1561: 10216.0\n",
            "Loss after epoch 1562: 9970.0\n",
            "Loss after epoch 1563: 10278.0\n",
            "Loss after epoch 1564: 9654.0\n",
            "Loss after epoch 1565: 10592.0\n",
            "Loss after epoch 1566: 9996.0\n",
            "Loss after epoch 1567: 10028.0\n",
            "Loss after epoch 1568: 10168.0\n",
            "Loss after epoch 1569: 10042.0\n",
            "Loss after epoch 1570: 9796.0\n",
            "Loss after epoch 1571: 10256.0\n",
            "Loss after epoch 1572: 10268.0\n",
            "Loss after epoch 1573: 10226.0\n",
            "Loss after epoch 1574: 10018.0\n",
            "Loss after epoch 1575: 9894.0\n",
            "Loss after epoch 1576: 9846.0\n",
            "Loss after epoch 1577: 9958.0\n",
            "Loss after epoch 1578: 10126.0\n",
            "Loss after epoch 1579: 9908.0\n",
            "Loss after epoch 1580: 10142.0\n",
            "Loss after epoch 1581: 9896.0\n",
            "Loss after epoch 1582: 10112.0\n",
            "Loss after epoch 1583: 10096.0\n",
            "Loss after epoch 1584: 10140.0\n",
            "Loss after epoch 1585: 9864.0\n",
            "Loss after epoch 1586: 10094.0\n",
            "Loss after epoch 1587: 10004.0\n",
            "Loss after epoch 1588: 9886.0\n",
            "Loss after epoch 1589: 9856.0\n",
            "Loss after epoch 1590: 10170.0\n",
            "Loss after epoch 1591: 10088.0\n",
            "Loss after epoch 1592: 9918.0\n",
            "Loss after epoch 1593: 9878.0\n",
            "Loss after epoch 1594: 9910.0\n",
            "Loss after epoch 1595: 9864.0\n",
            "Loss after epoch 1596: 10070.0\n",
            "Loss after epoch 1597: 9964.0\n",
            "Loss after epoch 1598: 10174.0\n",
            "Loss after epoch 1599: 9848.0\n",
            "Loss after epoch 1600: 10060.0\n",
            "Loss after epoch 1601: 9970.0\n",
            "Loss after epoch 1602: 9782.0\n",
            "Loss after epoch 1603: 9812.0\n",
            "Loss after epoch 1604: 9954.0\n",
            "Loss after epoch 1605: 9788.0\n",
            "Loss after epoch 1606: 9868.0\n",
            "Loss after epoch 1607: 9858.0\n",
            "Loss after epoch 1608: 10106.0\n",
            "Loss after epoch 1609: 9772.0\n",
            "Loss after epoch 1610: 10004.0\n",
            "Loss after epoch 1611: 9872.0\n",
            "Loss after epoch 1612: 9758.0\n",
            "Loss after epoch 1613: 9840.0\n",
            "Loss after epoch 1614: 9932.0\n",
            "Loss after epoch 1615: 9774.0\n",
            "Loss after epoch 1616: 10144.0\n",
            "Loss after epoch 1617: 9870.0\n",
            "Loss after epoch 1618: 9948.0\n",
            "Loss after epoch 1619: 9968.0\n",
            "Loss after epoch 1620: 9796.0\n",
            "Loss after epoch 1621: 9690.0\n",
            "Loss after epoch 1622: 9714.0\n",
            "Loss after epoch 1623: 10126.0\n",
            "Loss after epoch 1624: 10030.0\n",
            "Loss after epoch 1625: 9804.0\n",
            "Loss after epoch 1626: 9924.0\n",
            "Loss after epoch 1627: 9634.0\n",
            "Loss after epoch 1628: 10002.0\n",
            "Loss after epoch 1629: 9898.0\n",
            "Loss after epoch 1630: 10068.0\n",
            "Loss after epoch 1631: 9680.0\n",
            "Loss after epoch 1632: 9864.0\n",
            "Loss after epoch 1633: 9826.0\n",
            "Loss after epoch 1634: 9694.0\n",
            "Loss after epoch 1635: 9906.0\n",
            "Loss after epoch 1636: 10032.0\n",
            "Loss after epoch 1637: 9692.0\n",
            "Loss after epoch 1638: 10044.0\n",
            "Loss after epoch 1639: 9622.0\n",
            "Loss after epoch 1640: 9794.0\n",
            "Loss after epoch 1641: 10036.0\n",
            "Loss after epoch 1642: 9674.0\n",
            "Loss after epoch 1643: 9976.0\n",
            "Loss after epoch 1644: 9942.0\n",
            "Loss after epoch 1645: 9734.0\n",
            "Loss after epoch 1646: 9990.0\n",
            "Loss after epoch 1647: 9882.0\n",
            "Loss after epoch 1648: 9566.0\n",
            "Loss after epoch 1649: 9788.0\n",
            "Loss after epoch 1650: 9872.0\n",
            "Loss after epoch 1651: 9592.0\n",
            "Loss after epoch 1652: 9814.0\n",
            "Loss after epoch 1653: 9760.0\n",
            "Loss after epoch 1654: 9818.0\n",
            "Loss after epoch 1655: 9996.0\n",
            "Loss after epoch 1656: 9856.0\n",
            "Loss after epoch 1657: 9868.0\n",
            "Loss after epoch 1658: 9588.0\n",
            "Loss after epoch 1659: 9598.0\n",
            "Loss after epoch 1660: 9716.0\n",
            "Loss after epoch 1661: 9724.0\n",
            "Loss after epoch 1662: 9928.0\n",
            "Loss after epoch 1663: 9884.0\n",
            "Loss after epoch 1664: 9728.0\n",
            "Loss after epoch 1665: 9490.0\n",
            "Loss after epoch 1666: 10008.0\n",
            "Loss after epoch 1667: 9630.0\n",
            "Loss after epoch 1668: 9800.0\n",
            "Loss after epoch 1669: 9916.0\n",
            "Loss after epoch 1670: 9676.0\n",
            "Loss after epoch 1671: 9914.0\n",
            "Loss after epoch 1672: 9624.0\n",
            "Loss after epoch 1673: 9514.0\n",
            "Loss after epoch 1674: 9902.0\n",
            "Loss after epoch 1675: 9868.0\n",
            "Loss after epoch 1676: 9670.0\n",
            "Loss after epoch 1677: 9766.0\n",
            "Loss after epoch 1678: 9678.0\n",
            "Loss after epoch 1679: 9704.0\n",
            "Loss after epoch 1680: 9354.0\n",
            "Loss after epoch 1681: 9822.0\n",
            "Loss after epoch 1682: 9526.0\n",
            "Loss after epoch 1683: 9582.0\n",
            "Loss after epoch 1684: 9640.0\n",
            "Loss after epoch 1685: 9438.0\n",
            "Loss after epoch 1686: 9546.0\n",
            "Loss after epoch 1687: 9468.0\n",
            "Loss after epoch 1688: 9574.0\n",
            "Loss after epoch 1689: 9544.0\n",
            "Loss after epoch 1690: 9742.0\n",
            "Loss after epoch 1691: 9478.0\n",
            "Loss after epoch 1692: 9548.0\n",
            "Loss after epoch 1693: 9654.0\n",
            "Loss after epoch 1694: 9472.0\n",
            "Loss after epoch 1695: 9668.0\n",
            "Loss after epoch 1696: 9464.0\n",
            "Loss after epoch 1697: 9574.0\n",
            "Loss after epoch 1698: 9688.0\n",
            "Loss after epoch 1699: 9386.0\n",
            "Loss after epoch 1700: 9522.0\n",
            "Loss after epoch 1701: 9574.0\n",
            "Loss after epoch 1702: 9376.0\n",
            "Loss after epoch 1703: 9356.0\n",
            "Loss after epoch 1704: 9604.0\n",
            "Loss after epoch 1705: 9342.0\n",
            "Loss after epoch 1706: 9330.0\n",
            "Loss after epoch 1707: 9374.0\n",
            "Loss after epoch 1708: 9488.0\n",
            "Loss after epoch 1709: 9666.0\n",
            "Loss after epoch 1710: 9548.0\n",
            "Loss after epoch 1711: 9416.0\n",
            "Loss after epoch 1712: 9350.0\n",
            "Loss after epoch 1713: 9584.0\n",
            "Loss after epoch 1714: 9786.0\n",
            "Loss after epoch 1715: 9546.0\n",
            "Loss after epoch 1716: 9422.0\n",
            "Loss after epoch 1717: 9344.0\n",
            "Loss after epoch 1718: 9486.0\n",
            "Loss after epoch 1719: 9408.0\n",
            "Loss after epoch 1720: 9782.0\n",
            "Loss after epoch 1721: 9514.0\n",
            "Loss after epoch 1722: 9772.0\n",
            "Loss after epoch 1723: 9322.0\n",
            "Loss after epoch 1724: 9016.0\n",
            "Loss after epoch 1725: 9448.0\n",
            "Loss after epoch 1726: 9328.0\n",
            "Loss after epoch 1727: 9394.0\n",
            "Loss after epoch 1728: 9734.0\n",
            "Loss after epoch 1729: 9346.0\n",
            "Loss after epoch 1730: 9684.0\n",
            "Loss after epoch 1731: 9278.0\n",
            "Loss after epoch 1732: 9370.0\n",
            "Loss after epoch 1733: 9340.0\n",
            "Loss after epoch 1734: 9476.0\n",
            "Loss after epoch 1735: 9502.0\n",
            "Loss after epoch 1736: 9452.0\n",
            "Loss after epoch 1737: 9386.0\n",
            "Loss after epoch 1738: 9380.0\n",
            "Loss after epoch 1739: 9568.0\n",
            "Loss after epoch 1740: 9256.0\n",
            "Loss after epoch 1741: 9350.0\n",
            "Loss after epoch 1742: 9358.0\n",
            "Loss after epoch 1743: 9380.0\n",
            "Loss after epoch 1744: 9306.0\n",
            "Loss after epoch 1745: 9488.0\n",
            "Loss after epoch 1746: 9150.0\n",
            "Loss after epoch 1747: 9270.0\n",
            "Loss after epoch 1748: 9302.0\n",
            "Loss after epoch 1749: 9304.0\n",
            "Loss after epoch 1750: 9272.0\n",
            "Loss after epoch 1751: 9278.0\n",
            "Loss after epoch 1752: 9264.0\n",
            "Loss after epoch 1753: 9470.0\n",
            "Loss after epoch 1754: 9028.0\n",
            "Loss after epoch 1755: 9312.0\n",
            "Loss after epoch 1756: 9318.0\n",
            "Loss after epoch 1757: 9494.0\n",
            "Loss after epoch 1758: 9084.0\n",
            "Loss after epoch 1759: 9196.0\n",
            "Loss after epoch 1760: 9528.0\n",
            "Loss after epoch 1761: 9504.0\n",
            "Loss after epoch 1762: 9352.0\n",
            "Loss after epoch 1763: 9378.0\n",
            "Loss after epoch 1764: 9166.0\n",
            "Loss after epoch 1765: 9190.0\n",
            "Loss after epoch 1766: 9050.0\n",
            "Loss after epoch 1767: 9116.0\n",
            "Loss after epoch 1768: 9312.0\n",
            "Loss after epoch 1769: 9222.0\n",
            "Loss after epoch 1770: 9396.0\n",
            "Loss after epoch 1771: 9214.0\n",
            "Loss after epoch 1772: 9278.0\n",
            "Loss after epoch 1773: 9056.0\n",
            "Loss after epoch 1774: 9264.0\n",
            "Loss after epoch 1775: 9262.0\n",
            "Loss after epoch 1776: 9228.0\n",
            "Loss after epoch 1777: 9206.0\n",
            "Loss after epoch 1778: 9134.0\n",
            "Loss after epoch 1779: 9420.0\n",
            "Loss after epoch 1780: 9028.0\n",
            "Loss after epoch 1781: 9108.0\n",
            "Loss after epoch 1782: 9334.0\n",
            "Loss after epoch 1783: 8846.0\n",
            "Loss after epoch 1784: 9100.0\n",
            "Loss after epoch 1785: 8990.0\n",
            "Loss after epoch 1786: 9216.0\n",
            "Loss after epoch 1787: 9490.0\n",
            "Loss after epoch 1788: 9468.0\n",
            "Loss after epoch 1789: 9098.0\n",
            "Loss after epoch 1790: 9552.0\n",
            "Loss after epoch 1791: 9172.0\n",
            "Loss after epoch 1792: 9084.0\n",
            "Loss after epoch 1793: 9270.0\n",
            "Loss after epoch 1794: 9304.0\n",
            "Loss after epoch 1795: 9148.0\n",
            "Loss after epoch 1796: 9116.0\n",
            "Loss after epoch 1797: 9326.0\n",
            "Loss after epoch 1798: 9380.0\n",
            "Loss after epoch 1799: 9032.0\n",
            "Loss after epoch 1800: 9302.0\n",
            "Loss after epoch 1801: 9210.0\n",
            "Loss after epoch 1802: 9326.0\n",
            "Loss after epoch 1803: 9250.0\n",
            "Loss after epoch 1804: 9128.0\n",
            "Loss after epoch 1805: 9030.0\n",
            "Loss after epoch 1806: 9300.0\n",
            "Loss after epoch 1807: 8966.0\n",
            "Loss after epoch 1808: 8796.0\n",
            "Loss after epoch 1809: 9264.0\n",
            "Loss after epoch 1810: 9368.0\n",
            "Loss after epoch 1811: 9134.0\n",
            "Loss after epoch 1812: 9120.0\n",
            "Loss after epoch 1813: 9052.0\n",
            "Loss after epoch 1814: 9160.0\n",
            "Loss after epoch 1815: 9012.0\n",
            "Loss after epoch 1816: 9362.0\n",
            "Loss after epoch 1817: 9160.0\n",
            "Loss after epoch 1818: 8898.0\n",
            "Loss after epoch 1819: 8924.0\n",
            "Loss after epoch 1820: 9242.0\n",
            "Loss after epoch 1821: 9172.0\n",
            "Loss after epoch 1822: 9120.0\n",
            "Loss after epoch 1823: 9262.0\n",
            "Loss after epoch 1824: 9114.0\n",
            "Loss after epoch 1825: 9234.0\n",
            "Loss after epoch 1826: 9236.0\n",
            "Loss after epoch 1827: 8776.0\n",
            "Loss after epoch 1828: 8644.0\n",
            "Loss after epoch 1829: 8990.0\n",
            "Loss after epoch 1830: 8818.0\n",
            "Loss after epoch 1831: 8948.0\n",
            "Loss after epoch 1832: 9086.0\n",
            "Loss after epoch 1833: 9074.0\n",
            "Loss after epoch 1834: 8934.0\n",
            "Loss after epoch 1835: 9046.0\n",
            "Loss after epoch 1836: 8988.0\n",
            "Loss after epoch 1837: 8998.0\n",
            "Loss after epoch 1838: 8768.0\n",
            "Loss after epoch 1839: 9062.0\n",
            "Loss after epoch 1840: 8974.0\n",
            "Loss after epoch 1841: 9100.0\n",
            "Loss after epoch 1842: 8790.0\n",
            "Loss after epoch 1843: 9002.0\n",
            "Loss after epoch 1844: 9194.0\n",
            "Loss after epoch 1845: 9162.0\n",
            "Loss after epoch 1846: 8896.0\n",
            "Loss after epoch 1847: 9094.0\n",
            "Loss after epoch 1848: 9024.0\n",
            "Loss after epoch 1849: 9054.0\n",
            "Loss after epoch 1850: 8920.0\n",
            "Loss after epoch 1851: 9060.0\n",
            "Loss after epoch 1852: 8810.0\n",
            "Loss after epoch 1853: 8946.0\n",
            "Loss after epoch 1854: 8808.0\n",
            "Loss after epoch 1855: 8922.0\n",
            "Loss after epoch 1856: 8884.0\n",
            "Loss after epoch 1857: 8854.0\n",
            "Loss after epoch 1858: 8952.0\n",
            "Loss after epoch 1859: 8758.0\n",
            "Loss after epoch 1860: 8880.0\n",
            "Loss after epoch 1861: 8740.0\n",
            "Loss after epoch 1862: 8840.0\n",
            "Loss after epoch 1863: 9048.0\n",
            "Loss after epoch 1864: 8838.0\n",
            "Loss after epoch 1865: 9004.0\n",
            "Loss after epoch 1866: 8752.0\n",
            "Loss after epoch 1867: 8530.0\n",
            "Loss after epoch 1868: 8982.0\n",
            "Loss after epoch 1869: 8886.0\n",
            "Loss after epoch 1870: 8732.0\n",
            "Loss after epoch 1871: 8736.0\n",
            "Loss after epoch 1872: 8828.0\n",
            "Loss after epoch 1873: 8810.0\n",
            "Loss after epoch 1874: 8948.0\n",
            "Loss after epoch 1875: 8626.0\n",
            "Loss after epoch 1876: 8864.0\n",
            "Loss after epoch 1877: 8772.0\n",
            "Loss after epoch 1878: 8698.0\n",
            "Loss after epoch 1879: 8980.0\n",
            "Loss after epoch 1880: 9094.0\n",
            "Loss after epoch 1881: 8894.0\n",
            "Loss after epoch 1882: 8922.0\n",
            "Loss after epoch 1883: 8674.0\n",
            "Loss after epoch 1884: 8844.0\n",
            "Loss after epoch 1885: 8810.0\n",
            "Loss after epoch 1886: 8900.0\n",
            "Loss after epoch 1887: 9050.0\n",
            "Loss after epoch 1888: 8678.0\n",
            "Loss after epoch 1889: 8768.0\n",
            "Loss after epoch 1890: 8686.0\n",
            "Loss after epoch 1891: 8686.0\n",
            "Loss after epoch 1892: 8956.0\n",
            "Loss after epoch 1893: 8822.0\n",
            "Loss after epoch 1894: 8826.0\n",
            "Loss after epoch 1895: 8600.0\n",
            "Loss after epoch 1896: 8750.0\n",
            "Loss after epoch 1897: 8630.0\n",
            "Loss after epoch 1898: 9080.0\n",
            "Loss after epoch 1899: 8792.0\n",
            "Loss after epoch 1900: 8514.0\n",
            "Loss after epoch 1901: 8568.0\n",
            "Loss after epoch 1902: 8630.0\n",
            "Loss after epoch 1903: 8836.0\n",
            "Loss after epoch 1904: 8914.0\n",
            "Loss after epoch 1905: 8574.0\n",
            "Loss after epoch 1906: 8824.0\n",
            "Loss after epoch 1907: 8892.0\n",
            "Loss after epoch 1908: 8626.0\n",
            "Loss after epoch 1909: 8500.0\n",
            "Loss after epoch 1910: 8934.0\n",
            "Loss after epoch 1911: 8552.0\n",
            "Loss after epoch 1912: 8464.0\n",
            "Loss after epoch 1913: 8970.0\n",
            "Loss after epoch 1914: 8808.0\n",
            "Loss after epoch 1915: 8422.0\n",
            "Loss after epoch 1916: 8716.0\n",
            "Loss after epoch 1917: 8708.0\n",
            "Loss after epoch 1918: 8472.0\n",
            "Loss after epoch 1919: 8668.0\n",
            "Loss after epoch 1920: 8610.0\n",
            "Loss after epoch 1921: 8588.0\n",
            "Loss after epoch 1922: 8556.0\n",
            "Loss after epoch 1923: 8760.0\n",
            "Loss after epoch 1924: 8636.0\n",
            "Loss after epoch 1925: 8904.0\n",
            "Loss after epoch 1926: 8594.0\n",
            "Loss after epoch 1927: 8504.0\n",
            "Loss after epoch 1928: 8652.0\n",
            "Loss after epoch 1929: 8804.0\n",
            "Loss after epoch 1930: 8648.0\n",
            "Loss after epoch 1931: 8812.0\n",
            "Loss after epoch 1932: 8746.0\n",
            "Loss after epoch 1933: 8642.0\n",
            "Loss after epoch 1934: 8302.0\n",
            "Loss after epoch 1935: 8576.0\n",
            "Loss after epoch 1936: 8476.0\n",
            "Loss after epoch 1937: 8622.0\n",
            "Loss after epoch 1938: 8782.0\n",
            "Loss after epoch 1939: 8570.0\n",
            "Loss after epoch 1940: 8484.0\n",
            "Loss after epoch 1941: 8584.0\n",
            "Loss after epoch 1942: 8524.0\n",
            "Loss after epoch 1943: 8618.0\n",
            "Loss after epoch 1944: 8514.0\n",
            "Loss after epoch 1945: 8616.0\n",
            "Loss after epoch 1946: 8552.0\n",
            "Loss after epoch 1947: 8528.0\n",
            "Loss after epoch 1948: 8298.0\n",
            "Loss after epoch 1949: 8352.0\n",
            "Loss after epoch 1950: 8546.0\n",
            "Loss after epoch 1951: 8584.0\n",
            "Loss after epoch 1952: 8626.0\n",
            "Loss after epoch 1953: 8602.0\n",
            "Loss after epoch 1954: 8584.0\n",
            "Loss after epoch 1955: 8608.0\n",
            "Loss after epoch 1956: 8570.0\n",
            "Loss after epoch 1957: 8714.0\n",
            "Loss after epoch 1958: 8540.0\n",
            "Loss after epoch 1959: 8590.0\n",
            "Loss after epoch 1960: 8604.0\n",
            "Loss after epoch 1961: 8524.0\n",
            "Loss after epoch 1962: 8400.0\n",
            "Loss after epoch 1963: 8518.0\n",
            "Loss after epoch 1964: 8276.0\n",
            "Loss after epoch 1965: 8554.0\n",
            "Loss after epoch 1966: 8340.0\n",
            "Loss after epoch 1967: 8384.0\n",
            "Loss after epoch 1968: 8302.0\n",
            "Loss after epoch 1969: 8574.0\n",
            "Loss after epoch 1970: 8632.0\n",
            "Loss after epoch 1971: 8316.0\n",
            "Loss after epoch 1972: 8518.0\n",
            "Loss after epoch 1973: 8448.0\n",
            "Loss after epoch 1974: 8712.0\n",
            "Loss after epoch 1975: 8376.0\n",
            "Loss after epoch 1976: 8388.0\n",
            "Loss after epoch 1977: 8326.0\n",
            "Loss after epoch 1978: 8402.0\n",
            "Loss after epoch 1979: 8500.0\n",
            "Loss after epoch 1980: 8380.0\n",
            "Loss after epoch 1981: 8272.0\n",
            "Loss after epoch 1982: 8238.0\n",
            "Loss after epoch 1983: 8542.0\n",
            "Loss after epoch 1984: 8562.0\n",
            "Loss after epoch 1985: 8484.0\n",
            "Loss after epoch 1986: 8314.0\n",
            "Loss after epoch 1987: 8366.0\n",
            "Loss after epoch 1988: 8552.0\n",
            "Loss after epoch 1989: 8582.0\n",
            "Loss after epoch 1990: 8354.0\n",
            "Loss after epoch 1991: 8362.0\n",
            "Loss after epoch 1992: 8488.0\n",
            "Loss after epoch 1993: 8398.0\n",
            "Loss after epoch 1994: 8258.0\n",
            "Loss after epoch 1995: 8394.0\n",
            "Loss after epoch 1996: 8318.0\n",
            "Loss after epoch 1997: 8522.0\n",
            "Loss after epoch 1998: 8374.0\n",
            "Loss after epoch 1999: 8126.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14172892, 31558000)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Palabras que MÁS se parecen "
      ],
      "metadata": {
        "id": "yO4lOuG0tf7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(positive=[\"caballero\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xs2znRbtsrq",
        "outputId": "a8554011-40bf-4323-cb00-2b8f50e7d753"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('el', 0.535047173500061),\n",
              " ('rey', 0.49865198135375977),\n",
              " ('dragón', 0.43063533306121826),\n",
              " ('mago', 0.38038501143455505),\n",
              " ('suelo', 0.3332987427711487),\n",
              " ('sorprendido', 0.3228212296962738),\n",
              " ('espejo', 0.3194670081138611),\n",
              " ('arriba', 0.3069528341293335),\n",
              " ('bufón', 0.30569782853126526),\n",
              " ('herrero', 0.30319517850875854),\n",
              " ('ante', 0.29895052313804626),\n",
              " ('rápidamente', 0.27513277530670166),\n",
              " ('puente', 0.2616966664791107),\n",
              " ('merlín', 0.2594411373138428),\n",
              " ('mucho', 0.2577259838581085)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(positive=[\"armadura\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hqk8JC8teGO",
        "outputId": "375b88c8-9fbe-4172-e22c-b36fbfb7c978"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('después', 0.359968364238739),\n",
              " ('cima', 0.3396948575973511),\n",
              " ('vida', 0.33104708790779114),\n",
              " ('pensar', 0.3214288651943207),\n",
              " ('bueno', 0.319081574678421),\n",
              " ('visera', 0.30767378211021423),\n",
              " ('hijo', 0.29840072989463806),\n",
              " ('puerta', 0.29037338495254517),\n",
              " ('barba', 0.28004884719848633),\n",
              " ('espada', 0.2749238610267639),\n",
              " ('habitación', 0.2736709713935852),\n",
              " ('fuego', 0.27049967646598816),\n",
              " ('hombro', 0.2695312798023224),\n",
              " ('misma', 0.2670157551765442),\n",
              " ('única', 0.26016175746917725)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(positive=[\"julieta\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhGVqYxtty_L",
        "outputId": "6557701a-e936-4b4e-8627-d773b26f6969"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amaba', 0.3950004279613495),\n",
              " ('fue', 0.3402339518070221),\n",
              " ('habían', 0.31799033284187317),\n",
              " ('parte', 0.3163617253303528),\n",
              " ('necesitado', 0.31185752153396606),\n",
              " ('hablar', 0.31131711602211),\n",
              " ('aquello', 0.2874036729335785),\n",
              " ('amado', 0.28302252292633057),\n",
              " ('ese', 0.2779780328273773),\n",
              " ('nota', 0.275251179933548),\n",
              " ('poco', 0.27507615089416504),\n",
              " ('bueno', 0.2705758512020111),\n",
              " ('perdido', 0.2701999545097351),\n",
              " ('les', 0.2662353217601776),\n",
              " ('había', 0.2624650299549103)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(positive=[\"castillo\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbNrOj75WfRm",
        "outputId": "63bf0051-d094-48c2-fd35-0635fd59438f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('espejo', 0.2969150245189667),\n",
              " ('continuó', 0.28406602144241333),\n",
              " ('entró', 0.2702958583831787),\n",
              " ('pensamiento', 0.26796311140060425),\n",
              " ('bufón', 0.2673908472061157),\n",
              " ('eres', 0.2555221915245056),\n",
              " ('hombre', 0.2526976466178894),\n",
              " ('poco', 0.2521313428878784),\n",
              " ('silencio', 0.24583519995212555),\n",
              " ('miedo', 0.24568074941635132)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Palabras que MENOS se parecen:"
      ],
      "metadata": {
        "id": "ncRJjh6Evfcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model_2.wv.most_similar(negative=[\"armadura\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnrZfGK5vV8j",
        "outputId": "78f78994-6437-42ef-86ee-574ad574736c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('la', 0.3934031128883362),\n",
              " ('tendréis', 0.3143630027770996),\n",
              " ('del', 0.307258278131485),\n",
              " ('abrir', 0.2981376647949219),\n",
              " ('mucho', 0.28400400280952454),\n",
              " ('mientras', 0.2770874500274658),\n",
              " ('dijo', 0.26948556303977966),\n",
              " ('dragones', 0.2631210386753082),\n",
              " ('puente', 0.24549484252929688),\n",
              " ('desapareció', 0.24121452867984772)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model_2.wv.most_similar(negative=[\"caballero\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a138b3ed-de1f-4d70-f2bb-b8e8e6169c37",
        "id": "f8lpdAcNB4Ub"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hace', 0.35617825388908386),\n",
              " ('estos', 0.35594308376312256),\n",
              " ('ayuda', 0.3500673174858093),\n",
              " ('medida', 0.3406900465488434),\n",
              " ('cruzada', 0.3170248568058014),\n",
              " ('tanto', 0.31408166885375977),\n",
              " ('viaje', 0.3133825361728668),\n",
              " ('los', 0.30042967200279236),\n",
              " ('tener', 0.2946837544441223),\n",
              " ('difícil', 0.2939636707305908)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model_2.wv.most_similar(negative=[\"julieta\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116661a0-f52a-4610-cf37-6c8cf80a6226",
        "id": "3YLT6JjjB4Um"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('del', 0.3303414583206177),\n",
              " ('debe', 0.32508790493011475),\n",
              " ('hay', 0.3218531906604767),\n",
              " ('tenéis', 0.32151517271995544),\n",
              " ('¿qué', 0.310785174369812),\n",
              " ('explicó', 0.28930947184562683),\n",
              " ('ir', 0.2835199236869812),\n",
              " ('espejo', 0.27972033619880676),\n",
              " ('puedes', 0.2757706344127655),\n",
              " ('puedo', 0.2705800533294678)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(negative=[\"ardilla\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxTyDkfxWCKL",
        "outputId": "e956d2bb-0f57-4a7b-ef76-9228b41d1163"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('quitarse', 0.4007602632045746),\n",
              " ('sabía', 0.38899457454681396),\n",
              " ('de', 0.3342830240726471),\n",
              " ('enorme', 0.30914440751075745),\n",
              " ('ponerse', 0.30849120020866394),\n",
              " ('dentro', 0.3062536418437958),\n",
              " ('atrapado', 0.29749417304992676),\n",
              " ('todas', 0.2820086181163788),\n",
              " ('mismo', 0.2789800465106964),\n",
              " ('reino', 0.27278584241867065),\n",
              " ('cruzada', 0.26729750633239746),\n",
              " ('era', 0.2666422724723816),\n",
              " ('parecía', 0.266150563955307),\n",
              " ('porque', 0.2587030231952667),\n",
              " ('dragones', 0.2536733150482178)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(negative=[\"dragón\"], topn=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb4dfa6-d721-47c1-d2f1-fdcac8f27f9c",
        "id": "Zp0HTDTEB4Um"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('durante', 0.4075787663459778),\n",
              " ('hablando', 0.34886059165000916),\n",
              " ('bien', 0.34122148156166077),\n",
              " ('sido', 0.3111303448677063),\n",
              " ('exclamó', 0.30669480562210083),\n",
              " ('no', 0.2982860207557678),\n",
              " ('verdadero', 0.2856340706348419),\n",
              " ('soy', 0.2825816571712494),\n",
              " ('dicho', 0.27722615003585815),\n",
              " ('tanto', 0.267424613237381),\n",
              " ('tendréis', 0.26650315523147583),\n",
              " ('misma', 0.2597801685333252),\n",
              " ('hermoso', 0.25772494077682495),\n",
              " ('realidad', 0.2555617094039917),\n",
              " ('podido', 0.25137418508529663)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f) Gráfico con TSNE"
      ],
      "metadata": {
        "id": "ttowKnJ2vUwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "f6003a70-7345-4d95-9978-b9ba79bb7da4",
        "id": "T8zghhAPvSwZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning:\n",
            "\n",
            "The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning:\n",
            "\n",
            "The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e6ed727a-90c9-4863-8400-443ae43c8f40\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e6ed727a-90c9-4863-8400-443ae43c8f40\")) {                    Plotly.newPlot(                        \"e6ed727a-90c9-4863-8400-443ae43c8f40\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"el\",\"que\",\"de\",\"la\",\"y\",\"caballero\",\"a\",\"no\",\"en\",\"se\",\"con\",\"su\",\"una\",\"lo\",\"por\",\"un\",\"del\",\"hab\\u00eda\",\"para\",\"m\\u00e1s\",\"le\",\"merl\\u00edn\",\"dijo\",\"los\",\"al\",\"las\",\"es\",\"era\",\"pero\",\"armadura\",\"estaba\",\"castillo\",\"ardilla\",\"rebeca\",\"si\",\"vez\",\"cuando\",\"como\",\"me\",\"todo\",\"julieta\",\"tiempo\",\"sam\",\"yo\",\"pregunt\\u00f3\",\"sus\",\"os\",\"mismo\",\"\\u00e9l\",\"ser\",\"tan\",\"esto\",\"sobre\",\"eso\",\"rey\",\"otra\",\"s\\u00ed\",\"mi\",\"ten\\u00eda\",\"uno\",\"qu\\u00e9\",\"sin\",\"verdad\",\"ahora\",\"replic\\u00f3\",\"esta\",\"pod\\u00eda\",\"drag\\u00f3n\",\"porque\",\"s\\u00f3lo\",\"puerta\",\"tambi\\u00e9n\",\"voz\",\"este\",\"crist\\u00f3bal\",\"ver\",\"decir\",\"aqu\\u00ed\",\"ya\",\"hacia\",\"ni\",\"mago\",\"vos\",\"sendero\",\"muy\",\"fue\",\"vida\",\"\\u00bfc\\u00f3mo\",\"mientras\",\"hecho\",\"as\\u00ed\",\"mir\\u00f3\",\"\\u00bfqu\\u00e9\",\"conocimiento\",\"nunca\",\"silencio\",\"cada\",\"visera\",\"te\",\"cuenta\",\"est\\u00e1is\",\"cabeza\",\"mucho\",\"puede\",\"luz\",\"nada\",\"cosas\",\"ella\",\"momento\",\"dio\",\"animales\",\"bueno\",\"hacer\",\"o\",\"d\\u00eda\",\"he\",\"respondi\\u00f3\",\"todos\",\"ese\",\"parec\\u00eda\",\"ambici\\u00f3n\",\"durante\",\"siempre\",\"antes\",\"\\u00e1rbol\",\"toda\",\"todas\",\"camino\",\"l\\u00e1grimas\",\"caballo\",\"tener\",\"yelmo\",\"estoy\",\"pie\",\"caer\",\"hab\\u00e9is\",\"luego\",\"est\\u00e1\",\"habitaci\\u00f3n\",\"poco\",\"t\\u00fa\",\"realmente\",\"fuera\",\"herrero\",\"manera\",\"vuestro\",\"coraz\\u00f3n\",\"pues\",\"sab\\u00eda\",\"amor\",\"miedo\",\"vuestra\",\"mente\",\"poder\",\"entonces\",\"tengo\",\"\\u00bfpor\",\"sentido\",\"c\\u00f3mo\",\"hablar\",\"castillos\",\"vio\",\"ha\",\"solo\",\"bien\",\"soy\",\"barba\",\"fuego\",\"despu\\u00e9s\",\"gente\",\"haber\",\"batalla\",\"hasta\",\"gran\",\"podr\\u00eda\",\"medida\",\"son\",\"\\u00bfy\",\"aprender\",\"simplemente\",\"sol\",\"otro\",\"ojos\",\"puedo\",\"atrapado\",\"sinti\\u00f3\",\"grit\\u00f3\",\"comenz\\u00f3\",\"hab\\u00edan\",\"eran\",\"lugar\",\"pens\\u00f3\",\"desde\",\"cima\",\"bolsalegre\",\"hombro\",\"ir\",\"hay\",\"o\\u00edr\",\"dos\"],\"x\":[0.30248337984085083,-3.828143835067749,-2.6338891983032227,1.4970487356185913,-1.6437991857528687,2.6856422424316406,-1.0250881910324097,-4.037285327911377,-4.118636131286621,-0.6769399046897888,-2.5472450256347656,-0.352780818939209,0.3436274528503418,-4.031893253326416,-4.48612117767334,1.7489093542099,-2.1060893535614014,-8.461074829101562,-5.462634086608887,-3.0526516437530518,-2.7983429431915283,-5.680342197418213,-6.268745422363281,22.9138126373291,1.6319650411605835,2.02524733543396,-11.76213550567627,-11.278582572937012,-6.312772274017334,13.849236488342285,-7.45553731918335,0.39125603437423706,13.803180694580078,5.504978656768799,-16.130922317504883,9.875261306762695,10.122196197509766,-1.9084749221801758,-6.135013580322266,-13.9967622756958,-11.452506065368652,-23.29500389099121,-24.711793899536133,-8.245034217834473,-14.40810775756836,-4.433163166046143,-25.70231819152832,11.584600448608398,13.34180736541748,-2.2793502807617188,-31.727685928344727,10.580633163452148,6.896023273468018,3.1264796257019043,-14.354409217834473,26.18007469177246,-19.450593948364258,-12.35132122039795,-28.661287307739258,-42.61163330078125,0.8446934223175049,-23.0946102142334,11.818730354309082,18.0598201751709,-6.562245845794678,-14.038247108459473,3.014622211456299,42.265132904052734,-2.333871364593506,12.111581802368164,33.83698272705078,-11.372488021850586,22.988597869873047,-49.87406921386719,-29.404821395874023,5.769726753234863,5.35271692276001,-8.9503173828125,-36.97481155395508,-23.884584426879883,-11.67708683013916,38.233158111572266,-18.73294448852539,12.59067153930664,10.220345497131348,-14.560227394104004,15.946340560913086,9.65869140625,14.704702377319336,-25.674755096435547,14.39095687866211,17.357524871826172,-35.992408752441406,-1.8326038122177124,-9.436577796936035,1.0445544719696045,-25.5766544342041,26.525297164916992,-7.864548683166504,25.78449058532715,-7.742880821228027,5.125934600830078,-32.03255844116211,-13.199082374572754,1.7476680278778076,-40.71786117553711,-44.45222473144531,27.98969078063965,8.719754219055176,-16.029186248779297,35.53437423706055,5.648186206817627,2.237926959991455,-2.9541797637939453,-17.948013305664062,-3.8239080905914307,1.3930240869522095,36.788665771484375,41.596553802490234,17.999921798706055,20.28417205810547,-37.25841522216797,10.769140243530273,43.60654067993164,4.205287933349609,31.469219207763672,3.307302474975586,-36.19878387451172,-1.321913480758667,9.056469917297363,-38.60578155517578,25.878068923950195,-29.082626342773438,10.461587905883789,-9.092535972595215,-2.7038540840148926,14.971355438232422,-14.535371780395508,20.79795265197754,-4.772867679595947,-10.521583557128906,-7.253254413604736,-42.378047943115234,4.694360733032227,-6.964983940124512,-15.58371639251709,39.611873626708984,-41.10839080810547,-14.053062438964844,15.659256935119629,-43.60951614379883,21.354774475097656,21.491670608520508,35.3672981262207,-22.01662254333496,33.31522750854492,-1.8002140522003174,4.532212734222412,0.3150118589401245,-7.686944007873535,33.1478385925293,-10.601683616638184,-8.850089073181152,31.070846557617188,-11.738677978515625,-43.2424201965332,8.196990013122559,19.068721771240234,22.560091018676758,-14.651689529418945,-16.949140548706055,31.64109992980957,-21.233844757080078,13.286680221557617,5.393089294433594,15.304494857788086,-6.361814498901367,-22.655895233154297,7.0910186767578125,-28.556995391845703,8.95054817199707,-43.11754608154297,-37.050785064697266,20.55841064453125,28.669116973876953,-8.860305786132812,-5.6256937980651855,0.428591787815094,-29.857830047607422,-18.49628257751465,33.56763458251953,3.9312496185302734,-28.298662185668945,33.96678924560547,-18.65675926208496,10.109474182128906,19.640424728393555,3.932945489883423,-14.405725479125977,26.476051330566406],\"xaxis\":\"x\",\"y\":[-3.823758840560913,6.963448524475098,0.025647565722465515,1.8184701204299927,-3.5233397483825684,-6.884535312652588,1.3582755327224731,10.05864429473877,-2.599191665649414,-1.607406497001648,-1.829282522201538,-5.7936530113220215,0.21848614513874054,12.07667064666748,1.2487492561340332,-0.9622116684913635,-7.291586875915527,-0.5300737619400024,-0.5940536856651306,5.067319869995117,-5.058568477630615,3.463575601577759,7.615670680999756,-22.487295150756836,-2.872626781463623,-5.128465175628662,9.419759750366211,3.9912819862365723,17.69978904724121,-3.330745220184326,-8.14183235168457,-8.140603065490723,-7.179551601409912,-13.969995498657227,12.888490676879883,34.860233306884766,14.916929244995117,11.517148971557617,12.175826072692871,15.203828811645508,-1.6249797344207764,-21.838340759277344,25.47315788269043,13.02652645111084,0.5724444389343262,-10.13498592376709,9.334775924682617,12.032931327819824,20.760299682617188,8.935832023620605,37.896514892578125,18.20793342590332,-37.39590835571289,14.838723182678223,5.89633846282959,-40.35582733154297,13.06428337097168,35.94474792480469,-1.8015209436416626,13.028307914733887,15.426878929138184,42.81917953491211,-10.11493968963623,25.22015953063965,9.466048240661621,46.97101974487305,39.58134078979492,3.6235389709472656,25.611705780029297,8.826737403869629,11.842552185058594,16.52454948425293,0.5980038642883301,1.2966887950897217,-21.304407119750977,9.6545991897583,29.65569305419922,8.194358825683594,5.562774181365967,-30.003442764282227,21.188241958618164,-4.296086311340332,6.184743404388428,4.902167320251465,2.404423952102661,8.70857048034668,-3.7441821098327637,30.19938087463379,-12.473627090454102,14.661046981811523,37.8894157409668,-6.991085052490234,29.310707092285156,-10.055614471435547,40.48408126831055,-10.941136360168457,-43.08070373535156,-9.743800163269043,15.610515594482422,26.13257598876953,34.63450241088867,-19.965499877929688,41.55133819580078,11.536160469055176,4.693495273590088,16.561044692993164,-19.689239501953125,-1.7860609292984009,-13.71111011505127,-8.374892234802246,-17.015127182006836,25.50887107849121,21.306034088134766,2.4303412437438965,-5.232772350311279,38.45795440673828,28.623741149902344,-21.308917999267578,16.318771362304688,43.42366409301758,2.942601203918457,0.7409518957138062,44.323387145996094,-22.74175262451172,-11.334505081176758,-36.44729995727539,-49.74049758911133,-35.094242095947266,-26.041194915771484,-8.218329429626465,-14.416718482971191,-13.833041191101074,12.30638313293457,-28.856830596923828,-32.182708740234375,36.10609817504883,-33.67169952392578,-18.40250015258789,44.305843353271484,-7.31463623046875,26.113515853881836,19.881269454956055,1.5701953172683716,-7.169112682342529,49.93947982788086,41.3927001953125,-7.7454962730407715,-3.767345428466797,3.164334297180176,3.6404409408569336,6.984017848968506,-17.917917251586914,20.09008026123047,30.656917572021484,15.997979164123535,-4.604186058044434,16.067842483520508,4.884862899780273,49.47135543823242,-41.3785400390625,-9.792176246643066,-18.719627380371094,2.35591983795166,-18.286285400390625,-37.68091583251953,29.20025062561035,-4.11157751083374,-7.147884368896484,-13.412046432495117,-2.3545632362365723,-19.153919219970703,7.399855613708496,2.823765754699707,1.8030904531478882,40.77088928222656,31.733659744262695,-2.7017436027526855,11.536355018615723,-43.93741989135742,32.33638000488281,-11.598563194274902,-27.806047439575195,-25.903650283813477,30.285503387451172,-6.014761447906494,-22.58606719970703,5.668228626251221,-30.497146606445312,16.987890243530273,-2.080204725265503,18.902141571044922,-2.904768228530884,-10.655210494995117,5.3137898445129395,37.4810676574707,-24.31406593322754,13.599864959716797,18.34136199951172,18.79536247253418,-24.3981876373291],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e6ed727a-90c9-4863-8400-443ae43c8f40');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(w2v_model_2)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones:\n",
        "\n",
        "El texto utilizado para crear los embeddings es un cuento en español llamado \"El caballero de la armadura oxidada\". El corpus resultante contiene 1121 documentos y un vocabulario de 455 palabras. Utilicé librería Gensim y probé con ambos modelos Skipgram y CBOW. En los dos casos, consideré:\n",
        "  *  Dimensión de los vectores de salida: 50\n",
        "  *  Mínimo numero de veces que tiene que estar repetida la palabra para quedar dentro del vocabulario: 5\n",
        "  *  Cantidad de palabras antes y después de la palabra target: 2\n",
        "  *  Entrenamiento con 2000 epochs.\n",
        "Para determinar el vocabulario, usé el tokenizador de Keras y TSNE de sklearn para graficar los resultados tal como hicimos en clase.\n",
        "\n",
        "\n",
        "Observaciones\n",
        "\n",
        "\n",
        "*   El tokenizador de Keras elimina las mayúsculas, por lo cual hay que tener esto en cuenta cuando se hace la búsqueda de palabras similares.\n",
        "*   Como aquí no se utiliza stemming, se observa que el vocabulario aparecen palabras con la misma raíz (ejemplos: \"amor\" y \"amoroso\", \"caballero\" y \"caballeros\").\n",
        "*   En el cuento habían muchos diálogos, por lo cual fue necesario preprocesar el texto para quitar quitar caracteres como guiones, ya que Gensim no los elimina y al realizar los ensayos el modelo detectaba estos elementos como los más parecidos a los nombres de los personajes principales (el caballero o Merlín, por ejemplo).\n",
        "*   Los modelos parecen funcionar bastante bien a pesar que la relación entre documentos y vocabulario no es tan significativa (nro de documentos aprox 2,5 veces más grande que nro de palabras en el vocabulario).\n",
        "*   Como no se removieron las stop-words, estas aparecen muy asociadas a varias de las palabras analizadas - por ejemplo para la palabra \"caballero\" el modelo encuentra el artículo \"el\" como la palabra más parecida (similitud coseno = 0.91 con Skipgram).\n",
        "\n",
        "*   Similitudes:\n",
        "      * Cuando se busca \"caballero\", los dos algoritmos encuentran que \"el\" es la palabra más parecida. CBOW parece dar un mejor resultado porque encuentra palabras como \"rey\", \"mago\", \"Merlín y \"dragón\" que corresponden a personajes fuertemente asociados con el caballero protagonista.\n",
        "      * Cuando se busca \"armadura\", Skipgram encuentra por ejemplo \"lado\", \"realidad\", \"desconocido\", \"aprender\" y CBOW en cambio \"barba\", \"vida\", \"cima\" y \"visera\". Los resultados son considerablemente distintos pero en ambos casos tienen relación con la armadura.\n",
        "      * Cuando se busca \"julieta\" los dos modelos encuentran \"amaba\" y \"amado\" que es correcto ya es que la esposa del caballero. \n",
        "      * Si se busca \"castillo\" , Skipgram devuelve \"silencio\" y \"conocimiento\" como más parecidas, lo que tiene mucho sentido en relación con la temática de los capítulos 4 (\"El castillo del silencio\") y 5 (\"El castillo del conocimiento\").\n",
        "\n",
        "*  Diferencias: Cuando se busca las palabras menos parecidas a \"armadura\" por ejemplo, el modelo devuelve algunas opciones como \"puente\", \"levadizo\", \"espejo\" (Skipgram) y dragones (CBOW). Esto tiene mucho sentido porque el dragon y el puente levadizo aparecen hacia el final de la historia (capítulo 6), donde el caballero ya se ha librado de la mayor parte de su armadura y por lo tanto ya casi no se menciona.\n",
        "\n",
        "* Gráficos de TSNE: El gráfico para el modelo que usa Skipgram parece estar mucho más concentrado en el centro. Haciendo zoom, se observan varios grupos de palabras interesantes: \"caballero\", \"armadura\" y \"atrapado\" que representan el tema central del cuento, y por otro lado \"rebeca\", \"ardilla\", \"animales\", \"miedo\" y \"hablar\" que resumen el viaje del caballero a lo largo de los diferentes castillos acompañado de la paloma rebeca y la ardilla. \n",
        "CBOW muestra resultados similares, pero junto a la palabra \"caballero\" coloca también a \"julieta\" su esposa, que se menciona repetidamente a lo largo de la historia, y \"herrero\", que es a quien recurre el caballero en el primer capítulo para quitarse la armadura.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G7SvJ3Ro8TsR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}