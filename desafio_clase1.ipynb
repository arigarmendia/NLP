{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[],"source":["# FORMA NRO 1\n","def get_vocabulary(corpus):\n","    documents = [] # Lista para guardar los documentos del corpus\n","    for document in range(len(corpus)):\n","        documents.append(corpus[document].split()) # Separo palabras y guardo el documento en la lista\n","    vocabulary = np.unique(np.concatenate(documents).ravel()) # Armo array con todas las palabras y tomo las no repetidas\n","    return documents, vocabulary\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VOCABULARIO:['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","DOCUMENTOS:[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n"]}],"source":["# VERIFICO RESULTADOS CON LA PRIMERA FUNCIÓN\n","documents1, vocabulary1 = get_vocabulary(corpus)\n","\n","print(f\"VOCABULARIO:{vocabulary1}\")\n","print(f\"DOCUMENTOS:{documents1}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# FORMA NRO 2\n","def get_vocab(corpus):\n","    documents = np.char.split(corpus.reshape(len(corpus),1)).flatten()\n","    vocabulary = np.unique(np.concatenate(documents))\n","    return documents.tolist(), vocabulary"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["VOCABULARIO:['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","DOCUMENTOS:[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n"]}],"source":["# VERIFICO RESULTADOS CON SEGUNDA FUNCIÓN\n","documents2, vocabulary2 = get_vocab(corpus)\n","\n","print(f\"VOCABULARIO:{vocabulary2}\")\n","print(f\"DOCUMENTOS:{documents2}\")\n"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["def get_ohe(corpus):\n","    documents, vocabulary = get_vocab(corpus) # Con la función anterior calculo arrays de documentos y vocabulario\n","    ohe_result = np.zeros((len(documents),len(vocabulary)), dtype='int8') # Creo un ndarray con ceros para guardar el resultado\n","    for document in range(len(documents)):\n","       mask = np.in1d(vocabulary, documents[document]) # Con esta máscara ubico los índices de palabras en el vocabulario para cada doc\n","       ohe_result[document,mask] = 1 # Convierto a 1s usando la máscara en mi matriz de resultados\n","    return ohe_result, vocabulary, documents"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DOCUMENTOS:[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","VOCABULARIO:['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","ONE-HOT ENCODING:\n"," [[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 1 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["ohe_result, vocabulary, documents = get_ohe(corpus)\n","\n","print(f\"DOCUMENTOS:{documents}\")\n","print(f\"VOCABULARIO:{vocabulary}\")\n","print(f\"ONE-HOT ENCODING:\\n {ohe_result}\")"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def get_freq(corpus):\n","    documents, vocabulary = get_vocab(corpus) # Con la función anterior calculo arrays de documentos y vocabulario\n","    frequencies = np.zeros((len(documents),len(vocabulary)), dtype='int8') # Creo un ndarray con ceros para guardar el resultado\n","    for document in range(len(documents)):\n","      mask = np.in1d(vocabulary, documents[document]) # Con esta máscara ubico los índices de palabras en el vocabulario para cada doc\n","      uniques, counts = np.unique(documents[document], return_counts=True) \n","      frequencies[document, mask] = counts\n","    return frequencies, vocabulary, documents"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DOCUMENTOS:[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","VOCABULARIO:['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","VECTOR DE FRECUENCIAS (TF):\n"," [[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 2 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n"]}],"source":["frequencies, vocabulary, documents  = get_freq(corpus)\n","\n","print(f\"DOCUMENTOS:{documents}\")\n","print(f\"VOCABULARIO:{vocabulary}\")\n","print(f\"VECTOR DE FRECUENCIAS (TF):\\n {frequencies}\")"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["def get_tfidf(corpus):\n","    ohe_result, _, _ = get_ohe(corpus) # Calculo OHE porque lo voy a usar para el idf (para hallar el denominador del log)\n","    tf, _, _ = get_freq(corpus)\n","    idf = np.log10(len(corpus)/(np.sum(ohe_result, axis=0))) \n","    tfidf = tf * idf\n","    return tfidf, tf, idf"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["TF:\n"," [[0 1 0 1 0 1 0 0 1]\n"," [1 1 1 1 0 1 2 0 0]\n"," [0 0 0 0 1 0 1 1 0]]\n","\n","IDF:\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.47712125 0.17609126\n"," 0.17609126 0.47712125 0.47712125]\n","\n","TF-IDF):\n"," [[0.         0.17609126 0.         0.17609126 0.         0.17609126\n","  0.         0.         0.47712125]\n"," [0.47712125 0.17609126 0.47712125 0.17609126 0.         0.17609126\n","  0.35218252 0.         0.        ]\n"," [0.         0.         0.         0.         0.47712125 0.\n","  0.17609126 0.47712125 0.        ]]\n"]}],"source":["tfidf, tf, idf = get_tfidf(corpus)\n","\n","print(f\"TF:\\n {tf}\\n\")\n","print(f\"IDF:\\n {idf}\\n\")\n","print(f\"TF-IDF):\\n {tfidf}\")"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":359,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def compare(corpus, doc_idx):\n","    tfidf_vector, _, _ = get_tfidf(corpus)\n","    target_vector = tfidf[doc_idx]\n","    similarity_result = []\n","    similarity_idx = np.arange(len(corpus))\n","    for vector in range(len(tfidf_vector)):\n","        cosine_sim = cosine_similarity(tfidf_vector[vector], target_vector)\n","        similarity_result.append(cosine_sim)\n","    similarity_result = np.array(similarity_result)\n","    print(f\"Similitud coseno: {similarity_result}\")\n","    order_idx = np.argsort(similarity_result)[::-1]\n","    result = corpus[order_idx][1:]\n","    \n","    return result\n","\n"]},{"cell_type":"code","execution_count":360,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Similitud coseno: [1.        0.2003419 0.       ]\n","Documento seleccionado: que dia es hoy\n","Documentos ordenados por mayor similitud coseno:['martes el dia de hoy es martes' 'martes muchas gracias']\n"]}],"source":["# Prueba Nro 1\n","\n","doc_nbr = 0\n","result1 = compare(corpus, doc_nbr)\n","print(f\"Documento seleccionado: {corpus[doc_nbr]}\")\n","print(f\"Documentos ordenados por mayor similitud coseno:{result1}\")\n","\n"]},{"cell_type":"code","execution_count":361,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Similitud coseno: [0.2003419  1.         0.10845712]\n","Documento seleccionado: martes el dia de hoy es martes\n","Documentos ordenados por mayor similitud coseno:['que dia es hoy' 'martes muchas gracias']\n"]}],"source":["# Prueba Nro 2\n","\n","doc_nbr = 1\n","result2 = compare(corpus, doc_nbr)\n","print(f\"Documento seleccionado: {corpus[doc_nbr]}\")\n","print(f\"Documentos ordenados por mayor similitud coseno:{result2}\")\n","\n"]},{"cell_type":"code","execution_count":362,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Similitud coseno: [0.         0.10845712 1.        ]\n","Documento seleccionado: martes muchas gracias\n","Documentos ordenados por mayor similitud coseno:['martes el dia de hoy es martes' 'que dia es hoy']\n"]}],"source":["# Prueba Nro 3\n","\n","doc_nbr = 2\n","result3 = compare(corpus, doc_nbr)\n","print(f\"Documento seleccionado: {corpus[doc_nbr]}\")\n","print(f\"Documentos ordenados por mayor similitud coseno:{result3}\")\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('ari-env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"a25e91bd5a7c6b895cbcd0e53a12fc643be6b7302a2f32a7a65958bddcd535a8"}}},"nbformat":4,"nbformat_minor":0}
